{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Lambda Feedback!","text":"Students: Teachers: <ul><li>Accessible content - in the browser and on PDF. </li><li>Feedback - express mathematical ideas naturally and get instant feedback. </li><li>Analytics - track your progress, manage your time</li><li>Social - connect with someone doing the same thing as you, now!</li></ul> <ul><li>Curate content - edit and publish your content in one place.</li><li>Share - customise content from others; share your own content and get kudos.</li><li>Analytics - curate automated feedback to meet student needs; arrange in-person lessons according to student needs.</li></ul> <p>This project began at Imperial College in 2022. The project itself, and the documentation, is currently under construction.</p> <p>Lambda Feedback is a homework platform providing automated formative feedback. We are initially targeting STEM subjects in Higher Education, with a particular focus on mathematical subjects (such as mathematical methods or mechanics). The value proposition is given briefly here.</p> <p>In these docs you can find:</p> <p><li> Student guide </li><li> Teacher guide </li><li> Advanced teachers. <p>Check out Lambda Feedback by clicking on the button below!</p> <p>Visit Lambda Feedback</p> <p>Articles relating to Lambda Feedback:</p> <ul> <li>Value proposition: Computers make us human</li> <li>Student experience of self-study: Getting stuck</li> <li>The role of challenge in self-study: Friction in the ideal learning process</li> <li>Configuring online learning: Worked solutions: when and how to use them?</li> <li>Articles on evaluation function algorithms, and on data analytics, are in preparation.</li> </ul>"},{"location":"opportunities/","title":"Opportunities","text":"<p>2023/06/05: there are no vacancees at the moment. The positions below are now filled.</p>"},{"location":"opportunities/#principal-full-stack-developer","title":"Principal Full Stack Developer","text":"<p>We are recruiting a Principal Full Stack Developer to work on the Lambda Feedback project.</p> <p>Work is by contract for up to 40 days per year. The contractor will implement new features, review work by software engineers on the project, and advise on architecture decisions.</p> <p>The developer should be senior with significant experience taking responsibility for a full stack application, and ready to 'hit the ground running'. The tech stack is AWS / Postgres / Prisma / GraphQL / Nest.js / Next.js (React.js). The project is all built in Typescript. Infrastructure, testing, and deployment is all automated. We use test driven development, and CI/CD using CircleCI.</p> <p></p> <p>We are a diverse team of educators, students, and software professionals developing an application in-situ with our users. This is a motivating application in education and uses exciting new technologies. We are a flexible team that values creativity and redefining problems before solving them.</p> <p></p> <p>We have work that needs to be completed by July, and will have potential follow on work and commercialisation opportunities if the initial work is successful.</p> <p>Work is by contract (outside IR35) and we pay for deliverables. Prices for deliverables are agreed based on a day rate of \u00a3500-\u00a3800 depending on competence. We prefer to write and agree detailed completion criteria before agreeing to work. All work is quality assured, including testing with users, before approval.</p> <p>The Lambda Feedback project is owned and operated by Imperial College London. We work on campus in South Kensington, London. The position of contractor can optionally be fulfilled remotely if the holder prefers but we do expect occasional visits in-person. We are very flexible with timings and work regimes - our priority is to get the deliverables; we know that people work differently, and that people work best when they work in their own way.</p> <p>If you are interested, please enquire by email with peter [dot] johnson [at] ic.ac.uk.</p>"},{"location":"opportunities/#summer-placements","title":"Summer placements","text":"<p>Bursary: 8 positions, 8 weeks each (flexible), full-time. Bursary: \u00a3365 per week.</p> <p>Who should apply: Students from Imperial College London from any cohort who study in the following subjects: Aeronautics, Chemical Engineering, Computing, Design Engineering, Materials Science, Mathematics, Mechanical Engineering, Physics.</p> <p>Campus/Location: South Kensington, with opportunities to be remote later in the project.</p> <p>How to apply: apply here. Applications should be 300-500 words.</p> <p>Deadline: 31st March</p> <p>Contact details: Peter [dot] Johnson [at] ic.ac.uk</p> <p>More details on the project:</p>"},{"location":"opportunities/#lambda-feedback-software-a-place-to-do-homework","title":"Lambda Feedback software, a place to do homework","text":"<p>Lambda Feedback is a web platform that hosts homework, with a focus on mathematical subjects. The platform hosts\u202fquestion content both in the browser and in traditional PDF format. Online step-by-step solutions are also provided and are particularly popular with students.</p> <p>In addition to content delivery, the platform provides automated feedback on student responses. The long-term vision is rich, timely, personalised, feedback to students at the time of doing their homework.</p> <p>The software is being developed within Imperial. This year is our first academic year in \u2018alpha\u2019 version which hosted 9 modules across 8 departments and 2 faculties, with over 1,000 student users. We are now working to widen the availability of the software and to improve the functionality.</p> <p>More information about the software can be found here:\u202f Article: https://teachingengineers.wordpress.com/2022/07/18/computers-make-us-human/\u202f Presentation: click here</p> <p>We have 8 StudentShapers positions in summer 2023 each with the following purpose:\u202f \u2022 In partnership with an academic staff member, curate their content on Lambda Feedback. Key aspects include content transfer and editing; setting up automated feedback; improving the content.\u202f \u2022 As part of the wider team of summer students, develop the software more broadly. Key aspects include documenting good practice, testing new features, designing new features, and designing a broader vision for the future software \u2013 for example curating positive learning communities on the platform, identifying key analytics to serve students and teachers, or developing study aids.</p> <p>Essential skills and experience that we are looking for:\u202f \u2022 A passion for and knowledge of your own subject\u202f \u2022 A deep appreciation for the student experience in your subject, and the key needs of students\u202f \u2022 A keen interest in content management, including typesetting  (markdown, LaTeX, images; learn as you go!)\u202f \u2022 A vision for digital education where software serves the needs of today\u2019s students</p> <p>Additional ways you can add value to the project if you have the skills:\u202f \u2022 Mathematical computing skills, e.g. in Python, to help develop our evaluation functions (more info here: https://lambda-feedback.github.io/user-documentation/advanced/)\u202f \u2022 Data science skills to analyse our growing data set, for example skills in SQL queries, data analysis e.g. in Pandas, data visualisation, machine learning.\u202f \u2022 Graphic design, UI/UX design, vision development for online products\u202f \u2022 Web development skills in any part of the following stack: AWS / Postgres / Prisma / GraphQL / Nest.js / Next.js (React.js) / Typescript / CircleCI</p>"},{"location":"terminology/","title":"Terminology","text":""},{"location":"terminology/#general-information","title":"General Information","text":"<p>LambdaFeedback is a place to study online. Teachers curate content that students can access. Content is available in the browser and in PDF. Automated feedback on final answers and detailed worked solutions are provided.</p>"},{"location":"terminology/#terminology-used-and-definitions","title":"Terminology Used and Definitions","text":"<p>Here, the fundamental structure and terminology will be laid out.</p>"},{"location":"terminology/#evaluation-functions","title":"Evaluation Functions","text":"<p>An evaluation function is an algorithm that is applied to a response area, whereby the student's response is evaluated and checked. The types of evaluation functions correspond to the types of response areas.</p>"},{"location":"terminology/#final-answer","title":"Final Answer","text":"<p>This section lies within the \"Help\" panel which appears upon clicking on the \"Help\" button. It serves as a simple container for the final answer, so that the student may compare results.</p> <p>This is an optional section, and so does not have to be included in any question.</p>"},{"location":"terminology/#modules","title":"Modules","text":"<p>A module is a set programme of taught material. In a university setting, this would correspond to a course module.</p>"},{"location":"terminology/#questions","title":"Questions","text":"<p>A question is a problem within a set, and it may contain any number of parts.</p>"},{"location":"terminology/#response-areas","title":"Response Areas","text":"<p>A response area is an interactive element. Student enters a response and receives feedback. There are different types of response area (text, numerical, array etc.), and these correspond to the different types of information the student is required to input.</p>"},{"location":"terminology/#sets","title":"Sets","text":"<p>We use the word 'Set' to refer to a group of questionscontent. In a university setting, a Set typically corresponds to an individual homework/tutorial sheet.</p>"},{"location":"terminology/#structured-tutorial","title":"Structured Tutorial","text":"<p>Content providing a structure with which to approach a problem - but not to give the full details away. It is encouraged to be the first piece of guidance for the student before they look at the \"Worked Solution\", or \"Final Answer\".</p> <p>This section lies within the \"Help\" panel which appears upon clicking on the \"Help\" button.</p> <p>This is an optional section, and so does not have to be included in any question.</p>"},{"location":"terminology/#student-learner","title":"Student (learner)","text":"<p>From the perspective of Lambda Feedback, a student is someone who accesses and responds to problem sets. A student only has permissions to view and respond to problem sets (not to edit them).</p>"},{"location":"terminology/#teacher","title":"Teacher","text":"<p>From the perspective of Lambda Feedback, a teacher is someone who creates and manages content. A teacher's account has permissions to create, edit, and delete content within a Module.</p>"},{"location":"terminology/#worked-solution","title":"Worked Solution","text":"<p>The stages of working that lead to a final answer. It may be split into multiple steps which the student can reveal sequentially. This section lies within the \"Help\" panel which appears upon clicking on the \"Help\" button.</p> <p>This is an optional section, and so does not have to be included in any question.</p>"},{"location":"advanced/","title":"Advanced users","text":"<p>Advanced users can develop their own evaluation functions.</p>"},{"location":"advanced/#evaluation-functions","title":"Evaluation functions","text":"<p>Evaluation functions are responsible for taking in a user's response, comparing it with a correct answer, and providing feedback to the frontend application. Living as containserized Lambda functions on the cloud, they are infinitely customisable and language-agnostic. Content authors should be able to create their own at will. However, we are aware that in a lot of cases, this grading logic will be similar, which is why a few functions have already been created.</p> <p>Evaluation functions - Quickstart Guide</p>"},{"location":"advanced/#response-areas","title":"Response areas","text":"<p>Response areas are components in the frontend where student users can enter a response. The response is sent to the evaluation function, which returns feedback to the response area. In the alpha version response areas are built into the software (rather than being modular) so are not straightforward to redevelop. This website catalogues the basic behaviour of response areas, to inform developers of evaluation functions.</p> <p>Response areas - overview</p>"},{"location":"advanced/#system-architecture","title":"System Architecture","text":"<ul> <li>Technologies</li> <li>Deployment pipelines</li> <li>Hierarchy</li> </ul>"},{"location":"advanced/#future-features","title":"Future Features","text":""},{"location":"advanced/placeholder/","title":"coming soon","text":""},{"location":"advanced/evaluation_functions/","title":"Deployed Evaluation Functions","text":"<p>Documentation for each of the functions registered to the LambdaFeedback platform are pulled in this section automatically. This is done using a custom MkDocs plugin EvalDocsLoader.</p> <p>If you can't see any documentation files under this section, please contact an admin.</p>"},{"location":"advanced/evaluation_functions/alternate_languages/","title":"Alternate Evaluation Function Languages","text":""},{"location":"advanced/evaluation_functions/alternate_languages/#lambda-compatible-images","title":"Lambda-Compatible Images","text":""},{"location":"advanced/evaluation_functions/alternate_languages/#extending-a-pre-built-lambda-image","title":"Extending a pre-built Lambda image","text":"<ul> <li>Available for: Node.js, Python, Java, .NET, Go, Ruby</li> <li>Docs</li> <li>Repo</li> <li>These base images are regularly updated, and the most widely used (more docs)</li> <li>They also come with pre-packaged runtime interface clients - a HTTP interface for runtimes to receive invocation events and respond<ul> <li>Good for local development</li> </ul> </li> </ul>"},{"location":"advanced/evaluation_functions/alternate_languages/#creating-custom-base-images","title":"Creating custom base images","text":"<ul> <li>Using the lambda/provided image<ul> <li>This \"contains all the required components to run functions packaged as container images on Lambda\"</li> </ul> </li> <li>Building a custom runtime from scratch <ul> <li>Custom AWS Lambda runtimes</li> <li>Runtimes walkthrough tutorial</li> </ul> </li> <li>Emulate execution locally? <p>Lambda provides a runtime interface emulator (RIE) for you to test your function locally. The AWS base images for Lambda and base images for custom runtimes include the RIE. For other base images, you can download the\u00a0Runtime interface emulator\u00a0from the AWS GitHub repository.</p> </li> </ul>"},{"location":"advanced/evaluation_functions/alternate_languages/#misc-notessources","title":"Misc Notes/Sources","text":"<ul> <li>The Lambda Execution Environment</li> <li>Create Images from Alternative base images</li> </ul>"},{"location":"advanced/evaluation_functions/alternate_languages/#development-philosophy","title":"Development Philosophy","text":"<p>Ultimately we want to call a function made by a user in any language. Two ways to do this:</p> <ul> <li> <p>We write and provide runtime in all the different languages. This means that all the logic happens in that language. We write the code that actually receives the requests from lambda function events. In this case, the user function can be imported from those handlers.</p> <ul> <li>Writing handlers in each of those languages requires time and extensive knowledge (in order to write robust code)</li> <li>Handler code needs to:<ul> <li>Have clean and reliable error catching</li> </ul> </li> </ul> </li> <li> <p>We write a global runtime, which makes a call to their function via a sub-process. We call their script, which must recieve the payload as a commandline argument.</p> <ul> <li>User has to write more code <ul> <li>For allowing cmdline arguments, and parsing of inputs</li> </ul> </li> <li>Might be slower than in other languages. Since another script has to be executed.</li> </ul> </li> </ul>"},{"location":"advanced/evaluation_functions/feedback/","title":"Base Layer Feedback Implementation","text":"<p>Input structure:</p> <pre><code>{\n    \"response\": \"user input\",\n    \"answer\": \"original answer\",\n    \"params\": {\n        \"cases\": [\n            {\n                \"answer\": \"same shape as original answer\",\n                \"feedback\": \"feedback string\",\n                \"params\": {...} # Any parameters to set or override\n            },\n            ...\n        ]\n    }\n}\n</code></pre>"},{"location":"advanced/evaluation_functions/feedback/#execution-logic-for-the-eval-command","title":"Execution Logic for the <code>eval</code> command","text":"<ol> <li>First <code>evaluation_function</code> is called using the response, answer and params</li> <li>If evaluation threw an error, then return the error message</li> <li>If evaluation was successful, check for matching cases<ol> <li>If \"params\" contains a non-empty list of \"cases\", determine the correct feedback, add it to the result and return the block (Logic for this is described in the next section) </li> <li>If \"params\" doesn't contain a list of cases, simply return the result</li> </ol> </li> </ol>"},{"location":"advanced/evaluation_functions/feedback/#determining-the-correct-feedback-case","title":"Determining the correct feedback case","text":"<ol> <li>Iterate through each case in the list of <code>cases</code>:<ol> <li>Validate the case has an 'answer' and 'feedback'</li> <li>If the case contains 'params', then merge them with the original 'params', overwriting values if they already exist</li> <li>Call <code>evaluation_function</code> with the student \"response\", case \"answer\" and merged \"params\"<ol> <li>If the function returns \"is_correct: true\", we have a match, store case and feedback returned from the evaluation function</li> <li>If the function returns an error, catch it and add it to a list of warnings</li> </ol> </li> </ol> </li> <li>If no matches were found, don't return any feedback </li> <li>If exactly one match was found, check if <code>override_eval_feedback</code> is in parameters<ol> <li>If <code>override_eval_feedback</code> is set to true, return the case feedback</li> <li>If <code>override_eval_feedback</code> is not set or set to false, append the evaluation function feedback to the case feedback, separated by a linebreak and the return the result</li> </ol> </li> <li>If more than one matches were found, return the first one (using the same procedure as if only one match was found) and add a warning explaining which cases matched, and why only the first was selected.</li> </ol>"},{"location":"advanced/evaluation_functions/local/","title":"Running and Testing Functions Locally","text":""},{"location":"advanced/evaluation_functions/local/#simple","title":"Simple","text":""},{"location":"advanced/evaluation_functions/local/#using-docker","title":"Using Docker","text":"<p>This method builds and runs evaluation functions in the same way they are deployed on AWS as Lambda functions. Extending a pre-built and AWS-maintained base python image, the container contains a HTTP client which can be used to locally simulate Lambda execution events. </p> <p>Note that this is different from the simple method proposed, in that it gives access to all the functionality provided by the base layer. This means that commands such as <code>docs</code> and <code>healthcheck</code> can be tested.</p> <ol> <li> <p>Install Docker on your machine</p> </li> <li> <p>Navigate to the root directory of your function</p> </li> <li> <p>Build the image. This will pull our base image from Dockerhub, extend it with files specific to your evaluation function and name it <code>eval-tmp</code>.     <pre><code>docker image build -t eval-tmp app\n</code></pre></p> </li> <li> <p>Spin up a container using the image built in the previous step.     <pre><code>docker run --rm -d --name eval-function -p 9000:8080 eval-tmp \n</code></pre></p> </li> <li> <p>You can now simulate requests to the function using any request client (like Insomnia or Postman). By default, the url you can hit is:     <pre><code>http://localhost:9000/2015-03-31/functions/function/invocations\n</code></pre></p> Warning <p>When deployed, our Lambda functions are triggered by calls made through an AWS API Gateway. This means that when testing locally, events sent should follow the structure of events triggered by that resource. That is, if you want to simulate what it would be like to make web requests to the deployed function.</p> <p>Specifically, this means structuring requests in the following way: <pre><code>{\n  \"headers\": {\n    \"command\": \"eval\"\n  },\n  \"body\": {\n    \"response\": \"a\",\n    \"answer\": \"a\",\n    \"params\": {\n      \"garlic\": \"moreish\"\n    }\n  }\n}\n</code></pre></p> <p>The main difference is that <code>headers</code> and <code>body</code> are sent as keys in the main body of the local request. When hitting the deployed function through the API Gateway, the <code>command</code> field would instead be passed in the actual HTTP headers of the request - and the actual request body would only contain the <code>response</code>, <code>answer</code> and <code>params</code> fields.</p> </li> <li> <p>(Optional) The <code>run</code> command specifies the -d flag, which spins up the container in detached mode. If you want to inspect the logs of the function, you can run:     <pre><code>docker container logs -f eval-function \n</code></pre></p> </li> </ol> Tip <p>You will very rarely need this, but you can peek into the running container by opening a shell within it using:</p> <pre><code>docker exec -it eval-function bash\n</code></pre>"},{"location":"advanced/evaluation_functions/local/#useful-links","title":"Useful Links","text":""},{"location":"advanced/evaluation_functions/module/","title":"evaluation-function-utils Package","text":"<ul> <li>Error Reporting </li> <li>Schema validation</li> <li>Local testing</li> </ul>"},{"location":"advanced/evaluation_functions/module/#errors","title":"Errors","text":"<p>Submodule containing custom error and exception classes, which can be properly caught by the base evaluation layer, and return more detailed and appropriate errors.</p>"},{"location":"advanced/evaluation_functions/module/#class-evaluationexception","title":"class <code>EvaluationException</code>","text":"<p>This class extends the usual python <code>Exception</code>, with additional functionality. It can be used to package additional fields and values to errors thrown and returned by evaluation functions.</p> <p>Example</p> <p>If at some point in the execution of the <code>evaluation_function</code>, an error is thrown:</p> <pre><code>from evaluation_function_utils.errors import EvaluationException\n\nif isinstance(input, str):\n    raise EvaluationException(\n        \"The input must not be a string\", \n        valid_types=[\"int\", \"float\", \"array\"],\n    )\n</code></pre> <p>Then the output generated by the lambda function will look like:</p> <pre><code>{\n  \"command\": \"eval\",\n  \"error\": {\n    \"message\": \"The input must not be a string\",\n    \"valid_types\": [\n      \"int\", \"float\", \"array\"\n    ]\n  }\n}\n</code></pre> <p>This class contains an error_dict property, which packages the additional arguments given to the Exception instance into a JSON-serializable object. It does so in an error-safe way, also reporting serialization errors if they occur.</p>"},{"location":"advanced/evaluation_functions/module/#client","title":"Client","text":"<p>This submodule contains a custom <code>EvaluationFunctionClient</code>, which can be used to call other deployed evaluation functions.</p>"},{"location":"advanced/evaluation_functions/module/#class-evaluationfunctionclient","title":"class <code>EvaluationFunctionClient</code>","text":"<p>Client wrapped around the botocore.client.Lambda, for invoking deployed evaluation functions. On initialisation, it fetches credentials from environment variables \"INVOKER_KEY\", \"INVOKER_ID\" and \"INVOKER_REGION\", or from an optional environment file prescrived by <code>env_path</code>. </p> <p>Example</p> <pre><code>from evaluation_function_utils.client import EvaluationFunctionClient\nclient = EvaluationFunctionClient()\n\ndef evaluation_function(response, answer, params): \n    return client.invoke('isExactEqual', response, answer, params)\n</code></pre> <p>In this example, the evaluation_function completely offloads grading to the deployed 'isExactEqual' function. </p> <p>Note: The <code>EvaluationFunctionClient.invoke</code> method was designed to behave exactly as if the <code>evaluation_function</code> function defined in the targeted deployed function was called directly. This means that if errors are encountered an <code>EvaluationException</code> is raised.</p>"},{"location":"advanced/evaluation_functions/quickstart/","title":"Developing Evaluation Functions: Getting Started","text":""},{"location":"advanced/evaluation_functions/quickstart/#what-is-an-evaluation-function","title":"What is an Evaluation Function?","text":"<p>It's a cloud function which performs some computation given some user input (the response), a problem-specific source of truth (the answer), and some optional parameters (params). Evaluation functions capture and automate the role of a teacher who has to keep marking the same question countless times. The simplest example for this would be one which checks for exact equivalence - where the function signals a response is correct only if it is identical to the answer. However, more complex and exotic ones such as symbolic expression equivalence and parsing of physical units can be imagined. </p>"},{"location":"advanced/evaluation_functions/quickstart/#getting-setup-for-development","title":"Getting Setup for Development","text":"<ol> <li>Get the code on your local machine (Using github desktop or the <code>git</code> cli)<ul> <li>For new functions: create and clone a new repository using the boilerplate template. Make sure the new repository is set to public (it needs access to organisation secrets).</li> <li>For existing functions: please make your changes on a new separate branch </li> </ul> </li> <li>If you are creating a new function, you'll need to set it's name (as it will be deployed) in the <code>config.json</code> file, available in the root directory.<ul> <li>The name must be unique. To view existing grading functions, go to:<ul> <li>Staging API Gateway Integrations</li> <li>Production API Gateway Integrations</li> </ul> </li> </ul> </li> <li> <p>You are now ready to start making changes and implementing features by editing each of the three main function-logic files:</p> <ol> <li> <p><code>app/evaluation.py</code>: This file contains the main <code>evaluation_function</code> function, which ultimately gets called to compare a response to an answer. </p> <p><code>evaluation.py</code> Specification</p> </li> <li> <p><code>app/evaluation_tests.py</code>: This is where you can test the logic in <code>evaluation.py</code>, following the standard <code>unittest</code> format. </p> <p><code>evaluation_tests.py</code> Specification</p> </li> <li> <p>Documentation files:</p> <ul> <li> <p><code>app/docs/dev.md</code>: This file should be edited to reflect any changes/features implemented, following a developer perspective. It is baked into the function's image to be pulled by this documentation website under the deployed functions section.</p> </li> <li> <p><code>app/docs/user.md</code>: This file documents how the function can be used by a teacher user, from the perspective of editing content on the LambdaFeedback platform. This time, files are collated and displayed in the Teacher section.</p> </li> </ul> </li> </ol> </li> <li> <p>Changes can be tested locally by running the tests you've written using: <pre><code>python -m unittest app/evaluation_tests.py\n</code></pre> Running and Testing Functions Locally</p> </li> <li> <p>Merge commits into the default branch will trigger the <code>test-and-deploy.yml</code> workflow, which will build the docker image, push it to a shared ECR repository, then call the backend <code>grading-function/ensure</code> route to build the necessary infrastructure to make the function available from the client app.</p> </li> <li> <p>You can now test the deployed evaluation function using your prefered request client (such as Insomnia or Postman or simply <code>curl</code> from a terminal). Functions are made available at:     <pre><code>https://c1o0u8se7b.execute-api.eu-west-2.amazonaws.com/default/&lt;function name as defined in config.json&gt;\n</code></pre></p> <p>Example Request to SymbolicEqual</p> <pre><code>``` \ncurl --request GET \\\n    --url https://c1o0u8se7b.execute-api.eu-west-2.amazonaws.com/default/symbolicEqual \\\n    --header 'Content-Type: application/json' \\\n    --header 'command: eval' \\\n    --data '{\"response\": \"x + x\", \"answer\": \"2*x\"}'\n```\n</code></pre> </li> <li> <p>In order to make your new function available on the LambdaFeedback platform, you have to register it via the Admin Panel. This is done by supplying its name, url (the same as the one above) and supported response types. </p> </li> </ol>"},{"location":"advanced/evaluation_functions/quickstart/#more-info","title":"More Info","text":"<ul> <li> <p>General Function Specification and Behaviour</p> <ul> <li>Function philosophy including deployment strategy</li> <li>Request/Response schemas and communication spec </li> <li>Base layer logic, properties and behaviour</li> </ul> </li> <li> <p>EvaluationFunctionUtils (python package)</p> <ul> <li>Error Reporting </li> <li>Schema validation</li> <li>Local testing</li> </ul> </li> </ul>"},{"location":"advanced/evaluation_functions/specification/","title":"Evaluation Function Specification","text":""},{"location":"advanced/evaluation_functions/specification/#introduction-and-philosophy","title":"Introduction and Philosophy","text":"<p>Functionality for each evaluation function is split up as follows:</p> <p>Universal function behaviour applicable to every function, such as the ability to run tests, return documentation and execute the evaluation is handled by the Base Layer. This is the docker image which is extended by every developed evaluation function.</p> <p>Functionality that may be required in more than one function (but not necessarily all), such as the ability to call already deployed functions and error reporting is handled by the evaluation_function_utils python package. This package comes pre-installed in the base layer, and can optionally be imported and called from the evaluation_function.</p> <p>Finally, specific comparison logic and handling of bespoke evaluation parameters is done in the custom evaluation_function, unique to each deployed instance. This is the logic that differenciates each function (comparing numbers, matrices, images, equations, graphs, text, tables, etc ...).</p>"},{"location":"advanced/evaluation_functions/specification/#commands","title":"Commands","text":"<p>Commands are handled by the base layer. They define a unified interface for interacting with all deployed evaluation functions on the web. Practically, these are specified in the \"command\" request header.</p> <p>Example</p> <p>To execute the <code>docs-user</code> command for a function, the following header would be specified alonside the http request made to the endpoint on which the function is made available:</p> <pre><code>```bash\ncurl --request GET \\\n--url https://c1o0u8se7b.execute-api.eu-west-2.amazonaws.com/default/isExactEqual \\\n--header 'command: docs-user'\n```\n</code></pre>"},{"location":"advanced/evaluation_functions/specification/#eval","title":"<code>eval</code>","text":"<p>This is the default command, used to compare a student's <code>response</code> and correct <code>answer</code>, given certain <code>params</code>. Outputs for this command depend on the success of the execution of the user-defined <code>evaluation_function</code>. If an error was thrown during execution, it is caught by the main handler and an error block is returned - otherwise, successful execution outputs are supplied under a <code>result</code> field.</p> <p>Output Structure: Successful evaluation</p> <pre><code>{\n    \"command\": \"eval\",\n    \"result\": {\n        \"is_correct\": \"&lt;bool&gt;\",\n\n        # Optional fields added by feedback generation (1)\n        \"feedback\": \"&lt;string&gt;\",\n        \"warnings\": \"&lt;array&gt;\"\n\n        # This output can also contain any number of fields given by `evaluation_function`\n    }\n}\n</code></pre> <ol> <li>See the Feedback Page for more information</li> </ol> <p>Output Structure: Error thrown during Execution</p> <pre><code>{\n    \"command\": \"eval\",\n    \"error\": {\n        \"message\": \"&lt;string&gt;\", # Always present\n\n        # This object can contain other number of additional fields\n        # passed through by the EvaluationException (1) for debugging e.g.:\n        \"serialization_errors\": [],\n        \"culprit\": \"user\",\n        \"detail\": \"...\"\n    }\n}\n</code></pre> <ol> <li>This is a custom error class from the evaluation-function-utils package, which developers are encouraged to use in order to output richer errors. See the Error handling section for more information.</li> </ol>"},{"location":"advanced/evaluation_functions/specification/#preview","title":"<code>preview</code>","text":"<p>This command is similar to <code>eval</code>, except it doesn't return whether an answer is correct or provide feedback. Instead, <code>preview</code> provides a way for students view their response after some pre-processing, e.g. as rendered LaTeX when using Sympy for symbolic algebra.</p> <p>This should be faster to compute than <code>eval</code>, allowing students to get live preview of their response.</p>"},{"location":"advanced/evaluation_functions/specification/#healthcheck","title":"<code>healthcheck</code>","text":"<p>This command runs and returns a summary three testing suites: requests, responses and evaluation. Request and response tests check that inputs and outputs to the function work correctly, and follow the correct syntax. Evaluation tests are unique to each evaluation function and test the actual comparison logic.</p>"},{"location":"advanced/evaluation_functions/specification/#docs-user","title":"<code>docs-user</code>","text":"<p>Command returns the <code>docs/user.md</code> file (base64 encoded)</p>"},{"location":"advanced/evaluation_functions/specification/#docs-dev","title":"<code>docs-dev</code>","text":"<p>Command returns the <code>docs/dev.md</code> file (base64 encoded)</p>"},{"location":"advanced/evaluation_functions/specification/#base-layer","title":"Base Layer","text":""},{"location":"advanced/evaluation_functions/specification/#file-structure","title":"File Structure","text":"<p>A standard evaluation function repository based on the provided boilerplate will have the following file structure:</p> <pre><code>app/\n    __init__.py\n    evaluation.py # Script containing the main evaluation_function\n    evaluation_tests.py # Unittests for the main evaluation_function\n    requirements.txt # list of packages needed for algorithm.py\n    Dockerfile # for building whole image to deploy to AWS\n\n    docs/ # Documentation pages for this function (required)\n        dev.md # Developer-oriented documentation\n        user.md # LambdaFeedback content author documentation\n\n.github/\n    workflows/\n        test-and-deploy.yml # Testing and deployment pipeline\n\nconfig.json # Specify the name of the evaluation function in this file\nREADME.md\n.gitignore\n</code></pre> <p>Warning</p> <p>If you want to split up function logic into different files, these must be added to the <code>Dockerfile</code>. This is so they are packaged with the built image when deployed. For example, if <code>evaluation.py</code> imports functionality from an <code>app/utils.py</code> file, then the following line must be added:</p> <pre><code>RUN pip3 install -r requirements.txt\n\n# Copy the evaluation and testing scripts\nCOPY evaluation.py ./app/\nCOPY evaluation_tests.py ./app/\n\n# Copy additional files\nCOPY utils.py ./app/\n\n# Copy Documentation\nCOPY docs/dev.md ./app/docs/dev.md\n</code></pre>"},{"location":"advanced/evaluation_functions/specification/#evaluationpy","title":"<code>evaluation.py</code>","text":"<p>The entire framework, validation and testing developed around evaluation functions is ultimately used to get to this file, or the <code>evaluation_function</code> function within it, to be more precise.</p>"},{"location":"advanced/evaluation_functions/specification/#the-evaluation_function","title":"The <code>evaluation_function</code>","text":""},{"location":"advanced/evaluation_functions/specification/#inputs","title":"Inputs","text":"<p>All evaluation functions are passed three arguments:</p> <ul> <li><code>response</code>: Data input by the user</li> <li><code>answer</code>: Data to compare user input to (could be from a DB of answers, or pre-generated by other functions)</li> <li><code>params</code>: Parameters which affect the comparison process (replacements, tolerances, feedbacks, ...)</li> </ul> <p>For evaluation functions that use Sympy or LaTeX for mathematical expressions, it's not always possible for a student to type the correct symbols. Instead we need to use simpler symbols. For example, \\(\\overline{U_{ij}}\\) cannot be written using standard sympy syntax, and therefore has to be substituted for something else, such as <code>\"u\"</code> or <code>\"U\"</code>.</p> <p>Therefore, evaluation functions using mathematical expressions should be able to handle multiple symbols to represent the same variable. To achieve this, every evaluation function is passed a <code>symbols</code> entry in <code>params</code>, to allow functions to convert a student's response:</p> <pre><code>{\n    \"response\": \"user input\",\n    \"answer\": \"model response to compare against\",\n    \"params\": {\n        \"symbols\": {...},\n        ... # params set by the teacher\n    }\n}\n</code></pre> <p><code>symbols</code> is a dictionary, where each key represents the main Sympy symbol (known as the <code>code</code>), and has two entries:</p> <ul> <li><code>latex</code>: the string used for rendering the symbol in LaTeX</li> <li><code>aliases</code>: a list of alternative Sympy symbols that can be used by the student to represent the <code>code</code>.</li> </ul> <p>For the example above with \\(\\overline{U_{ij}}\\), <code>symbols</code> would have the form:</p> <pre><code>{\n    ...\n    \"params\": {\n        \"symbols\": {\n            \"u\": {\n                \"latex\": \"\\\\overline{U_{ij}}\",\n                \"aliases\": [\"U\"]\n            }\n        }\n    }\n}\n</code></pre> <p>Note that in JSON, special characters need to be escaped, so the latex symbol above will have a double-backslash instead.</p> <p>Currently, the backend only supports one LaTeX symbol for multiple Sympy symbols. In future, this will be a many-to-many relationship.</p>"},{"location":"advanced/evaluation_functions/specification/#outputs","title":"Outputs","text":"<p>The function should output a single JSON-encodable dictionary. Although a large amount of freedom is given to what this dict contains, when utilising the function alongside the lambdafeedback web app, a few values are expected/able to be consumed:</p> <p><code>is_correct: &lt;bool&gt;</code>: Boolean parameter indicate whether the comparison between <code>response</code> and <code>answer</code> was deemed correct under the parameters. This field is then used by the web app to provide the most simple feedback to the user (green/red).</p> <p>Info</p> <p>More standardised function outputs that the frontend can consume are to come</p>"},{"location":"advanced/evaluation_functions/specification/#error-handling","title":"Error Handling","text":"<p>Error reporting should follow a specific approach for all evaluation functions. If the <code>evaluation_function</code> you've written doesn't throw any errors, then it's output is returned under the <code>result</code> field - and assumed to have worked properly. This means that if you catch an error in your code manually, and simply return it - the frontend will assume everything went fine. Instead, errors can be handled in two ways:</p> <p>Letting <code>evaluation_function</code> fail: On the request handler in the Base Layer, the call to evaluation_function is wrapped in a try/except which catches any exception. This causes the evaluation to stop completely, returning a standard message, and a repr of the exception thrown in the <code>error.detail</code> field.</p> <p>Custom errors: If you want to report more detailed errors from your function, use the <code>EvaluationException</code> class provided in the evaluation-function-utils package. These are caught before all other standard exceptions, and are dealt with in a different way. These provide a way for your function to throw errors and stop executing safely, while supplying more accurate feedback to the front-end.</p> <p>Example</p> <p>It is discouraged to do the following in the evaluation code: <code>python     if something.bad.happened():         return {             \"error\": {                 \"message\": \"Some important message\",                 \"other\": \"details\",             }         }</code></p> <pre><code>As this causes the actual function output (by the AWS lambda function) to be:\n```json\n{\n    \"command\": \"eval\",\n    \"result\": {\n        \"error\": {\n            \"message\": \"Some important message\",\n            \"other\": \"details\"\n        }\n    }\n}\n```\n\nInstead, use custom exceptions from the [evaluation-function-utils](module.md#errors) package.\n```python\nif something.bad.happened():\n    raise EvaluationException(message=\"Some important message\", other='details')\n```\n\nAs the actual function output will look like:\n```json\n{\n    \"command\": \"eval\",\n    \"error\": {\n        \"message\": \"Some important message\",\n        \"other\": \"details\"\n    }\n}\n```\n\nThis immediately indicates to the frontend client that something has gone wrong, allowing for proper feedback to be displayed.\n</code></pre>"},{"location":"advanced/evaluation_functions/specification/#evaluation_testspy","title":"<code>evaluation_tests.py</code>","text":""},{"location":"advanced/evaluation_functions/specification/#documentation","title":"Documentation","text":"<p>Two essential and required documentation files are copied over during the creation of the evaluation function docker image. These are subsequently served by the function under the <code>docs-dev</code> and <code>docs-user</code> commands, to be accessed by this documentation website, as well as for embedding on LambdaFeedback. For more information about the markdown syntax, please refer to the following sources:</p> <ul> <li>MkDocs Documentation</li> <li>MkDocs-Material Documentation</li> </ul>"},{"location":"advanced/evaluation_functions/specification/#docsdevmd","title":"<code>docs/dev.md</code>","text":""},{"location":"advanced/evaluation_functions/specification/#docsusermd","title":"<code>docs/user.md</code>","text":""},{"location":"advanced/response_areas/overview/","title":"Overview of response areas","text":""},{"location":"advanced/response_areas/overview/#list-of-response-areas","title":"List of response areas","text":"<p>The list of response areas is maintained in the Teacher section here. In the Developer area (here), the behaviour of the response areas is documented.</p>"},{"location":"advanced/response_areas/overview/#data-types-when-submitting-empty-responses-default-behaviour","title":"Data types when submitting empty responses (default behaviour)","text":"<p>If a user submits a response without inputing a value, the response areas convert the responses as follows before passing them to the evaluation functions:</p> Input Value Type Default Value Comment number undefined [Behaviour needs updating] string undefined [Behaviour needs updating] MATRIX <code>\" \"</code> empty string in all cells TABLE <code>\" \"</code> empty string in all cells MULTIPLE CHOICE <code>False</code> all choices set to false"},{"location":"releases/","title":"Releases","text":""},{"location":"releases/#release-20240914","title":"Release 2024/09/14","text":"<ul> <li>b134-ipados-ios-safari-like-flag-problem-help-off-the-page - fixed scrolling of problem sets when using iPadOS or iOS Safari</li> <li>b439-disable-download-when-no-pdf-available - improved behavior of the \u201cDownload set\u201d drop-down button</li> <li>b407-all-questions-published-when-publishing-one - corrected version history page to display accurate data when viewing past question versions</li> <li>b434-ui-redesign-tweaks - additional tweaks to the user interface</li> <li>b442-bring-back-sets-download-options - restored \u201cSet Download\u201d drop-down button that was removed during the UI redesign</li> <li>b447-aws-db-backups-stopped - fixed the database backup issue</li> <li>b451-display-modules-even-if-sets-are-hidden - updated the system so students can view their modules, even if no sets are available </li> </ul>"},{"location":"releases/#release-20240910","title":"Release 2024/09/10","text":"<ul> <li>b413-authentication-failures - code cleanup for updated authentication to avoid logging out (see b413 in 2024/08/23)</li> <li>b438-enable-canvas-for-all-users - enabled canvas for all users (see b343 in 2024/06/28)</li> <li>b441-custom-milkdown-theme-bug - adjusted the new Milkdown theme to improve compatibility with math mode</li> </ul>"},{"location":"releases/#release-20240904","title":"Release 2024/09/04","text":"<ul> <li>b441-revert-to-nord-theme - undo milkdown theme switch until math block is fixed</li> </ul>"},{"location":"releases/#release-20240903","title":"Release 2024/09/03","text":"<ul> <li>b386-provide-drop-down-list-for-ra-default-lambda-function</li> </ul>"},{"location":"releases/#release-20240902","title":"Release 2024/09/02","text":"<ul> <li>b398-upgrade-student-module-list - add new card view to module list student page</li> <li>b430-fix-redesign-bugs - add proper error handling to teacher pages when not a teacher</li> <li>b435-remove-env-from-git - remove .env file from git as it shouldn't be checked into vcs</li> </ul>"},{"location":"releases/#release-20240828","title":"Release 2024/08/28","text":"<ul> <li>b383-check-for-existing-module-name - Check if module name already exists when creating new module</li> <li>b383_do_not_query_without_module_id - do not run query from header without module id </li> <li>b393-canvas-stored - Store canvas in database</li> <li>b425-studentmodule-and-studentmodules-api-retrieve-hidden-sets - do not retrieve hidden sets for students</li> <li>b427_display_pdf_errors_after_set_publish - Display PDF error message when publishing whole set</li> <li>b428-bulk-rollover-qa-comments - updates to bulk rollover feature</li> <li>b431-add-sentry - Add Sentry error monitoring</li> <li>b433-not-possible-to-enrol-students - fix to student enrollment</li> <li>b436-fix-instance-swapper - fix instance swapper</li> </ul>"},{"location":"releases/#release-20240823-2","title":"Release 2024/08/23 - 2","text":"<ul> <li>b380-fix-tables - Table paging fix</li> <li>b379-disappearing-r-at-beginning-of-line-milkdown - fix disappearing 'R' at beginning of line milkdown</li> <li>b413-force-renew - authentication update to avoid logging out</li> <li>b429_deleting_cases_and_tests_qa - ensure feedback case order is maintained</li> </ul>"},{"location":"releases/#release-20240823","title":"Release 2024/08/23","text":"<ul> <li>b413-grounded - updates to the authentication flow</li> </ul>"},{"location":"releases/#release-20240822-2","title":"Release 2024/08/22 - 2","text":"<ul> <li>b402-create-table-view - table view added to the teacher module view</li> <li>b406-prepare-ui-update - changes in the user interface</li> </ul>"},{"location":"releases/#release-20240822","title":"Release 2024/08/22","text":"<ul> <li>b356-delete-all-questions-in-set-not-handled-gracefully - create blank question when all others are deleted</li> <li>b409-module-bulk-rollover - bulk creation of new module instances (for admins)</li> <li>b417-set-part-to-a-when-switching-question - in teacher mode, when switching a question, always display part (a)</li> <li>b419-deleting-case-is-causing-feedbacks-to-shift-incorrectly - display correct remaining cases after deleting one</li> <li>b423-pdf-generation-displays-different-error-first-time - first PDF generation message consistent with follow up messages</li> </ul>"},{"location":"releases/#release-20240807","title":"Release 2024/08/07","text":"<ul> <li>b375-correct-tex-and-pdf-for-solutions - PDF generation improvements</li> <li>b412-export-import-wrong-order-of-parts - ensure correct part and response-area order when importing</li> <li>b413-authentication-failures - part 2 - prevent application logouts</li> <li>b416-download-set-as-json-downloads-wrong-set - ensure correct set when exporting JSON</li> </ul>"},{"location":"releases/#release-20240802","title":"Release 2024/08/02","text":"<ul> <li>b391-milkdown-fault-if-latex-on-last-line - fixed milkdown bug - if text ends with latex, it rendered raw but now renders properly.</li> <li>b415-guidance-time-suggestion-feature-by-colin - guidance time suggestion (using Machine Learning based on our database of content)</li> </ul>"},{"location":"releases/#release-20240726","title":"Release 2024/07/26","text":"<ul> <li>b369-guidance-text-on-enrollment - add a guidance text when adding students or teachers</li> <li>b381-not-possible-to-add-multiple-teachers - allow to add multiple teachers</li> <li>b410-open-doc-links-in-new-tab - open external links in a new tab</li> <li>b413-authentication-failures - fixed problems with application logouts</li> </ul>"},{"location":"releases/#release-20240724","title":"Release 2024/07/24","text":"<ul> <li>b378-admin-module-instance-breadcrumbs-incorrect - corrected the application header (for Admin module instance page)</li> </ul>"},{"location":"releases/#release-20240723","title":"Release 2024/07/23","text":"<ul> <li>b132 - security update for milkdown</li> <li>b366-non-imperial-users-to-be-able-to-log-in - non-Imperial logins enabled</li> <li>b374-admin-analytics-evaluation-functions - analytics for evaluation function errors</li> <li>b387-import-question-does-not-import-worked-solutions - corrected question export with solutions</li> <li>b388-tutorials-and-solutions-steps-messed-up - corrected sorting of solution branches</li> </ul>"},{"location":"releases/#release-20240718","title":"Release 2024/07/18","text":"<ul> <li>b392-essay-code-ras - add two new response area types: code and essay</li> <li>b396-better-feedback-box - improve the feedback box UI and accessibility</li> </ul>"},{"location":"releases/#release-20240716","title":"Release 2024/07/16","text":"<ul> <li>b395-vertical-text-align - remove excess margin from top part of question</li> </ul>"},{"location":"releases/#release-20240628","title":"Release 2024/06/28","text":"<ul> <li>b258-performance-analyse-db - faster response from DB queries</li> <li>b343-canvas - student canvas in beta mode (hidden by default)</li> <li>b351-teacher-module-page-ui-upgrades - Teacher module home page UI upgrades (tabs added)</li> <li>b357-upgrade-aws-sdk-v2-to-v3 - software library updates</li> <li>b359-generate-tex-file - upload/download whole Sets as LaTeX files</li> </ul>"},{"location":"releases/#release-20240614","title":"Release 2024/06/14","text":"<ul> <li>b305-export-whole-set - import/export whole sets</li> <li>b334-upgrade-node-next-nest - library updates</li> </ul>"},{"location":"releases/#release-20240529","title":"Release 2024/05/29","text":"<ul> <li>b352-support-to-eval-function-20-get-all-routes-by-getroutes - evaluation function deployment (check existing routes)</li> <li>b353-question-import-filter-out-unicode-characters - remove character (U-2006) on json import</li> <li>b354-double-confirm-on-confirmation-pop-ups - fix confirm button on modals in teacher mode</li> </ul>"},{"location":"releases/#release-20240524","title":"Release 2024/05/24","text":"<ul> <li>b97-remove-all-references-to-mongodb - remove code linking to legacy databases</li> <li>b243-add-question-id-to-the-url - add question identifier to the url</li> <li>b285-move-module-instance-drop-down-to-left-to-replace-the-instance-label - more user-friendly module instance selection</li> <li>b304-milkdown-element-in-admin-that-will-display-on-home-page - add an administrator page to configure a home page banner</li> <li>b330-modal-update - question version switch: allow teacher either to save or discard existing draft</li> <li>b349-support-to-eval-function-20-ensure-deployments - evaluation functions: production and non-production versions</li> </ul>"},{"location":"releases/#release-20240515","title":"Release 2024/05/15","text":"<ul> <li>b250-expression-ra-scan-mode-copy-and-paste - allow copy and paste and other improvements in the scan mode functionality</li> <li>b314-remove-experimental-from-ra-panel - \"experimental\" from the photo upload and handwritting labels removed</li> <li>b338-create-a-new-set-when-creating-a-module - a default set automatically creating when a new module is created</li> <li>b342-do-not-generate-pdf-when-creating-new-question - prevent PDF generation when a new question is added</li> <li>b345-after-pdf-generation-extraction-cleanup - a technical improvements into the PDF generation</li> </ul>"},{"location":"releases/#release-20240426","title":"Release 2024/04/26","text":"<ul> <li>b230-pdf-generation-in-a-separate-lambda-function - PDF generation is faster, more secure, and frees up bandwidth on the main server.</li> <li>b328-improve-expression-ui-in-tests - fix expression response area preview in tests tab</li> <li>b331-work-solutions-empty-content-not-handled-as-no-work-solutions - work solutions and structured tutorials buttons not to be displayed if the content is empty</li> <li>b339-accessible-response-area-feedback - displaying error returned by evaluation functions in a user-friendly format</li> <li>b340-remove-input-type-changed-warning-on-new-ra - do not display warning about response area type change for new response areas</li> </ul>"},{"location":"releases/#release-20240419","title":"Release 2024/04/19","text":"<ul> <li>337-individual-tests-always-fail - fix individual reponse area test runs</li> <li>327-consolidate-response-area-components - improvements for better response area consistency</li> </ul>"},{"location":"releases/#release-20240321","title":"Release 2024/03/21","text":"<ul> <li>b332-table-smart-resizing - resize table width based on the screen size</li> </ul>"},{"location":"releases/#release-20240319","title":"Release 2024/03/19","text":"<ul> <li>b286-ra-analytics-when-config-is-changed - Fix aggregates in stats</li> <li>b311-expression-area-layout-issues - Improve expression RA layout</li> <li>b325-populate-new-tests-with-the-answer - Populate new tests with the answer</li> <li>b322-enable-live-preview-in-teacher-mode - Attempt to enable live preview in teacher mode</li> <li>b35/b329-simplify-response-components - Simplificaton of Response Type components code</li> </ul>"},{"location":"releases/#release-20240313","title":"Release 2024/03/13","text":"<ul> <li>b84-legacy-content-db-tables - DB updates. No change to UX</li> <li>b315-include-answer-when-importing-case - ensure the answer value is included when importing a case from stats</li> <li>b320-response-type-allowlist - improves modular response areas</li> <li>b325-populate-new-tests-with-the-answer - prepopulate the answer by the correct answer when creating a new test</li> <li>b326-question-alignments - imroves alignments on the edit question page</li> </ul>"},{"location":"releases/#release-20240308","title":"Release 2024/03/08","text":"<ul> <li>b283-table-with-1-column-layout - improves table layout</li> <li>b324-show-required-error-on-number-input-wizard - improves number input validations</li> </ul>"},{"location":"releases/#release-20240305","title":"Release 2024/03/05","text":"<ul> <li>b301-redesign-part-response-areas-and-text-between-them - teachers can drag response areas while surrounding text stays in place, and merges where necessary.</li> <li>b35/b310-modular-response-areas-phase-6-cleanup - completes modular response areas. Code improvements and removing legacy tables.</li> <li>b323-delete-empty-answer-in-ra-panel - ensure delete works in answer box in response area panel</li> </ul>"},{"location":"releases/#release-20240304","title":"Release 2024/03/04","text":"<ul> <li>b319-survey-promotion-banner-on-home-page - add a banner onto the landing page advertising a survey with a link</li> </ul>"},{"location":"releases/#release-20240301","title":"Release 2024/03/01","text":"<ul> <li>b287-limit-access-to-sets-published-outside-of-current-date - ensure access to Sets follows release rules, including via URL</li> <li>b303-redirect-help-to-userdocs - redirect lambdafeedback.com/help to user documentation and lambdafeedback.com/[module slug] to the module page</li> <li>b318-url-for-survey - redirect lambdafeedback.com/survey</li> </ul>"},{"location":"releases/#release-20240229","title":"Release 2024/02/29","text":"<ul> <li>b35/b308-modular-response-areas-phase-4-custom-response-types - allow admin to dynamically create and manage new response types</li> <li>b35/b309-modular-response-areas-phase-5-migration - migrate all existing response types to the new modular type</li> <li>b313-always-display-post-ra-text-in-pdf-but-not-in-stats-mode - include all text in PDF (including after first response area)</li> </ul>"},{"location":"releases/#release-20240226","title":"Release 2024/02/26","text":"<ul> <li>b35-number-input-nan - fix handling of non-number input in the number answer wizard</li> <li>b317-no-header-refetch-on-mount - avoid unwanted refetch when resizing browser window on a set page</li> <li>b35/b307-modular-response-areas-phase-3-all-writes - start writting new and edited Response Area's Response to the new modular table</li> <li>b274-when-deleting-a-question-display-loading-message - display \"loading\" message when deleting a question</li> </ul>"},{"location":"releases/#release-20240220","title":"Release 2024/02/20","text":"<ul> <li>b290-the-final-answer-button-is-displayed-even-if-there-is-no-final-answer - fix: only display 'final answer' button when there is content to show</li> <li>b297-give-error-if-creating-module-with-same-name-as-deleted-module - improved formatting of error messages</li> <li>b299-legacy-content-db-tables-ra-contents - DB updates. No change to UX.</li> <li>b302-modal-warning-before-disabling-branching - warning modal when disabling branching in worked solutions and structured tutorials</li> <li>b35/b306-modular-response-areas-phase-2-new-modular-type - backend updates for modular response areas.</li> </ul>"},{"location":"releases/#release-20240215","title":"Release 2024/02/15","text":"<ul> <li>b35/b295-modular-response-areas-phase-1-switchless-frontend - a technical improvement to the response area building blocks in the code, so that it is easier, more intuitive and more straight forward to add new response areas</li> </ul>"},{"location":"releases/#release-20240213","title":"Release 2024/02/13","text":"<ul> <li>b271-unify-modals - unified modals to use same style</li> <li>b294-check-imports-from-material-ui - prevent importing whole library when importing an icon</li> <li>b300-delete-ra-add-warning-into-the-modal-that-the-text-below-the-ra-will-be-deleted-as-well - when deleting a response area (RA), warning modal that text below RA will also be deleted</li> </ul>"},{"location":"releases/#release-20240125","title":"Release 2024/01/25","text":"<ul> <li>b240-structured-tutorial-component-upgrade - converted structured tutorial to use the same structure and logic as worked solutions</li> </ul>"},{"location":"releases/#release-20240124","title":"Release 2024/01/24","text":"<ul> <li>b273-limit-access-to-unpublished-sets - ensure no student access to hidden sets via a url</li> <li>b277-milkdown-first-non-markdown-update-is-ignored - milkdown fix to for edge cases that were not saved (single character; deleting selection).</li> <li>b279-table-with-1-column - wider columns for table response areas with one column</li> <li>b280-change-response-colour-to-white - specifically for 'riskAssessment' evaluation function: display feedback for incorrect answer in white colour</li> <li>b281-tweaks-to-ra-analytics - tweaks to response area analytics</li> </ul>"},{"location":"releases/#release-20240116","title":"Release 2024/01/16","text":"<ul> <li>b272-legacy-db-tables-tutorial-sections - refactoring the database. No change to UX.</li> </ul>"},{"location":"releases/#release-20240110","title":"Release 2024/01/10","text":"<ul> <li>b264-untangle-changes - a technical improvement to make the milkdown wrapper code clearer.</li> <li>b247-re-generate-pdf-after-deleting-a-question - an improvement so that the PDF is automatically re-generated when a published question is deleted</li> <li>b158-change-prod-bucket-to-prod-not-staging - a technical change so that imported images and generated PDF files are saved in the correct AWS bucket dependently on the environment (production, staging or development)</li> <li>b232-ra-analytics-visual-alignment - a change to display response area analytics correctly aligned with labels</li> <li>b77-published-question-change-of-input-type - an improvement to allow changing of the input type on the response area that was already published.</li> <li>b262-legacy-content-db-tables-part-contents - refactoring the database. No change to UX.</li> <li>b245-question-numbering-is-sometimes-wrong-on-the-student-module-home-page - a correction so that question numbers are reconciled after a question is deleted</li> <li>b141-update-link-in-modal - a correction of the link from the modal (which appears when deleting a response area) to the user documentation</li> <li>b211-response-area-preview-remove-border - a change in the question preview in the teacher mode so that it is displayed in the same way as in the student mode</li> <li>b103-milkdown-slow-rendering - a technical change to speed up testing in local development environments</li> </ul>"},{"location":"releases/#release-20231215","title":"Release 2023/12/15","text":"<ul> <li>b103-milkdown-slow-rendering - developers can set a flag in local environment to speed up rendering pages with milkdown</li> <li>b235-content-with-hash-copied-across - prevent milkdown copying content with hash from one question to another</li> <li>b244-fix-notes-saving-in-the-student-mode - ensure student notes are visible including when switching from teacher to student mode</li> <li>b248-remove-unwanted-content-from-pdf - removed legacy response area pre-text and post-text from PDFs</li> <li>b251-post-a-reply-in-one-click - post a reply to a comment with one click</li> <li>b256-include-frequency-data-when-downloading-csv - correction to csv file generation for question stats, to include question numbers and frequency</li> <li>b260-number-and-unit-ra-do-not-align-with-pre-text-in-student-mode - align pre-text in the response area with number and units in student mode</li> <li>b261-master-content-sometimes-not-saved - ensure master content entered by the user is saved after publishing a question (not copied from the published version)</li> </ul>"},{"location":"releases/#release-20231208","title":"Release 2023/12/08","text":"<ul> <li>b246-rendering-of-list-of-sets-in-teacher-mode-takes-long-time - an improvement to render list of sets in teacher mode quicker</li> <li>b255-recover-lost-marked-parts - further corrections to DB. Some question parts were not marked correctly as DONE for questions imported from JSON between 13/10/23 and 5/12/24.</li> </ul>"},{"location":"releases/#release-20231205","title":"Release 2023/12/05","text":"<ul> <li>b242-mark-as-done-copied-across-questions - correction to DB submissions for questions imported from JSON between 13/10/23 and 5/12/24, which were linked together incorrectly.</li> </ul>"},{"location":"releases/#release-20231204","title":"Release 2023/12/04","text":"<ul> <li>b224-add-guidance-to-help - guidance on a question, already visible to users in a widget on top-right, is now also visible with the support material below the question   </li> <li>b228-legacy-content-db-tables-master-content - refactoring the database. No change to UX.</li> <li>b109-expression-input-tweaks - tweaks to the few improvements in the expression response area (555 in 2023/05/26): icons, placeholder, upload size limit.</li> <li>b249-selected-question-index-lost - editor UX, improve the robustness of: when a question is added or published, ensure that question remains in focus to the user.</li> <li>b241-link-from-feed-needs-updating - corrected a URL linking from the teacher feed to a question.</li> </ul>"},{"location":"releases/#release-20231113","title":"Release 2023/11/13","text":"<ul> <li>b227-correct-set-estimates - time format improvement for displaying time estimate for each set in the list of set</li> <li>b233-publish-set-pdf-generation - an adjustment to the Publish whole set functionality to generate PDF after the confirmation button is clicked   </li> </ul>"},{"location":"releases/#release-20231109","title":"Release 2023/11/09","text":"<ul> <li>b186-add-time-estimates-for-each-set-in-teacher-mode - added set estimates which is calculated as summary of estimates of all questions</li> <li>b204-input-symbols-empty-row-should-not-be-validated - an improvement to prevent validation of input symbols when a new row to enter input symbols is added</li> <li>b206-input-symbols-with-spaces - an improvement to remove potential spaces entered into the input symbol alternatives (the values must be seaparated by comma without spaces to make sure they work correctly)</li> <li>b226-update-question-split-prisma-transaction - extended Prisma timeout when a question is being saved or publish</li> <li>b225-bug-in-timed-release-for-pm-times - a change to display hours in 24 hour format when displaying time</li> </ul>"},{"location":"releases/#release-20231103","title":"Release 2023/11/03","text":"<ul> <li>b214-admin-dashboard-carry-on - admin dashboard improvements:</li> <li>A drop down list to select the time period for the user access events graph</li> <li>The last part of the graph lines are dotted to make clear that last values are subject to change</li> </ul>"},{"location":"releases/#release-20231101","title":"Release 2023/11/01","text":"<ul> <li>b207-pressing-enter-in-the-flag-textbox - an improvement so that when a user is using an expression response area and he attempts to submit a comment (or flag a problem) at the same time by clicking the enter, then only the comment (or the problem message) is submitted (and not the answer in the response area)</li> <li>b213-question-export-import-to-handle-mp3 - an improvement to allow to export and import questions containing an audio (or more audios)</li> <li>b217-remove-header-text-on-module-page-for-students - removed the header on the student module page as it is not needed</li> <li>b215-do-not-update-or-delete-notes-in-teacher-preview - an improvement to prevent submitting student solutions in the teacher preview mode</li> <li>b208-unposted-comments - an imrovement to handle the scenario when a user enters a comment and then, withouth submitting it, selects different question (the comment was copied to the newly selected question which is not a desired feature)</li> <li>b209-zero-comments-invite-comments - an improvement to open comments when there are no comments to invite users to comment</li> </ul>"},{"location":"releases/#release-20231020","title":"Release 2023/10/20","text":"<ul> <li>b202-ensure-eval-function-defaults-for-new-response-areas - an improvement so that evaluation function parameters are set to default values when creating a new response area</li> <li>b71-analytics-tweaks-teacher-view - the students list, view and contact pages were merged into a single page: - Filters by email and/or by access are available to filter the single list of students - A click on a student email opens a view which displays the same analytics the student can see   </li> <li>b162-analytics-tweaks-stats-modal - improvements in the analytics view: - Colour is indicating the answer's case colour, if any, or the correct/incorrect default colour - Checkmark is indicating that the answer was correct - More options added to allow the user to agregate student answers   </li> <li> <p>b67-simplify-stats-interaction - few changes to response area statistics in the teacher mode:</p> </li> <li> <p>The case is imported straight into the relevant response area</p> </li> <li> <p>The response area menu has a new button EXPLORE so that the teacher can see the statistics per response area     </p> </li> <li> <p>b192-reaction-count-one-hour-challenge - users can see the individual count of each type of reaction</p> </li> </ul> <p></p> <ul> <li>b183-activity-feed-make-clear-there-are-more-flags-than-5 - make clear to the user how many flags and comments there are in total as there might be more than 5 displayed on the teacher dashboard</li> </ul> <p></p> <ul> <li>b110-import-multiple-jsons-from-a-single-zip - allows to import more questions from one zip file. This includes questions with attached pictures. Import of questions with attached audio files is yet to come.</li> <li>b205-admin-analytics-initial-work - first version of the admin dashboard is now provided. It includes information about number of current users, questions and user access events</li> </ul>"},{"location":"releases/#release-20231012","title":"Release 2023/10/12","text":"<ul> <li>b180-prod-freezing-and-restarting - increasing allocated memory to accommodate multiple users triggering heavy processes (PDF compilation)</li> <li>b193-implement-auto-scaling-on-infrastructure - Infrastructure upgrades for larger scale usage.</li> <li>b124-question-export-with-pictures-fails-sometimes-on-cors-error - forcing Chrome to refresh media retriaval from S3 bucket to make sure correct headers are attached to the response</li> <li>b199-migration-script-for-physics-expression-ra - DB migration for legacy content.</li> <li>b194-create-set-and-first-question-improvement - new set automatically has a blank question ready.</li> <li>b197-not-possible-to-delete-a-question - increase timeout when deleting a question</li> <li>b143-more-info-in-modal-when-publish-whole-set - displaying list of questions that will be published in a modal before publishing whole set.</li> <li>b144-modal-to-check-before-removing-branches - a warning message is displayed before a branch from worked solutions is deleted</li> </ul>"},{"location":"releases/#release-20231005","title":"Release 2023/10/05","text":"<ul> <li>b136-change-to-breadcrumbs - an improvement to remove module instances from teachers and students breadcrumbs as they do not link to any pages</li> <li>b188-add-information-when-rendering-a-new-question - adding information that a question is being created when adding a new question</li> <li>b189-failed-fetching-your-problem-set-message-appearing-when-it-should-not - a warning message 'Failed fetching your problem set' is to be displayed only if there is an error</li> </ul>"},{"location":"releases/#release-20231003","title":"Release 2023/10/03","text":"<ul> <li>b191-expression-response-area-defaults - an improvement so that when creating a new response area of type EXPRESSION, the default values are set to:</li> <li>TRUE for Live preview</li> <li>FALSE for Display input symbols</li> <li>FALSE for Include in PDF</li> <li>TRUE for Enable handwriting input</li> <li>TRUE for Enable photo upload</li> <li>b187-support-materials-access-enhancements - enhancements to the support materals student access configuration:</li> <li>A new button event was added to record whether students proceeded or cancelled after a warning message appeared when a student tried to open a support material</li> <li>Labels were renamed to make their meaning clearer (e.g. 'Open' was changed to 'Available' and 'Hidden' to 'Unavailable')</li> <li>When a question part is marked as done, then no warning is displayed to a student when opening a support material (even if marked as Open with warnings)</li> </ul>"},{"location":"releases/#release-20230929","title":"Release 2023/09/29","text":"<ul> <li>b148-problem-adding-new-question-after-changing-name-of-current-question - an improvement so that a user cannot start changing newly added question (e.g. changing name) until all processes are finished and therefore preventing these changes to be wiped out.</li> <li>b161-renaming-question-straight-after-making-it - this is the same problem as b148</li> <li>b151-quote-marks-can-break-flags - an improvement so that double-quote marks, if used in a text, are displayed correctly in the generated csv file</li> <li>b164-grade-param-type-changed-reverts-to-string-when-value-is-empty - an improvment to identify a number as a number in the grade parameters, so that the type is displayed number and not as string</li> <li>b166-no-template-questions-in-the-list - an improvement to display all existing template questions in the list (when adding a new question from a template)</li> <li>b190-draw-area-width-keeps-changing - an improvement to stop the drawing area changing its width when a warning message is displayed that the writting cannot be interpreted</li> </ul>"},{"location":"releases/#release-20230927","title":"Release 2023/09/27","text":"<ul> <li>b157-new-eval-function-reset-parameters - improvement in the response area panel, when the evaluation function is changed, then the default evaluation function parameters are re-set.</li> <li>b167-teachers-are-sent-to-the-most-recent-instance-on-the-module-homepage-even-when-they-dont-have-access-they-should-be-sent-to-the-most-recent-one-that-they-have-access-to</li> <li>b163-failed-fetching-your-problem-set-displayed-on-every-page-load - an improvement so that the warning message only appears when the fetch returns an error.</li> <li>b149-restrict-access-to-worked-solutions - restrict student access to support materials on set level and on question level.   </li> <li>b165-preview-not-the-same-as-student-view - an improvement to displaye pre-text, value and post-text aligned horizontally in the response area student view</li> </ul>"},{"location":"releases/#release-20230908","title":"Release 2023/09/08","text":"<ul> <li>128-feedback-area-does-not-support-latex-rendering - Feedbacks returned by the evaluation function are displayed using latex editor.</li> </ul>"},{"location":"releases/#release-20230907","title":"Release 2023/09/07","text":"<ul> <li>b155-aws-ending-support-for-nodejs-14-in-aws-lambda - A clear-up of an outdated library.</li> <li>b153-pressing-enter-in-a-number-response-adds-new-line-to-the-response - Handle Enter in the response area as a submission of the answer.</li> <li>b139-archive-feature-enhancements - Enancements of module as module instance archiving.</li> <li>b68-cleaning-up-the-editor - many ui enhancements in the question editing page</li> <li>b115-case-color-under-feedback-tab-for-response-area-is-not-functional - The custom colour for feedbacks is now displayed correctly.</li> </ul>"},{"location":"releases/#release-20230830","title":"Release 2023/08/30","text":"<ul> <li>b33-audio-clips - in the content editor, drag-and-drop an audio file, and it will add a sound (e.g. narration) to the content.</li> <li>b145-xetex-pdf - PDFs are now compiled with xelatex, not PDFlatex.</li> <li>b150-extracting-code-from-listener-into-callback-fn - stats for typed expressions now record full submissions only (not keystrokes)</li> </ul>"},{"location":"releases/#release-20230822","title":"Release 2023/08/22","text":"<ul> <li>b147-time-guidance-is-currently-very-small - An adjustment after upgrading one of the libraries which caused the time guidance to shrink.</li> <li>b142-module-clone-enhancements - An enhancemnt to include links to already generated PDF files for all sets in the cloned module instance.</li> <li>b138-503-error - An enhancement to navigate to the teacher module / module instance after clicking Cancel button in the Set Metadata page.</li> </ul>"},{"location":"releases/#release-20230818","title":"Release 2023/08/18","text":"<ul> <li>b114-matrix-input-centering-in-teacher-mode-but-not-in-student-mode - The Check button for matrix questions in the response area panel is now vertically centred in the student view.</li> <li>b140-response-area-pre-text-doubled - The legacy response area pre-text was removed from the student view.</li> </ul>"},{"location":"releases/#release-20230816","title":"Release 2023/08/16","text":"<ul> <li>b127-cloned-instances-are-missing-tutorials-and-worked-solutions - An enhancement of the module cloning functionality to include worked solutions and tutorials.</li> <li>b125-when-publishing-question-update-the-student-view - An enhacement so that when a teacher publishes a question then, this question is visible in the student view without having to refresh the browser or log out and back in again.</li> <li>b83-revisit-set-archiving - This is a technical improvement of the existing functionality to archive sets so that it is done in the same way as archiving of other entities. It has no visible any impacts to a user.</li> <li>b111-archive-module-instance-option - A new feature to allow to archive a module instance. This feature is only available to an administrator.</li> <li>b126-archive-module-option - A new feature to allow to archive a module. This feature is only available to an administrator.</li> <li>b108-error-when-clicking-add-question-button-while-inside-part-content-box - Technical improvement. Upgrade of some libraries (Material UI) to prevent errors caused by issues in the older library version.</li> </ul>"},{"location":"releases/#release-20230721","title":"Release 2023/07/21","text":"<ul> <li>b101-tests-run-from-the-configure-panel-have-the-islatex-parameter-set-to-true - A correction to the settings on the new Expression input (see 555 in 2023/05/26). When calling an evaluation function, the <code>is_latex</code> parameter dependends on the type of input (type/draw/scan).</li> <li>b120-PDF-skill-time-info - PDFs now include information on skill level, time estimates, and guidance below the question title and above the question content.</li> <li>b122-multi-year-carry-on - extended UI features referring to module instances (see b82 below).</li> </ul>"},{"location":"releases/#release-20230719","title":"Release 2023/07/19","text":"<ul> <li>b82-multi-year-duplicate-module-instance-and-link-entities - new feature to clone module instances   </li> <li>b118-multi-year-tidy-up - multi module feature enhancements such as sorting and filtering module instances on the admin Module page</li> </ul>"},{"location":"releases/#release-20230714","title":"Release 2023/07/14","text":"<ul> <li>b72-multi-year-module-instances-introduction - All Modules now exist as an 'Instance' of a Module, in preparation for allowing multiple Instances. The UI navigation is updated to handle Module Instances.</li> <li>b81-show-preview-of-ra-in-input-type-select - Selecting an Input Type for a Response Area: a searchable preview of Input Types improves the UX: users see the preview while selecting.   </li> <li>b91-prevent-multiple-blank-questions - When a question is added, the 'add quesiton' button is temporarily disabled while the application updates.</li> <li>b112-bug-the-tab-navigation-bar-at-the-top-disappears - Editor tabs are pesistent including during keyboard navigation</li> <li>b116-pdf-display-between-ras - PDF generation: for multiple Response Areas in a Part, the order is now always correct</li> </ul>"},{"location":"releases/#release-20230622","title":"Release 2023/06/22","text":"<ul> <li>b39-new-editor-menus - question editor area menus have been converted into tabs. Other improvements have also been made to the editor layout inlcuding switching between teacher and student mode and staying on the same question. </li> <li>b62-add-tabs-to-reponse-area-panel - the Response Area panel is grouped into tabs that aid navigation and encourage a workflow that matches the way teachers think. Other layout improvements were also made within the tabs. </li> <li>b79-input-type-on-published-ra-should-not-be-editable - input type cannot be changed after publishing (see 598 here 2023/06/05).</li> <li>b85-incorrect-required-error-message - enhanced validation for number 0 in numeric response area.</li> <li>588-question-import-export-handle-images - import export includes images; a zip file is used to combine the JSON and the images.</li> <li>601-parameter-defaults-for-an-eval-function-cpq - improved the appearance of boolean evaluation function parameters.</li> <li>603-user-docs-updates - user documentation repo renamed from \"documentation\" to \"user_documentation\".</li> <li>608-link-word-sign-in-to-sign-in-on-homepage - on the home page 'sign in' text is now a link to sign in.</li> <li>619-mcq-check-button-should-be-vertically-central - the Check button for multi-choice questions in the response area panel is now vertically centred.</li> </ul>"},{"location":"releases/#release-20230605","title":"Release 2023/06/05","text":"<ul> <li>598-published-questions-change-of-approach - questions are now fully editable after publishing. All data from student responses persists through these changes. One exception is that the input type of a response area cannot be changed after publication, because this would change the format of the data that is recorded (you can, however, delete the response area and create a new one instead). Other new features: duplicate a Response Area; reorder Response Areas using drag and drop (in a similar way as reordering Parts).</li> <li>613-enable-publish-whole-set - see 606 below (2023/05/26). The 'Publish Whole Set' button is now enabled.</li> <li>614-error-with-stats-on-dev - ensures statistics still work with the new handwriting input (see 555 below).</li> </ul>"},{"location":"releases/#release-20230526","title":"Release 2023/05/26","text":"<ul> <li>555-handwriting-response-area-upgrades - A new version of the Expression input type is in use. Input by handwriting onscreen or with scanned images is an option for teachers to make available to students (default: off). Also, regardless of the input mode (type/draw/scan) the live preview now gives 'pre-submission' feedback on whether the response can be interpreted, and the Check button is only available if interpretation is successful.</li> <li>606-publish-whole-set-causing-stats-to-disappear - The 'Publish Whole Set' button in Teacher Edit mode has been disabled because it was causing data to become unlikned in the DB, giving the effect of data like number of completed parts 'disappearing'. Existing data has now been relinked and is all visible to users. The feature that caused the problem has been disabled while we prepare a replacement to be pushed shortly.</li> <li>612-whole-part-marked-as-done-with-more-response-areas - Student functionality. If a question part has multiple Response Areas, the logic is now that only if all Response Areas are correctly answered will the 'Mark as done' feature be automatically checked. Previously only one correct answer was required to trigger this effect.</li> <li>585-question-simple-import-and-export - Teacher functionality. The import/export functionality has been enhanced so that it Response Area parameters, cases, and tests are now all included.</li> </ul>"},{"location":"releases/#release-20230321","title":"Release 2023/03/21","text":"<ul> <li>571-simple-teacher-comment-feed - Teacher functionality. New 'Activity feed' (formerly 'Flagged Questions') contains flagged questions and comments. The teacher can filter the table to see e.g. only flags or only comments. The teacher can also sort the table e.g. to see the new activities first.</li> <li>569-numeric-input-strips-out-strings-that-may-have-meaning - Technical dept. For the Response Area input type 'Number', additional validation added; if the input contains a non-numeric value then a relevant error message is displayed to the user (this is linked to the 573-response-area-validation-specific-errors below).</li> <li>573-response-area-validation-specific-errors - Teacher and student functionality. More specific error messages are displayed when the user inserts a value in an incorrect format (e.g. a non-numeric value into the input that expects a number).</li> <li>582-empty-structured-tutorial-shouldnt-display - Technical debt. When a tutorial is deleted, it is not displayed at all to students (as opposed to being blank).</li> <li>585-question-simple-import-and-export - Teacher functionality. Export a question to a file in JSON format. Import a question from a file in JSON format. Images are not imported/exported - these need to be handled manually until a new feature is ready. This feature opens the door to file imports if content can be converted into the correct format.</li> <li>586-question-import-add-schema-validation - Teacher functionality. When importing a question from a file, the data structure and format is validated. If the validation fails then relevant error messages displayed to the user.</li> </ul>"},{"location":"releases/#release-20230306","title":"Release 2023/03/06","text":"<ul> <li>566-pdf-error-identification - Teacher functionality. When a PDF fails to compile, the location of the error source is given in more detail, e.g. 'Q2(c)'.</li> <li>576-orderedsetids-throws-error-in-main - Technical. When loading sets in a module on the teacher side, an error no longer appears in the console.</li> <li>522-adding-teacher-when-creating-module-inadequate-error-message - Admin functionality. When adding a new module, a teacher can be added simultaneously. If the proposed teacher is not already registered as a teacher, then they are now automatically created as a teacher and a confirmation message is displayed.</li> <li>524-remove-teacher-from-list - Admin functionality. Remove a teacher from the list of teachers. If the teacher is still a teacher on a module, then display a modal confirming which modules the teacher will be removed from. If the user confirms, the teacher is removed from all the modules and then they are deleted from the list of teachers.</li> <li>572-comment-upvote-tweeks - Teacher and Student functionality. Right margin on the comments tweaked so that the sorting feature and 'post' button are not too far away from each other.</li> <li>483-show-all-button - Teacher functionality. The Show All feature is now enabled in the question preview mode.</li> <li> <p>520-default-to-an-eval-function-after-selecting-the-response-area - Teacher functionality. In the Response area edit panel, automatically select a default eval function as follows (it can be edited by the teacher if necessary). The default selections are:</p> Response area Default evaluation function MCQ arrayEqual NUMERIC isSimilar Expression and Text symbolicEqual Table and Matrix arraySymbolicEqual NUMERIC_UNITS comparePhysicalQuantities </li> </ul>"},{"location":"releases/#release-20230210","title":"Release 2023/02/10","text":"<ul> <li>560-comment-feature-tweaks - UI improvements to the comments feature.</li> <li>550-comment-upvotes - users can upvote comments by clicking on the heart. Sorting by upvotes is default</li> <li>546-always-test-a-response-area-when-saving - [For teachers only] this is an invisible feature that automatically tests a response area, when closing the editing panel, to check that the correct answer is accepted as correct. A failure to pass this test will show an error and not save the response area until fixed. The reason for this feature is to catch things like empty cells in the teacher answer which, e.g. for a matrix, would make marking student answers impossible. If such errors were allowed to pass, then students would experience errors when using the response area - hence it cannot be allowed. The auto-test feature is not enabled for all response areas as some are not compatible - the option can be enabled/disabled for each response area by admins.</li> <li>568-numeric-input-expects-string - upgrade to the numeric input type when dealing with string inputs.</li> </ul>"},{"location":"student/","title":"Student/User Documentation","text":""},{"location":"student/#question-structure","title":"Question structure","text":"<p>The image above shows an example question, with numbers to indicate:</p> <ol> <li>Breadcrumbs showing location</li> <li>Name of the Problem Set</li> <li>PDF version (link)</li> <li>Names of the questions in the Set, indicating which question is open</li> <li>Question number and name</li> <li>Guidance (expands on hover)</li> <li>Master content (always visible to student)</li> <li>Part selection (tabs)</li> <li>Part content (only visible when relevant part is open - (a),(b), etc.)</li> <li>Response area, where student responses are entered and feedback is given</li> <li>Feedback to the teacher (currently in flux regarding the design - 31/8/22)</li> <li>Access to content 'below the line' providing extra support.</li> </ol>"},{"location":"student/#below-the-line","title":"Below the line","text":"<ul> <li>My solutions - create your own content. Drag and drop images or type content. Use standard markdown.</li> <li>Structured tutorial - teachers use this in different ways. It is generally a way to provide scaffolding if you're struggling.</li> <li>Final Answer - warning, don't ever look at the answer before you make your own genuine attempt at answering the question.</li> <li>Worked solutions - warning, don't ever look at the solutions before you make your own attempt. If necessary, look at the first line and reveal a step at a time.</li> </ul>"},{"location":"student/answering_questions/","title":"Answering Questions","text":""},{"location":"student/answering_questions/#overview","title":"Overview","text":"<p>The main view of a question is divided into two parts. The top half contains content that is relevant to the whole question, and the bottom half contains content for each individual part. Additionally, the part content may include one or more  response areas. When you think you have answered the question, enter your answer into the response area, if it exists, and press the \"Check\" button to check your work. If you are correct, the question will be marked as \"done\". If there is no response area (e.g. for a \"show that...\" question), you can manually mark the question as done using the box at the bottom right.</p>"},{"location":"student/answering_questions/#answers-and-worked-solutions","title":"Answers and Worked Solutions","text":"<p>If you are stuck, you can view worked solutions using the \"Worked Solutions\" option on the bottom ribbon. The steps in the solution are revealed step-by-step, so you should avoid the temptation to look at the whole solution at once, and try to complete as much as possible independantly. </p> <p></p> <p>You can also view the answer to each question using the \"Final Answer\" option on the bottom ribbon. This contains the  answer only, with no intermediate results or working.</p> <p>It is important that you always make your own genuine attempt to solve each problem before resorting to the final answers or the worked solutions. To help encourage this, a warning will appear if you try to access help before a question-specific time limit has elapsed.</p>"},{"location":"student/faq/","title":"Frequently Asked Questions","text":""},{"location":"student/faq/#why-i-cannot-find-the-module-i-am-looking-for","title":"Why I cannot find the module I am looking for","text":"<p>Access to each module is provided by the teacher owning the module.</p> <p>If you cannot find the module you are looking for, please contact your teacher.</p>"},{"location":"student/getting_started_student/","title":"Get started as a student using Lambda Feedback","text":""},{"location":"student/getting_started_student/#accessing-content","title":"Accessing content","text":""},{"location":"student/getting_started_student/#log-in","title":"Log in","text":"<p>Use your Imperial Microsoft account to sign in and access your modules. Once you sign in, you should see a list of the modules you are enrolled in:</p> <p>You can see the current progress of each module in this view.</p> <p></p>"},{"location":"student/getting_started_student/#select-a-module","title":"Select a module","text":"<p>Click on the module name to select it. You should now see a list of available problem sets. If none are available, your teacher may not have assigned any yet.</p> <p>You can see the current progress of each problem set in this view.</p> <p></p>"},{"location":"student/getting_started_student/#select-a-problem-set","title":"Select a problem set","text":"<p>Select the problem set you wish to work on, and you should see a list of questions on the left-hand side, with the selected question on the right. If a question has sub-parts, you can select them on the right.</p> <p></p>"},{"location":"student/getting_started_student/#accessing-the-pdf-version-of-a-problem-set","title":"Accessing the PDF version of a problem set","text":"<p>If you prefer to work on a PDF version of the problem set, you can generate a PDF by clicking the 'pdf' button underneath the problem set title.</p> <p></p>"},{"location":"student/getting_started_student/#answering-questions","title":"Answering questions","text":"<p>You can make progress on the problem by entering correct answers or clicking the 'Mark as done' button on the bottom right of each question page. This can be useful to track progress if working on the PDF version, or for questions which do not have a response box, e.g., show that questions.</p> <p>See the Answering Questions page for more help with answering questions.</p> <p></p>"},{"location":"student/milkdown_student/","title":"Text Editing","text":"<p>The Milkdown editor is widely used in Lambda Feedback wherever rich text input is required. On the student interface, it is used to add personal solution notes, and to write comments.</p> <p>It accepts:</p> <ul> <li>Standard Markdown</li> <li>\\(\\LaTeX\\)</li> <li>Images (paste or drag and drop)</li> <li>Videos (paste a URL)</li> </ul>"},{"location":"student/milkdown_student/#latex","title":"LaTeX","text":"<p>LaTeX is a typesetting system widely used in academia to produce well-formatted documents. It is mostly used in Lambda Feedback for its capability to render complex mathematical expressions clearly and accurately. </p> <p>As an example, the following LaTeX code:  <pre><code>\\int_V \\nabla \\cdot \\vec{f} \\mathrm{d}V = \\oint_S \\vec{f} \\cdot \\hat{n} \\mathrm{d}S\n</code></pre> Produces the following output:</p> \\[ \\int_V \\nabla \\cdot \\vec{f} \\mathrm{d}V = \\oint_S \\vec{f} \\cdot \\hat{n} \\mathrm{d}S \\] <p>In the Milkdown editor, anything surrounded by dollar signs (like <code>$ x^2 $</code>) will be interpreted as LaTeX.  Only the subset supported by KaTeX, which includes most common LaTeX functions, can be used.</p>"},{"location":"student/milkdown_student/#latex-equations-in-5-minutes","title":"LaTeX equations in 5 minutes","text":""},{"location":"student/milkdown_student/#numbers-and-letters","title":"Numbers and letters","text":"<p>Numbers and Latin letters can be entered as you would expect: <pre><code>1, 2, 3, 3.14159, -2.5, x, y, z\n</code></pre></p> \\[ 1, 2, 3, 3.14159, -2.5, x, y, z \\] <p>Subscripts can be written with <code>_</code> and superscripts can be written with <code>^</code>, for example in <code>x^2</code> (\\(x^2\\)) or <code>x_2</code> (\\(x_2\\)). Only the first character or command after a <code>_</code> or <code>^</code> will be taken. To subscript or superscript multiple characters, they can be  grouped in curly braces, like this: <code>V_{ab}</code> (\\(V_{ab}\\)).</p>"},{"location":"student/milkdown_student/#basic-functions","title":"Basic functions","text":"<p>Functions in LaTeX start with a backslash <code>\\</code>.</p> <p>Some common functions include Greek letters:</p> <ul> <li><code>\\pi</code> (\\(\\pi\\))</li> <li><code>\\delta</code> (\\(\\delta\\))</li> <li><code>\\Delta</code> (\\(\\Delta\\)) </li> <li>etc.</li> </ul> <p>Equalities: </p> <ul> <li><code>\\approx</code> (\\(\\approx\\))</li> <li><code>\\ne</code> (\\(\\ne\\))</li> <li><code>\\gt</code> (\\(\\gt\\))</li> <li>etc.</li> </ul> <p>Symbols/operators: - <code>\\int</code> (\\(\\int\\)) - <code>\\sum</code> (\\(\\sum\\)) - <code>\\sin</code> (\\(\\sin\\)) - <code>\\ln</code> (\\(\\ln\\)) - etc.</p>"},{"location":"student/milkdown_student/#functions-with-arguments","title":"Functions with arguments","text":"<p>Some functions take arguments. Arguments are given between curly braces <code>{}</code>. </p> <p>Some commonly functions with arguments are:</p> <ul> <li><code>\\sqrt{x}</code> (\\(\\sqrt{x}\\)). This places a square root sign around the argument.</li> <li> <p><code>\\frac{x}{y}</code> (\\(\\frac{x}{y}\\)). This command takes two arguments, and produces a fraction with the first argument in the numerator and the second on the denominator.</p> </li> <li> <p>Diacritics:</p> <ul> <li><code>\\vec{x}</code> (\\(\\vec{x}\\)).</li> <li><code>\\dot{x}</code> (\\(\\dot{x}\\)). </li> <li><code>\\hat{x}</code> (\\(\\hat{x}\\)).</li> <li>etc.</li> </ul> </li> <li> <p><code>\\mathrm{x}</code> (\\(\\mathrm{x}\\)). This formats the argument as regular, upright text, rather than italics. Should be used for units and operators (e.g. \\(\\frac{\\mathrm{d}y}{\\mathrm{d}x}\\)).</p> </li> </ul>"},{"location":"student/milkdown_student/#nesting","title":"Nesting","text":"<p>Functions can be nested arbitrarily. For example, a square root may contain a fraction, which may contain another square root: <pre><code>\\sqrt{ \\frac{-b \\pm \\sqrt{b^2 - 4ac }}{2a} }\n</code></pre></p> \\[\\sqrt{ \\frac{-b \\pm \\sqrt{b^2 - 4ac }}{2a} }\\]"},{"location":"student/milkdown_student/#going-further","title":"Going further","text":"<p>If you are unsure of the correct function to use to produce the desired result, there is a list of all supported KaTeX functions here.</p>"},{"location":"student/response_areas/","title":"Response Areas","text":""},{"location":"student/response_areas/#numerical-answers","title":"Numerical answers","text":"<p>This type of response area expects a numerical answer. Usually, a tolerance is allowed, so you will still be marked as correct if your response differs from the answer by a small amount. </p> <p></p> <p>Some questions will also require you to enter the units of the answer. In this case, any form of the same unit, with any SI prefix, should be accepted. For example, if the answer to a question is <code>10 MPa</code>, <code>0.01 GPa</code> and <code>10 MNm^-2</code> should both be marked correct. </p>"},{"location":"student/response_areas/#entering-mathematical-expressions","title":"Entering mathematical expressions","text":"<p>Entering mathematical expressions on Lambda is very similar to if you were doing it in Matlab, for example. </p>"},{"location":"student/response_areas/#examples","title":"Examples","text":"Expression Lambda Feedback input \\(x^2 - x - 2\\) <code>x^2 - x - 2</code> \\(\\sqrt{\\sin(x) + \\frac{\\pi}{2}}\\) <code>sqrt(sin(x) + pi/2)</code> $e^{\\frac{\\pi x}{2} + 1} <code>exp((pi*x)/2 + 1)</code>"},{"location":"student/response_areas/#reference","title":"Reference","text":"Operator Symbol Lambda Feedback input Addition \\(a + b\\) a+b Subtraction \\(a - b\\) a-b Multiplication \\(a \\times b\\) a*b Division \\(\\frac{a}{b}\\) a/b Exponentiation \\(a^b\\) a^b Square root \\(\\sqrt{a}\\) sqrt(a) <p>Common elementary functions such as \\(\\sin\\), \\(\\cos\\), \\(\\arcsin\\), \\(\\ln\\) etc. are also supported.</p>"},{"location":"teacher/","title":"Teacher and Content Author Documentation","text":"<p>In the 2022/23 academic year Lambda Feedback was in its alpha version. We are now in our Beta version. This means that some features are incomplete, and that the documentation is not ready yet. All teacher-users should be in direct contact with someone on the development team so that you can ask for support.</p> <p>Please provide feedback on the documentation as it develops.</p> <p>We will populate this area more soon.</p> <p>Try Getting Started ...</p>"},{"location":"teacher/guides/analytics/","title":"Analytics Guide","text":"<p>Analytics begin when a question is published. After publishing a question for the first time it becomes available to students and their usage is logged and fed back to the student and the teacher. </p>"},{"location":"teacher/guides/analytics/#analytics-history","title":"Analytics History","text":"<p>Analytics are linked to response areas. Each question can have more response areas and they can be added or removed. When a response area is removed, then it is removed only from the \"current version\" of the question (the version that the teacher is editing) and it persists on the previous version(s) of the question. It means that all submissions and analytics remain, but they are now linked to the response area which only exists on a previous version(s) of the question.</p> <p>Currently it is possible to see only analytics against the published version of the question.</p> <p>We are now working on the improvement so that it is possible to see analytics against all reponse areas (including those that exist only on previous versions of the question).</p>"},{"location":"teacher/guides/analytics/#tracking-students-response","title":"Tracking students' response","text":"<p>To improve the feedback that students receive and to better understand which areas they need help with, it is possible to check the different student responses and the frequency of each response for each response area. </p> <p>To see these statistics:</p> <ol> <li>Click on the Stats tab in teacher mode </li> <li>Then click on Explore in the top right corner of each response area.</li> </ol> <p>You can even export these statistics as csv file!</p>"},{"location":"teacher/guides/content-sets-questions/","title":"Editing questions","text":"<p>In this guide, we will walk through how to create sets and questions.</p> <ol> <li>Click on a Set in order to edit or add questions.</li> </ol> <p></p> <ol> <li>A guide to the editor:</li> </ol> <p></p> Label Name Description 1 Question Name Here we can edit the name given to the question 2 Master content Always visible. Uses a milkdown component. 3 Current part Referenes which question part we are editing 4 Part Content Here we can edit the specific content of the part (the sub question). 5 Response Area This is the means by which the student answers a given question. It is optional to include a response area. 6 Question Help Options Here we may add a Structured Tutorial, a Final Answer (\"Show Answer\"), or Worked Solutions. These buttons are also how the student will see them, hence the name of \"Show Answer\". 7 Teacher-Student View Toggle Here we may toggle between the teacher view (\"EDIT\"), and the student view (\"PREVIEW\"). This way we can edit the question, but also see a preview of how it would look to the student. 8 Edit Guidance Here we can add further details for guidance, estimated working time and skill level 9 Part option Here we can add, duplicate or (if there are more than one) delete a question part 10 Add question Here we can add create a new blank question, duplicate a question or upload a zip file containing JSON file(s) for Lambda Feedback. 11 File, Preview and Stats Travel to pages to a) File: version management/ download as JSON and delete question b) Preview: view the question as a student would see it c) Stats: View stats of student responses of the question set."},{"location":"teacher/guides/faq/","title":"Frequently Asked Questions","text":""},{"location":"teacher/guides/faq/#how-can-i-enroll-students-on-my-new-module","title":"How can I enroll students on my new Module","text":"<p>Students and users are given access to a module using their college email address (from microsoft).</p> <ol> <li>Login and navigate to your Teacher dashboard</li> <li>Select the module on which you want to enroll students</li> <li>When on the module page, click the View Students button</li> <li>Enter the enrolment page by clicking the Entroll Students  button</li> <li>Enroll students by supplying one or more student email addresses</li> </ol>"},{"location":"teacher/guides/faq/#how-can-i-move-questions-between-problem-sets","title":"How can I move questions between problem sets?","text":"<p>When creating a new question the teacher can choose to \"clone\" from an existing question. The teacher can then delete the original version.</p> <ol> <li>In the problem set you wish to move the question to, select the v symbol to the right of the Add Question button</li> <li>From the dropdown menu, select Clone From Question</li> <li>Select the title of the question you wish clone from the list that appear</li> <li>If you wish, go back and delete the question from its original location</li> </ol>"},{"location":"teacher/guides/faq/#how-can-i-share-a-link-to-a-problem-set","title":"How can I share a link to a Problem Set?","text":"<p>To share a link with students, open the Problem Set in STUDENT mode (light blue top bar), and copy the URL from the browser.</p> <p>To share a link with teachers who will access the content editor and analytics, share a link from TEACHER mode (orange top bar); students won't be able to access this link.</p>"},{"location":"teacher/guides/faq/#how-can-i-set-parameters-for-evaluation-functions","title":"How can I set parameters for evaluation functions?","text":"<p>The most common parameters will be visible uder the EVALUATE tab in the configure panel.</p> <p>If there is a parameter that is not already visible it can be set using the Advanced - raw parameters (also under the EVALUATE tab) by doing the following:</p> <p></p> <ol> <li>Hover over the list of parameters in the Advanced - raw parameters area. Click the green plus-symbol that appears.</li> </ol> <p></p> <ol> <li>Type the name of the parameter (without quotation marks).</li> </ol> <p></p> <ol> <li>Hover over the box that says <code>NULL</code> next to the newly added parameter. Click the green pen symbol that appears to the right of it.</li> </ol> <p></p> <ol> <li>Type in the desired value in box that appears. By default it will be assumed that the parameter value is a string. The webclient will infer other possible types based on the written input. If the setting should be a string, click the green checkmark to the top right, and if you want the inferred type click the green checkmark at the bottom right.</li> </ol> <p></p> <ol> <li>The parameter is now set.</li> </ol> <p></p>"},{"location":"teacher/guides/faq/#how-do-i-reorder-questions","title":"How do I reorder questions?","text":"<p>It is only possible to reorder published questions in a set. This prevents inadvertently inserting new questions between two published ones. This ensures consistency to the student when viewing a published set as existing questions will remain in an unchanged order, with new questions being added to the bottom (unless manually changed by the teacher). You can tell a question is unpublished as it will take the '1.X' numbering format</p> <p>To reorder questions:</p> <ol> <li>Publish the questions you wish to reorder using FILE &gt; SAVE AND PUBLISH (alternatively click on the PUBLISH WHOLE SET button)</li> <li>Refresh the page</li> <li>Drag and drop the questions into the new order</li> <li>Ensure the green box pops up saying: 'questions reordered successfully' - there is no need to republish the set</li> </ol>"},{"location":"teacher/guides/faq/#what-to-do-when-space-is-not-showing-in-the-pdf-generated-by-lambda-feedback","title":"What to do when <code>\\space</code> is not showing in the pdf generated by lambda feedback?","text":"<p>The Pandoc library that lambdafeedback use to generate a pdf does not support <code>\\space</code>. Alternatives that could be use to generate a space in math block is to use the tilde symbol <code>~</code> or <code>\\,</code> for thinner spacing.</p>"},{"location":"teacher/guides/faq/#what-to-do-if-the-pdf-is-not-compiling-my-inline-math-equation","title":"What to do if the pdf is not compiling my inline math equation?","text":"<p>Please check if there is an additional space at the start or a the end of the equation. This is usually the cause for inline math blocks not compiling.</p> <p>Sometimes if you are copy-pasting text into equations you may end up with certain characters that look normal but actually have different ASCII codes than what you intended. This may also cause a PDF not to compile.</p>"},{"location":"teacher/guides/faq/#how-can-i-have-the-same-font-for-the-unit-and-for-the-number-in-the-math-block","title":"How can I have the same font for the unit and for the number in the math block?","text":"<p>You can use the code <code>\\mathrm{}</code> or <code>{\\rm}</code>. Both code will give you your units in serifed Times New Roman, which is the same font as the number in the math block when compiled.</p>"},{"location":"teacher/guides/faq/#complex-numbers-notation","title":"Complex Numbers Notation","text":"<p>If you want to use <code>I</code> for the imaginary constant, add the parameter <code>complexNumbers</code> to \"advanced - raw parameters\" by clicking the green (+). Type in <code>complexNumbers</code> and press enter. Click the green edit button, type in \"True\" and a pop-up <code>bool - true</code> will appear. Click the green tick.</p> <p></p> <p>You can denote <code>i</code> and <code>j</code> as <code>I</code> by using the input symbols below. </p> <p></p> <p>Furthermore, the system can equate <code>exp(Ix)</code> to <code>cos(x)+Isin(x)</code>.</p>"},{"location":"teacher/guides/gettingstarted/","title":"Get started as a teacher using Lambda Feedback","text":""},{"location":"teacher/guides/gettingstarted/#access-a-module","title":"Access a module","text":"<p>Use your Imperial Microsoft account to sign in and access your modules. By default you are logged in as a student and the interface will be blue. If you have teacher priviliges then you will see a teacher button at the top.</p> <p></p> <p>To enter teacher mode, click on the Teacher button, and the colour of the interface will change to orange. This is where you are able to access all your modules, as well as upload and edit problem sets.</p> <p>As of 07/2023, new modules can only be added to Lambda Feedback by administrators. Please speak to an admin if you wish for your module to be added to the website.</p> <p></p> <p>To find the module you want, you can sort ASCENDING as per the image below: Image: quick sort (left) or filtering (right)</p> <p>As of 31/8/22 the filtering/sorting only works on the content visible on the current page (other pages are ignored). We aim to fix this by sorting at the backend.</p> <p>Select the module you wish to edit. </p>"},{"location":"teacher/guides/gettingstarted/#create-a-new-problem-set","title":"Create a new problem set","text":"<p>Click on your module and then click on \"content\" (upper left-hand corner). </p> <p>Create a new set by pressing the button seen below and this will automatically appear with a default name which you can edit by clicking 'edit set metadata': </p> <p>To edit the content, click on the set name. This will open the Set in a 'WYSIWYG' editor. The first question is automatically created with a default name.</p> <p>The question structure is described here.</p>"},{"location":"teacher/guides/gettingstarted/#below-the-line","title":"Below the line","text":"<p>Below the main question content you can provide high quality support material for students.</p> <p></p> <p>A student guide is here and teachers use the content as follows:</p> <ul> <li>Structured tutorial is a canvas to provide scaffolding to students struggling with the question.</li> <li>Final answer is self explanatory.</li> <li>Worked solutions provides detailed, step-by-step solutions.</li> </ul> <p>All content below the line uses milkdown functionality. Worked solutions can be branched. Future developments will add branching and response areas to structured tutorials.</p> <p>It is not necessary to include all three methods of help, if only one of the tabs is filled then only that one button will be included in the published student version.</p> <p>For general terminology, see here.</p> <p>To see further details on how to edit your questions, see here.</p>"},{"location":"teacher/guides/gettingstarted/#enrolling-students","title":"Enrolling students","text":"<p>In TEACHER mode, open your module home page and click 'VIEW STUDENTS' then 'ENROL STUDENTS'</p> <p> </p> <p>Enter a comma-separated list of email addresses. Press 'Enter' to confirm the addresses, and then 'SUBMIT' to enrol the students</p>"},{"location":"teacher/guides/gettingstarted/#imperial-college-london-email-addresses","title":"Imperial College London email addresses","text":"<p>You must use the long form email address:</p>"},{"location":"teacher/guides/gettingstarted/#valid","title":"Valid:","text":"<p>first.nameYY@imperial.ac.uk (student) j.doe@imperial.ac.uk (staff) first.name@imperial.ac.uk (staff)</p>"},{"location":"teacher/guides/gettingstarted/#invalid","title":"Invalid","text":"<p>abc123@ic.ac.uk abc123@imperial.ac.uk user@ic.ac.uk user@imperial.ac.uk first.nameYY@ic.ac.uk</p> <p>The reason for the above is because we use Azure Active Directory - i.e. Microsoft - to authorise users.</p>"},{"location":"teacher/guides/good-practice/","title":"Good practice","text":""},{"location":"teacher/guides/good-practice/#romanised-operators","title":"Romanised operators","text":"<p>Use romanised operators such as \\(\\sin\\), \\(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\) instead of \\(sin\\), \\(\\frac{d}{dx}\\), etc.</p>"},{"location":"teacher/guides/good-practice/#use-empty-lines","title":"Use empty lines","text":"<p>Using empty lines can improve the readability and neatness of your content. Empty lines are often useful before and after an equation, and between paragraphs of text. An empty line in markdown requires two spaces on the line, otherwise the line is ignored.</p>"},{"location":"teacher/guides/good-practice/#space-between-numbers-and-units","title":"Space between numbers and units","text":"<p>Put appropriate space between a number and its unit, such as <code>5 m</code> or <code>3 kg</code>, according to the SI conventions.</p>"},{"location":"teacher/guides/good-practice/#romanise-units-and-check-their-case","title":"Romanise units and check their case","text":"<p>Use romanised units such as \\(\\text{m}\\), \\(\\text{kN}\\) instead of \\(m\\), \\(kN\\). Ensure that the case of the unit is correct.</p>"},{"location":"teacher/guides/good-practice/#add-tests-to-response-areas","title":"Add tests to response areas","text":"<p>In a response area, press <code>configure</code> then <code>tests</code>.</p> <p>Tests allow you to enter potential student responses, define whether they are correct or not, then run the evaluation function on those student responses. This allows you to quickly test whether or not the evaluation function works as expected.</p>"},{"location":"teacher/guides/good-practice/#save-and-publish-as-you-go","title":"Save and publish as you go","text":"<p>Saving and publishing work regularly is recommended to prevent accidental data loss.</p>"},{"location":"teacher/guides/good-practice/#use-branching-when-relevant","title":"Use branching when relevant","text":"<p>Branching is a feature for <code>worked solutions</code>. It allows you to have different solution pathways Usage examples:</p> <ul> <li>When a question can be solved via multiple different methods, branching can be used for each method.</li> <li>When a question has multiple parts, where each part involves substitution of different values, branching can be used for each part.</li> </ul> <p></p>"},{"location":"teacher/guides/good-practice/#use-pre-response-area-text-to-be-clear-what-should-be-entered","title":"Use pre-response area text to be clear what should be entered","text":"<p>Pre-response area text is found under <code>configure</code> - <code>INPUT</code> in the evaluation function.</p> <p>You can use LaTeX in the pre-response area text.</p> <p></p>"},{"location":"teacher/guides/good-practice/#use-dfrac-for-bigger-fractions-when-needed","title":"Use <code>\\dfrac</code> for bigger fractions when needed.","text":"<p>Use <code>$\\dfrac{numerator}{denominator}$</code> for bigger fractions when you need to display them more clearly or emphasize them. For example, <code>$\\dfrac{3}{4}$</code> will produce a bigger fraction than <code>$\\frac{3}{4}$</code>. Alternatively, you can use <code>$\\displaystyle$</code> at the start of an inline equation to render everything afterwards full-size (as in display maths mode), this is especially helpful for integrals.</p>"},{"location":"teacher/guides/good-practice/#use-small-when-smaller-fonts-or-fractions-are-needed","title":"Use <code>\\small</code> when smaller fonts or fractions are needed","text":"<p>Use <code>$\\small{text}$</code> when you need to display smaller fonts or fractions in your LaTeX expressions. For example, <code>$\\small{\\frac{1}{2}}$</code> will produce a smaller fraction than <code>$\\frac{1}{2}$</code>.</p>"},{"location":"teacher/guides/good-practice/#use-audio-clips","title":"Use audio clips","text":"<p>Just drag + drop an audio file into the milkdown editor.</p>"},{"location":"teacher/guides/good-practice/#issue-with-input-symbols","title":"Issue with input symbols","text":"<p>For the <code>code</code> of input symbols in the response areas, the system cannot accept brackets (i.e <code>dot(x)</code> for \\(\\dot{x}\\)) and response must be formatted in different ways (i.e <code>dot_x</code>). </p> <p><code>a_b</code> will render as \\(a_b\\) without adding an input symbol, but note that <code>dot_x</code> overrides the <code>_</code> input (in this example, will render as \\(\\dot{x}\\) instead of \\(dot_x\\))</p>"},{"location":"teacher/guides/good-practice/#use-live-preview-and-permit-all-types-of-input","title":"Use live preview and permit all types of input","text":"<p>Live preview and input types are found in an evaluation function under <code>configure</code> - <code>INPUT</code>.</p> <p>Live preview instantly renders a student's input. This is very useful for long/complicated equations, as it allows students to ensure their input is correct.</p> <p></p>"},{"location":"teacher/guides/good-practice/#latex-help","title":"Latex help","text":"<ol> <li>Use \\begin{array} to generate compact table i.e  <pre><code>\\begin{array}{|c|c|}\n\\hline\n\\theta_{2,0} &amp; \\theta_{1,L}\\\\\n\\hline\n-6700 &amp; 130.5641\\\\\n\\hline\n-6600 &amp; 161.6086\\\\\n\\hline\n\\end{array}\n</code></pre></li> </ol> <ol> <li>Use <code>\\begin{aligned}</code> to keep your working formatted nicely <pre><code>\\begin{array}{ll}\nM_{d e f} &amp;=\\dfrac{1}{2}(M+M^T)\\\\\n&amp; =\\dfrac{1}{2} \\begin{pmatrix} 4 &amp; 14\\\\ -6 &amp; -11 \\end{pmatrix}+\\begin{pmatrix} 4 &amp; -6\\\\ 14 &amp; -11 \\end{pmatrix}\\\\\n&amp; =\\begin{pmatrix} 4 &amp; 4\\\\ 4 &amp; -11 \\end{pmatrix}\n\\end{array}\n</code></pre></li> </ol> <ol> <li>Use <code>\\left</code> and <code>\\right</code> for equations with multiple brackets</li> </ol> <pre><code>f(x)=\\left (\\frac{(\\cos (x) -x) + i(\\sin (x) - x)}{wi} \\right)\n</code></pre> <p>This also works for <code>[ ]</code> and <code>\\{ \\}</code></p> <ol> <li>Use <code>\\sin</code>, <code>\\cos</code> etc... if you are too lazy to write out <code>\\text{sin }</code> everytime in equation mode.</li> </ol>"},{"location":"teacher/guides/milkdown/","title":"The milkdown editor","text":"<p>The milkdown editor is widely used in Lambda Feedback. It accepts:</p> <ul> <li>standard markdown</li> <li>\\(\\LaTeX\\) (delimited by $ and limited to KaTeX functionality)</li> <li>images (paste or drag and drop)</li> <li>videos (paste a URL)</li> </ul>"},{"location":"teacher/guides/milkdown/#common-needs-in-milkdown","title":"Common needs in milkdown","text":"<p>Here's a walkthrough to create some basic content:</p>"},{"location":"teacher/guides/milkdown/#empty-lines","title":"Empty lines","text":"<p>Two blank spaces in a line will ensure it persists (as in standard markdown).</p>"},{"location":"teacher/guides/milkdown/#inline-maths","title":"Inline maths","text":"<p>Use the <code>$</code> sign to delimited inline maths. For example type the following:</p> <p><code>This is inline maths, $\\alpha&lt;0$, and it is useful</code></p> <p></p>"},{"location":"teacher/guides/milkdown/#equation-mode","title":"Equation mode","text":"<p>Start a blank line with <code>$$</code> then press the space bar. This will introduce an equation editor. Type raw \\(\\LaTeX\\) into the shaded part and see the live preview in the lower part. *Press <code>ctrl+enter</code> (Mac: <code>cmd+enter</code>) to exit the equation editing box.</p> <p>For example, type the following after typing <code>$$ [space]</code> into a fresh line:</p> <p><code>f(x) = \\int_{-\\infty}^\\infty \\hat{f}(\\xi)\\,e^{2 \\pi i \\xi x} \\,\\mathrm{d}\\xi</code></p> <p></p>"},{"location":"teacher/guides/milkdown/#steps-in-worked-solutions","title":"Steps in worked solutions","text":"<p>If you begin a fresh line with <code>---</code> (three dashes) then a horizontal rule appears. Alternatively click the button on the toolbar to insert a horizontal rule.</p> <p></p> <p>If you are editing a worked solution, then Lambda Feedback will split the worked solution into steps according to the location of horizontal rules. You can delete and add the rules and the solution steps will update.</p> <p>For example:</p> <p><code>This is the first step of the solution - which is a good hint towards solving</code> <code>---</code> <code>This is a second step, which makes it more obvious</code> <code>---</code> <code>Finally we reach the solution</code></p> <p>When viewing the worked solutions, this is how it looks:</p> <p></p> <p>This is the process to create the solution steps:</p> <p></p>"},{"location":"teacher/guides/milkdown/#images","title":"Images","text":"<p>You can add images with drag-and-drop or copy-and-paste. Currently (July '24) there is no way to resize images other than lowering the resolution - see below. </p> <p></p>"},{"location":"teacher/guides/question-export-import/","title":"Question export and import","text":""},{"location":"teacher/guides/question-export-import/#export-a-question","title":"Export a question","text":"<p>Under the File menu, select the Export as JSON option:</p> <p></p> <p>The question and images (if any) will be downloaded into your download folder.</p>"},{"location":"teacher/guides/question-export-import/#import-a-question","title":"Import a question","text":"<p>Click Add question menu and select Import questions from file option:</p> <p></p> <p>The file explorer opens. Select the zip file containing the question and click open. The question will be added as the last question.</p> <p>The zip file must contain question data in a valid JSON format. The best way to obtain a valid JSON format is to export a question, unzip the download file and open the JSON file. If the question contains media, they must be in the media folder inside of the zip file.</p>"},{"location":"teacher/guides/question-export-import/#import-more-than-1-question","title":"Import more than 1 question","text":"<p>The zip file can contain more than one question. Each of the questions must be in the JSON file and in the correct format. All media must be in the media folder.</p> <p>It is possible to e.g. export 2 questions, then unzip the exported zip files and then zip both questions and their medias into one zip file and then import the one zip file. Here is an example of a folder containing 2 questions and their medias:</p> <p></p> <p>The name of the folder and names of json files are not important. However, the name of media files must correspond with the names used in the json files when referring the media.</p>"},{"location":"teacher/reference/access_control/","title":"Access control","text":""},{"location":"teacher/reference/access_control/#modules","title":"Modules","text":"<p>Module access for students is controlled by enrolling student users. More details to be added here.</p>"},{"location":"teacher/reference/access_control/#sets","title":"Sets","text":"<p>Set access is granted to all users enrolled on a module, but the Set can be hidden by the teacher. Two methods can be used to hide a Set:</p> <ol> <li>Start and end dates (both optional) can be created in the Set Metadata</li> <li>The Set can me manually hidden, which overrides the above settings.</li> </ol>"},{"location":"teacher/reference/access_control/#support-material-within-questions","title":"Support material within questions","text":"<p>The following types of support materials are available to students in the <code>help</code> section:</p> <ul> <li>Sructured tutorial</li> <li>Final answer</li> <li>Worked solutions</li> </ul> <p>Two methods can be used to hide support material:</p>"},{"location":"teacher/reference/access_control/#configuring-student-access-at-the-set-level","title":"Configuring student access at the set level","text":"<p>Open the Edit Set Metadata page by clicking on the Edit Set Metadata button in the list of sets:</p> <p></p> <p>The page contains the Student access to support material section:</p> <p></p> <p>Access to each support material type can be set to one of the following options:</p>"},{"location":"teacher/reference/access_control/#available","title":"Available","text":"<p>Students can open this support material type without any restrictions.</p> <p>This is valid for all questions in the set except those for which the support material access is set to be unavailable at the question level (see below).</p>"},{"location":"teacher/reference/access_control/#available-with-warnings","title":"Available with warnings","text":"<p>A warning window appears if the studen opens the content before the recommended time.</p> <p>The recommended time is the Minimum time estimate (mins) which can be set on the question Guidance page:</p> <p></p> <p>However, the option will be changed to Available, if any of the following is true:</p> <ul> <li>The student has downloaded the PDF</li> <li>The part is marked as done</li> <li>There is no minimum time estimate set for the question</li> <li>The time now minus the time the student first accessed the question is more than the minimum time estimate</li> </ul> <p>This is valid for all questions in the set except those for which the support material access is set to be unavailable at the question level (see below).</p>"},{"location":"teacher/reference/access_control/#unavailable","title":"Unavailable","text":"<p>Students cannot open any support material for any question in the set.</p> <p>This is valid for all questions in the set, even those for which the support material access is set to Available at the question level (see below).</p>"},{"location":"teacher/reference/access_control/#configuring-student-access-at-the-question-level","title":"Configuring student access at the question level","text":"<p>The support material access configuration at the question level is located on the File tab:</p> <p></p> <p>All support material is available by default, it can be changed:</p> <ul> <li>If the switch is off, then the support material is available</li> <li>If the switch is on, then the support material is unavailable</li> </ul>"},{"location":"teacher/reference/access_control/#summary-overview","title":"Summary overview","text":"Set level setting Question level setting Result (using Final answer as an example) Description Comment Unavailable N/A The Final answer is disabled The setting at the question level is ignored Available Unavailable The Final answer is disabled Available with warnings Unavailable The Final answer is disabled The same result as above Available with warnings Available When the Final answer is clicked, a warning message appears Additional conditions must be met:  <li>PDF not downloaded</li> <li>Part not marked as done</li><li>The minimum time estimate is set for the question</li> <li>The time now minus the time the student first accessed the question is more than the minimum time estimate</li>If any of them is not met, then the support material will be available with no warnings."},{"location":"teacher/reference/latex_functionality/","title":"Latex functionality","text":"<p>Lambda feedback uses one content source to serve two outputs: web and PDF. Each output has different requirements, and content must meet both requirements in order to serve both outputs.</p>"},{"location":"teacher/reference/latex_functionality/#content-formatting","title":"Content formatting","text":"<p>All content is formatted in markdown. Headings, font style, lists, tables, images, \\(\\LaTeX\\), can all be created using standard markdown.</p> <p>Special attention is required when formatting \\(\\LaTeX\\) which, although it is formatted using standard markdown (i.e. delimited by the <code>$</code> for 'inline formulas', and <code>$$</code> for an equation environment), must use a subset of \\(\\LaTeX\\) in order to compile for both outputs. This sometimes requires a compromise by the author.</p>"},{"location":"teacher/reference/latex_functionality/#the-milkdown-editor","title":"The milkdown editor","text":"<p>All content in Lambda Feedback is stored as markdown (ASCII content), however it is always input/edited using the milkdown editor. This editor has the advantage of providing live interactive previews of content, including \\(\\LaTeX\\) via katex.</p>"},{"location":"teacher/reference/latex_functionality/#web-requirements-katex","title":"Web requirements: katex","text":"<p>\\(\\LaTeX\\) content is rendered in the web browser using the katex Javascript library. The katex home page has an intereactive input where content is rendered and can be checked for validity. The documentation lists which functions are supported.</p> <p>Katex is a subset of \\(\\LaTeX\\). Therefore some functions that work in \\(\\LaTeX\\) do not work in katex and won't render on the web. For example, the <code>tikz</code> package - which is a complex graphics package - is not supported by katex. Unsupported packages have knock-on effects, for example while the <code>\\cancel{}</code> function is supported, <code>\\cancelto{}{}</code> is not because it relies on <code>tikz</code>.</p> <p>Ensuring that content renders correctly on the web is straightforward because the editor gives a live preview - and will indicate when errors occur.</p>"},{"location":"teacher/reference/latex_functionality/#pdf-requirements-pandoc-and-pdflatexxetex","title":"PDF requirements: pandoc and PDFlatex/XeTeX","text":"<p>When a Problem Set is saved in the editor, the PDF is automatically compiled by sending the markdown content to Pandoc, which internally uses \\(\\LaTeX\\) (either PDFlatex of xelatex - depending on the settings within the Lambda Feedback stack) to render a PDF.</p> <p>Problems can occur with PDF compilation even if the web rendering is successful, because it uses different libraries to the web browser. If the PDF fails to compile, a red error bar will appear and provide the location of the error within the Problem Set (identifying which question), and the error that Pandoc returned.</p> <p>One key limitation of the Lambda Feedback system is that it uses markdown content, so cannot produce all the richness of a full \\(\\LaTeX\\) document (and the AMS math library). All equation environments in markdown are signalled by the <code>$$</code> delimiter which is equivalent to <code>\\begin{equation*}</code>. This rules out using alternative primary environments, such as <code>align</code>, <code>gather</code>, <code>multiline</code>, <code>alignat</code>, <code>falign</code>.</p> <p>You can use subordinate environments within an equation environment, for example the following is valid:</p> <pre><code>$$\n\\begin{aligned}\na &amp; b\\\\\nc &amp; d\n\\end{aligned}\n$$\n</code></pre> <p>Here the suffix <code>-ed</code> in <code>aligned</code> implies a subordinate environment; likewise <code>gathered</code>, <code>alignedat</code> etc. are all valid within an equation environment.</p>"},{"location":"teacher/reference/latex_functionality/#warning-no-blank-lines-allowed-in-aligned-subordinate-environment","title":"Warning: No blank lines allowed in <code>aligned</code> subordinate environment","text":"<p>If a blank line is present within a subordinate environment <code>\\begin{aligned}</code> then Pandoc will fail to compile the PDF. For example:</p> <p>```Faulty code example: $$ \\begin{aligned} a &amp; b\\ c &amp; d</p> <p>\\end{aligned} $$ ```</p> <p>The above will fail to compile the PDF. But removing the blank line will solve the problem.</p> <p>For further reading search for the AMS math package and related literature.</p>"},{"location":"teacher/reference/latex_functionality/#numbering-equations","title":"Numbering equations","text":"<p>Equation numbering is problematic and our advice is to use manual numbering. Automatic numbering is possible, for example using <code>\\begin{equation}</code> within a <code>$$</code> environment. Note that sometimes the equation numbers continue counting from one environment to the next, while at other times they don't. You cannot use <code>\\ref</code> to refer to automatic equation numbers.</p> <p>An alternative approach is to use an unnumbered aligned environment, and to add an extra column with the equation number in (e.g. <code>&amp;(2)</code>).</p> <p>For some ad hoc good practice tips, see good practice.</p>"},{"location":"teacher/reference/pdf_generation/","title":"PDF Generation","text":""},{"location":"teacher/reference/pdf_generation/#supported-packages","title":"Supported packages","text":"<p>Please see Latex Template for the up-to-date list.</p> <p>amsmath: This package is essential for many mathematical features, including aligned equations, matrices, and more advanced math functions. It\u2019s fundamental to most LaTeX documents involving mathematics.</p> <p>amssymb: Provides additional mathematical symbols not covered by the base LaTeX distribution.</p> <p>babel: Provides multilingual support in LaTeX documents. It allows you to typeset documents in various languages, providing proper hyphenation, date formats, and typographical conventions. It also enables you to switch between languages within the same document.</p> <p>biblatex: Is used for managing bibliographies in LaTeX documents. It offers advanced features for creating, formatting, and referencing bibliographic data. It provides more flexibility compared to traditional bibliography packages like natbib, allowing for extensive customization of citations and bibliography styles.</p> <p>bidi: Provides bidirectional text support in LaTeX. It is essential for typesetting documents that contain both left-to-right (LTR) and right-to-left (RTL) text, such as Arabic, Hebrew, Persian, and Urdu. It handles the complexities of mixing LTR and RTL scripts in the same document.</p> <p>booktabs: Enhances the quality of tables in LaTeX documents by providing additional commands for creating professionally styled tables. It focuses on the design and spacing of horizontal lines, helping to produce tables that adhere to high typographic standards without vertical rules, which are generally discouraged in professional typesetting.</p> <p>bracket: Is designed to handle specific types of brackets in mathematical environments. It provides commands to properly size and align brackets, ensuring that they scale correctly with the content they enclose, which is particularly useful in complex mathematical expressions.</p> <p>cancel: Is used to draw diagonal lines (\u201cslashes\u201d) through mathematical expressions, indicating cancellation. This is useful in demonstrating steps in mathematical derivations where terms are canceled out. The package provides commands for different styles of cancellation (e.g., diagonal, cross out).</p> <p>eurosym: Provides the Euro currency symbol (\u20ac) in LaTeX documents. It offers several options for the appearance of the symbol, ensuring that it integrates well with various fonts and typographical styles used in the document.</p> <p>fixltx2e: Provides fixes for bugs and improvements in the standard LaTeX2e distribution. It is particularly useful for older LaTeX distributions to ensure compatibility and correct behavior of certain commands. Note that in more recent LaTeX distributions, this package is deprecated as its fixes have been incorporated into LaTeX itself.</p> <p>fancyvrb: Provides enhanced functionality for typesetting verbatim text in LaTeX. It allows for customization of verbatim environments, including changing fonts, adding line numbers, and creating shaded backgrounds. It is useful for typesetting code listings or any text that should be displayed exactly as typed.</p> <p>fontenc: Is used to specify the font encoding in LaTeX documents. Font encoding defines how characters are represented in the output. By default, LaTeX uses a limited encoding (OT1), but fontenc allows you to switch to more comprehensive encodings like T1, which supports accented characters and other symbols, making the document suitable for European</p> <p>fontspec: Is used in conjunction with XeLaTeX or LuaLaTeX to load OpenType, TrueType, and other system fonts in LaTeX documents. It provides advanced font selection and configuration features, allowing you to use any font installed on your system with LaTeX, offering greater flexibility and typographic control.</p> <p>geometry: Simplifies the task of setting page dimensions in LaTeX documents. It allows you to specify margins, paper size, and other page layout parameters easily. This package is particularly useful for adjusting the layout to meet specific formatting requirements or to create custom-sized documents.</p> <p>graphicx: For including and manipulating images, which is relevant if you want to include things like scalable vector graphics that KaTeX also supports in some setups.</p> <p>grffile: Extends the file name handling capabilities in LaTeX, allowing for the inclusion of graphics with filenames containing multiple dots or spaces. It is particularly useful when working with image files that have complex names, ensuring LaTeX can correctly locate and render them.</p> <p>hyperref: Is used to create hyperlinks within a LaTeX document, enhancing navigation in PDFs. It automatically converts references, citations, and table of contents entries into clickable links. It also allows you to create custom hyperlinks to URLs, files, and internal document locations.</p> <p>ifxetex: Provides a simple conditional command that allows you to check if your document is being compiled with XeTeX. It is often used in conjunction with ifluatex to create documents that are compatible with multiple LaTeX engines (e.g., pdfTeX, XeTeX, LuaTeX).</p> <p>ifluatex: Provides a conditional command that allows you to check if your document is being compiled with LuaTeX. It helps ensure compatibility across different LaTeX engines by enabling engine-specific configurations.</p> <p>inputenc: Allows you to specify the input encoding of your LaTeX document, which determines how characters in your source file are interpreted. For example, using \\usepackage[utf8]{inputenc} allows you to directly type accented characters and special symbols in UTF-8 encoding. Note that in more recent versions of LaTeX, inputenc is no longer necessary for UTF-8, as it is handled natively.</p> <p>listings: Provides tools for including and formatting source code in LaTeX documents. It supports syntax highlighting for many programming languages and allows customization of font styles, colors, line numbers, and other aspects of code presentation, making it ideal for technical documents or publications involving code.</p> <p>longtable: Allows you to create tables that span multiple pages in a LaTeX document. It automatically breaks the table across pages, repeating the header and/or footer rows as needed, which is particularly useful for documents containing large datasets or extensive tabular information.</p> <p>lmodern: Provides the Latin Modern font family, an enhanced version of the Computer Modern fonts that are the default in LaTeX. lmodern includes additional characters and glyphs, supporting better scalability and compatibility with modern typographic standards.</p> <p>mathspec: Allows you to use OpenType fonts for typesetting mathematics in XeLaTeX and LuaLaTeX. It enables the selection of different fonts for math mode, offering more typographic flexibility and the ability to match math fonts with text fonts.</p> <p>microtype: Enhances the typographic quality of LaTeX documents by enabling microtypographic extensions like character protrusion and font expansion. These techniques improve justification, spacing, and overall visual appeal of the text, especially in justified paragraphs.</p> <p>natbib: Provides advanced citation management for LaTeX documents. It offers various citation styles, supports both author-year and numerical citations, and integrates well with the standard bibtex bibliography system. It is widely used in academic writing to control citation and bibliography formatting.</p> <p>parskip: Changes the way paragraphs are formatted in LaTeX by adding vertical space between paragraphs and eliminating indentation. It is useful when a document\u2019s design calls for a clear separation between paragraphs rather than the traditional indentation.</p> <p>pifont: Allows the use of Dingbat fonts in LaTeX documents. It provides easy access to various symbol fonts, including the popular Zapf Dingbats, which are useful for adding checkmarks, crosses, and other decorative symbols to your document.</p> <p>polyglossia: Is the multilingual package for XeLaTeX and LuaLaTeX, similar to babel but specifically designed for modern LaTeX engines. It provides language-specific typographical rules, hyphenation patterns, and more, enabling the seamless integration of multiple languages in a single document.</p> <p>setspace: Provides tools to adjust the spacing between lines in a LaTeX document. It allows you to easily switch between single, one-and-a-half, and double line spacing, either globally or locally within a document, which is often required in academic or formal writing.</p> <p>ulem: Provides various types of underlining in LaTeX, such as single, double, wavy, or dotted underlines. It also offers commands for striking out text. Unlike the standard \\underline command, ulem allows underlines that break at line ends, making it more flexible for text decoration.</p> <p>upquote: Ensures that straight quotes (' and \") are typeset as they appear in code listings or verbatim text, rather than being converted to curly quotes. This is particularly important when including code snippets where the distinction between straight and curly quotes is semantically significant.</p> <p>xcolor: For coloring text and math expressions, which KaTeX supports natively.</p> <p>xeCJK: Is specifically designed for typesetting documents that include Chinese, Japanese, and Korean (CJK) characters in XeLaTeX. It provides better handling of CJK fonts, enabling proper spacing, line breaking, and font selection for these languages. The package integrates seamlessly with XeLaTeX\u2019s ability to use system fonts, allowing for high-quality typesetting of multilingual documents that include both CJK and Latin scripts. xeCJK also offers various options for fine-tuning the appearance of CJK text, such as adjusting character spacing and font sizes.</p>"},{"location":"teacher/reference/pdf_generation/#packages-to-be-considered","title":"Packages to be considered","text":"<p>amsfonts: Provides additional fonts for mathematical symbols and characters.</p> <p>mathtools: This is an extension of amsmath and provides additional features and improvements.</p> <p>array: Used for creating arrays and matrices, which are also supported in KaTeX.</p> <p>physics: While not directly necessary, this package is often used for simplified physics notation (like easier derivatives and vectors), which KaTeX also supports to a degree.</p> <p>unicode-math (optional): If you are using XeLaTeX or LuaLaTeX and want better handling of Unicode math symbols, similar to KaTeX's native handling.</p>"},{"location":"teacher/reference/pdf_generation/#list-of-latex-packages-emulated-by-katex","title":"List of LaTex packages emulated by KaTeX","text":"<p>Package Emulation</p>"},{"location":"teacher/reference/evaluation_functions/","title":"Evaluation Functions","text":"<p>Evaluation functions are responsible for taking in a user's response, comparing it with a correct answer, and providing feedback to the frontend application. Living as containerized Lambda functions on the cloud, they are infinitely customisable and language-agnostic. Content authors should be able to create their own at will. However, we are aware that in a lot of cases, this grading logic will be similar, which is why a few functions have already been created. </p>"},{"location":"teacher/reference/response_area_components/","title":"Response Area Components","text":"<p>These are what the user interacts with on the front-end. They check an input given by the student, and provide feedback. As React components, they admit a certain number of parameters which are described in this section.</p> <p></p>"},{"location":"teacher/reference/response_area_components/#response-area-creation","title":"Response Area creation","text":"<p>Response areas are added to the question field, and are configured for each question in the set.</p>"},{"location":"teacher/reference/response_area_components/#add-response-area","title":"Add Response Area","text":"<p>The user can add any number of response areas to a question part. These may be separated by text fields. If desired, adding a double space in the field will space out response areas.</p>"},{"location":"teacher/reference/response_area_components/#duplicate","title":"Duplicate","text":"<p>The user can duplicate the response area within the same part using the duplicate icon. When a response area is duplicated, data entered in the teacher edit mode is copied (such as input type, evaluation function, input symbols, pre and post text, answer, tests, cases, ...). Data entered in the teacher preview mode (such as comments) and student mode (comments, flags, likes, student solutions, ...) is not copied.</p>"},{"location":"teacher/reference/response_area_components/#reorder","title":"Reorder","text":"<p>It is possible to reorder response areas within the part using the \"drag and drop\" feature. It works in the same way a reordering of parts:</p> <p>Move your mouse cursor over the response are you want to move. Then, press and hold down the left mouse button, move the object to the location you desire, and release the mouse button to set it down.</p>"},{"location":"teacher/reference/response_area_components/#delete-response-area","title":"Delete Response Area","text":"<p>The user can delete a response area without any restrictions. A popup message appears to confirm the deletion.</p> <p>However, it is important to remember that there might be submissions against the response area you are trying to delete. If this is the case, the popup message will contain the relevant information.</p> <p>See more information about analytics against deleted response areas in Analytics</p>"},{"location":"teacher/reference/response_area_components/#response-area-configuration","title":"Response Area configuration","text":"<p>The user can configure a response area using the configure button:  which opens the 'Response Area Panel'. The panel follows a workflow designed around the way a teacher thinks:</p> <ul> <li>Input</li> <li>Evaluation</li> <li>Feedback</li> <li>Tests</li> </ul> <p>Each stage is in a separate tab. Teachers are recommended to be mindful of this process when creating a response area.</p>"},{"location":"teacher/reference/response_area_components/#input","title":"Input","text":"<ul> <li>Select an input style for the student by scrolling or filtering. These consist of the following:</li> <li>Matrix</li> <li>Number</li> <li>Boolean (True/false)</li> <li>Text (Suitable for short text answers)</li> <li>Table</li> <li>Multiple-choice</li> <li>Expression (Gives a preview for the typed symbolic expression)</li> <li>Numeric units (Two fields, allowing for units to be assessed)</li> <li>Code</li> <li>Essay (Suitable for long text answers)</li> <li>Each field has suitable evaluation functions. For example, a simple numerical answer is best suited to number, as this supports isSimilar, while assessing an equation is best suited to the expression foeld, as this supports compareExpressions.</li> <li>Each input field may be configured with a series of options:</li> <li>Enable live preview. Default TRUE for the EXPRESSION input type, to validate student input before submitting for feedback.</li> <li>Display input symbols. Default FALSE. When TRUE, the symbols and associated shortcut codes that may be required for a problem are displayed beneath the input field. These are configured in the 'Evaluate' tab. </li> <li>Include in PDF. Default FALSE except for MCQ. Only affects the PDF version. Includes pre/post response text in the PDF, with a blank space between.</li> <li>Pre/post response text (optional). To clarify to students what to input in the response area. Accepts plain text, including single-dollar-delimited latex. E.g. <code>Estimate $f(x)=$</code> is acceptable. When using fractions in this field, use <code>$\\dfrac{}{}$</code> as this is more legible.</li> <li>Answer. Enter a reference answer. This will typically be the absolute solution to a problem. When requesting a symbolic answer, it must be given in terms of the chosen symbol shortcuts.  Configure the answer where relevant (e.g. number of rows and columns).</li> <li>Response Area Preview: for teachers to verify the configuration</li> <li> <p>EVALUATE: configure how student expressions are evaluated. This is a 'no code' parametric configuration. Settings will be upgraded as the system improves.</p> </li> <li> <p>Evaluation Function - select an evaluation function from the list. For example:</p> <ul> <li>isSimilar will perform a basic numerical comparison between the reference answer and         student input, with a configurable level of absolute and relative uncertainty.</li> <li>compareExpressions is typically used where a symbolic answer is requested.</li> </ul> </li> <li>Parameters - configure as provided, and add new parameters as required. Details depend on the Evaluation Function.</li> <li> <p>Input symbols - define a dictionary of symbols and their equivalent in code form. This essentially associates a LaTeX-rendered symbol with a machine-readable variable label, with the LaTeX render returned to the student through the preview. These symbols may also be hiddent to students. All inputs are plain text. For example, the symbol <code>$f(x)$</code> may have code <code>fx</code> and alternatives <code>f_x</code>, <code>f(x)</code>, <code>f</code>. This dictionary will be provided to the evaluation function, even if the teacher has not displayed it to the student. This allow teachers to accept several alternative symbols, such as those with different cases or conventional expressions. The configuration of input symbols is a very important part of providing high quality feedback. Note that the 'visibility' Boolean applies if input symbols are displayed to students, otherwise it is irrelevant. It allows Teachers to communicate some symbols to students, while keeping others hidden to the student but visible to the evaluation function.</p> </li> <li> <p>FEEDBACK: add 'cases'. Each case is an alternative reference answer, with customised parameters, so that multiple cases can be dealt with independently. Cases can be used to capture multiple correct approaches that are not equivalent. Cases can also be used to identify common incorrect approaches and to provide customised feedback. The FEEDBACK tab is typically populated after students start using the system, and when data is available to point to common expressions. Configuring a case works similarly to setting up the default answer in the INPUT tab, with added options for changing the colour of the given feedback, give custom feedback and toggling whether the case answer should be considered correct or not. Adding custom feedback will overwrite the feedback produced by the evaluation function. When a response is submitted, it is evaluated for all cases and feedback for the first case that matches will be displayed. When determining which matched case is first, the default answer described in the INPUT tab will take precedence over all other cases, otherwise the feedback for the matched case with the lowest number will be displayed (i.e. the answer given in the INPUT tab can be considered to be Case 0).  Feedback fields also support LaTeX equations in both <code>$f(x)$</code> and <code>$$f(x)$$</code> formats, and Markdown inputs such as line breaks. Make sure to follow good typesetting practice in this field.</p> </li> </ul> <p></p> <ul> <li>TESTS: tests provide a systematic way to log what behaviour the teacher expects. It provides a useful record and an efficient way to retest the bevhaiour of a response area over time (e.g. as evaluation functions evolve, or as the subject matter itself changes).</li> </ul>"},{"location":"teacher/reference/response_area_components/#restrictions-on-changes-the-input-type","title":"Restrictions on changes: the input type","text":"<p>It is possible to change the input type (e.g. from Text to Number) without any restrictions until the response area is saved (with or without publishing) to students.</p> <p>After the response area is saved, it is still possible to change the input type, but it will result into replacing the response area by a new one. The previous response area will still exist, but only on the previous version of the question. When replacing the response area, all response area content data (those entered by teachers including tutorials, final answer and worked solutions) are copied, but any existing response area event data (student answers, click events and statistics) will remain linked only to the previous response area.</p> <p>Student answers, click events and statisticsthose data are never lost by deleting a response area, they are always preserved. Once a question is saved (with or without publishing), then any new changes are saved into a new (draft) version of the question. So, if e.g. a response area is deleted after a question was published, then it is deleted from the draft version only. And if this draft version is later published, then the previously published version is preserved (and with it the \"deleted\" response area and linked submissions).</p> <p>The reason why the input type change is restricted is to preserve high quality data analytics as explained in the examples below.</p>"},{"location":"teacher/reference/response_area_components/#an-example-1-changing-input-type-on-published-response-area","title":"An Example 1 - changing input type on PUBLISHED response area","text":""},{"location":"teacher/reference/response_area_components/#first-part","title":"FIRST Part","text":"<ul> <li>The teacher creates a new question with Response Areas RA1 and RA2. -&gt; The version of the question is QV1 with status DRAFT.</li> <li>The teacher is making changes (including the change of the input type if needed). -&gt; The changes are being saved into QV1 with no restrictions</li> <li>The teacher performs PUBLISH action (let's assume RA1 and RA2 input types are both Number for this example). -&gt; The QV1 version status is changed to PUBLISHED</li> <li>Students are submitting their answers -&gt; submissions are recorder against Response Area RA1 and RA2 (in the single Number format for both response areas)</li> <li>The teacher clicks on a question to edit it -&gt; with the first click a new question version QV2 is created with status DRAFT</li> <li>The teacher makes following changes (which are being recorded against QV2):<ul> <li>In RA1: adds a new Input Symbol -&gt; the change is recorded against RA1</li> <li>In RA2: the teacher unlocks and changes the input type -&gt; RA2 is deleted (from the question version QV2) and a new response area RA3 is created (let's assume input type Table for this example)</li> </ul> </li> <li>The teacher performs PUBLISH action -&gt; the QV2 is published (with response area RA1 with input type Number and response area RA3 with input type Table)</li> <li>Students are submitting their answers -&gt; submissions are recorder against Response Area RA1 (in the single Number format) and against Response Area RA3 (in the Table format)</li> </ul> <p>=&gt; No submissions are lost. The original submissions (in the Number format) are linked to the RA2, which is preserved on the question version QV1. New submissions (in the table format) are linked to the RA3 which is recorded on the question version QV2.</p> <p>Please note: All statistics and submissions are currently displayed against the published question version only. So, though the submissions against RA2 are preserved, it is not currently possible to see them. We are working on the improvement to make this possible.</p>"},{"location":"teacher/reference/response_area_components/#second-part-this-is-an-extension-of-the-first-part","title":"SECOND Part - this is an extension of the FIRST Part","text":"<ul> <li>The teacher decides to REVERT (the question created in the FIRST Part) to the question version QV1 -&gt; a new question version QV3 is created and the content of the QV1 is copied to QV3 -&gt; QV3 is DRAFT version which contains RA1 (input type Number) and RA2 (input type Number)</li> <li>The teacher performs PUBLISH action -&gt; the QV3 is published and the teacher can now see submissions against RA1 and RA2, but he cannot see anymore submissions against RA3 (these are preserved against the QV2 version)</li> </ul>"},{"location":"teacher/reference/response_area_components/#an-example-2-changing-input-type-on-saved-response-area","title":"An Example 2 - changing input type on SAVED response area","text":"<ul> <li>The teacher creates a new question with Response Areas RA1 and RA2. -&gt; The version of the question is QV1 with status DRAFT.</li> <li>The teacher is making changes (including the change of the input type if needed). -&gt; The changes are being saved into QV1 with no restrictions</li> <li>The teacher performs SAVE action (let's assume RA1 and RA2 input types are both Number for this example). -&gt; The QV1 version status is changed to SAVED</li> <li>The teacher clicks on a question to edit it -&gt; with the first click a new question version QV2 is created with status DRAFT</li> <li>The teacher makes following changes (which are being recorded against QV2):<ul> <li>In RA1: adds a new Input Symbol -&gt; the change is recorded against RA1</li> <li>In RA2: the teacher unlocks and changes the input type -&gt; RA2 is deleted (from the question version QV2) and a new response area RA3 is created (let's assume input type Table for this example)</li> </ul> </li> <li>The teacher performs PUBLISH action -&gt; the QV2 is published (with response area RA1 with input type Number and response area RA3 with input type Table)</li> <li>Students are submitting their answers -&gt; submissions are recorder against Response Area RA1 (in the single Number format) and against Response Area RA3 (in the Table format)</li> <li>The teacher decides to REVERT to the question version QV1 -&gt; a new question version QV3 is created and the content of the QV1 is copied to QV3 -&gt; QV3 is DRAFT version which contains RA1 (input type Number) and RA2 (input type Number)</li> <li>The teacher performs PUBLISH action -&gt; the QV3 is published and the teacher can now see submissions against RA1. There are no submissions against RA2 as it has not been (until now) published. Submissions against RA3 are not visible, but they are preserved against the question version QV2.</li> </ul>"},{"location":"teacher/reference/response_area_components/#an-example-3-adding-new-response-area-to-a-published-question","title":"An Example 3 - adding new response area to a published question","text":"<ul> <li>The teacher creates a new question with Response Areas RA1 and RA2. -&gt; The version of the question is QV1 with status DRAFT.</li> <li>The teacher is making changes (including the change of the input type if needed). -&gt; The changes are being saved into QV1 with no restrictions</li> <li>The teacher performs SAVE (or PUBLISH) action (let's assume RA1 and RA2 input types are both Number for this example). -&gt; The QV1 version status is changed to SAVE (or PUBLISHED)</li> <li>The teacher clicks on a question to edit it -&gt; with the first click a new question version QV2 is created with status DRAFT</li> <li>The teacher adds a new response area RA3</li> </ul> <p>=&gt; At this point the teacher is making changes in the question version QV2 (DRAFT) in which:</p> <pre><code>- The input types of RA1 and RA2 are locked, because they exist on a saved version QV1. It does not matter if QV1 is (only) saved or published or if there are  or there are not existing submissions. The reason why it is locked is that the teacher can revert into this version later after submissions are created. By locking it we are making sure that the \"unlock\" process will be triggered which will preserve the original response area and it will create a new response area and it will make sure that the submissions are linked to response area with compatible input type.\n- The input type of RA3 is not locked at this point, because RA3 does not (yet) exist on any saved question version.\n</code></pre>"},{"location":"teacher/reference/response_area_components/Expression/","title":"Expression","text":"<p>This response area is very similar to Text, differing in that it can display how the user's response was interpreted back to them through the 'live preview' feature. This works using the grading function, providing a <code>feedback.response_latex</code> field, which gets rendered.</p>"},{"location":"teacher/reference/response_area_components/Expression/#evaluation-function-options","title":"Evaluation Function Options","text":""},{"location":"teacher/reference/response_area_components/Expression/#issimilar","title":"<code>isSimilar</code>","text":"<p>Calculates the difference between the teacher answer (ans) and the student response (res); compares this to an allowable difference comprising an absolute tolerance (atol) and a relative tolerance (rtol).</p>"},{"location":"teacher/reference/response_area_components/Expression/#symbolicequal","title":"<code>symbolicEqual</code>","text":"<p>Compares two symbolic expressions for mathematical equivalence, using SymPy. See SymPy for further information.</p>"},{"location":"teacher/reference/response_area_components/Expression/#component-parameters","title":"Component Parameters","text":""},{"location":"teacher/reference/response_area_components/Expression/#post_response_text-optional","title":"<code>post_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Expression/#pre_response_text-optional","title":"<code>pre_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Expression/#allow-handwrite-experimental","title":"Allow Handwrite (Experimental)","text":"<p>Enables a handwriting canvas in the browser, which allows a student can use to draw their expression, rather than type using Sympy's syntax.</p>"},{"location":"teacher/reference/response_area_components/Expression/#photo-experimental","title":"Photo (Experimental)","text":"<p>Allows a student to upload their expression as an image, as an alternative to handwriting if the student isn't using a phone or tablet.</p>"},{"location":"teacher/reference/response_area_components/Expression/#setting-the-answer","title":"Setting The Answer","text":"<p>Type the correct answer into the 'Response Area Answer' using standard syntax. As the student enters the answer, this will be rendered using the 'live preview' feature, to ensure the correct expression has been entered.</p> <p>Use the 'Response Area Preview' to check the answer has been set correctly.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Expression/#example-student-response-area","title":"Example Student Response area","text":"<p>Correct response given </p> <p>Incorrect response given </p>"},{"location":"teacher/reference/response_area_components/Matrix/","title":"Matrix","text":"<p>Matrix response area. Will populate the component with a grid of text input fields, in order to facilitate inputing matrices.</p>"},{"location":"teacher/reference/response_area_components/Matrix/#evaluation-function-options","title":"Evaluation Function Options","text":""},{"location":"teacher/reference/response_area_components/Matrix/#arrayequal","title":"ArrayEqual","text":"<p>Evaluation function checks if the supplied response and answer arrays are within the optionally supplied tolerances. This is based on the numpy.allclose function. Numpy is a dependancy for this function, but it means that arrays of any shape (regular) can be compared efficiently.</p>"},{"location":"teacher/reference/response_area_components/Matrix/#arraysymbolicequal","title":"ArraySymbolicEqual","text":"<p>Very similar to the SymbolicEqual grading function, but grading any list of expressions instead. This algorithm can take any level of nesting for \"response\" and \"answer\" fields, as grading is done recursively (as long as both shapes are identical). Symbolic grading is done using the SymPy library. See SymPy for further information.</p>"},{"location":"teacher/reference/response_area_components/Matrix/#component-parameters","title":"Component Parameters","text":""},{"location":"teacher/reference/response_area_components/Matrix/#rows-and-cols-required","title":"<code>rows and cols</code> (required)","text":"<p>Required paramter, describes the shape of the Matrix to be displayed. </p> <p>In the 'Response area answer' section, the number of rows and columns can either be typed directly into the corresponding boxes, or adjusted using the up and down arrows, which appear once the mouse hovers over the input box.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Matrix/#post_response_text-optional","title":"<code>post_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Matrix/#pre_response_text-optional","title":"<code>pre_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Matrix/#setting-the-answer","title":"Setting The Answer","text":"<p>Once the required number of rows and cols has been selected, Each element of the matrix can be entered by clicking the individual input boxes and typing in the correct numbers.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Matrix/#example-student-response","title":"Example Student Response","text":"<p>Correct response given  Incorrect response given </p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/","title":"MultipleChoice","text":"<p>General multiple choice response area. Features multiple options for single answer and randomising the order.</p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#evaluation-function-options","title":"Evaluation Function Options","text":""},{"location":"teacher/reference/response_area_components/MultipleChoice/#arrayequal","title":"ArrayEqual","text":"<p>Evaluation function checks if the supplied response and answer arrays are within the optionally supplied tolerances. This is based on the numpy.allclose function. Numpy is a dependancy for this function, but it means that arrays of any shape (regular) can be compared efficiently.</p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#parameters","title":"Parameters","text":""},{"location":"teacher/reference/response_area_components/MultipleChoice/#options-required","title":"<code>options</code> (required)","text":"<p>This is an array containing strings, each representing an option in the multiple choice component. These are parsed using the <code>parseEquations</code> function, meaning they can support markdown styling and LaTeX. </p> <p>Example</p> <pre><code>\"options\": [\n  \"\\\\( 4x^2 + 2 = \\\\frac{\\\\delta y}{\\\\delta x} \\\\)\",\n  \"\\\\( \\\\pi = 3 \\\\)\",\n  \"\\\\( K_{iakb} U^{b}_{k} = f^{a}_{i} \\\\)\",\n  \"\\\\( 3 = \\\\pi \\\\)\",\n]\n</code></pre>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#randomise-optional","title":"<code>Randomise</code> (optional)","text":"<p>This is an optional boolean which will shuffle the options array on each render of this component. </p> <p>switch to 'randomise' </p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#singleanswer-optional","title":"<code>singleAnswer</code> (optional)","text":"<p>By default, each item options is rendered using the html <code>checkbox</code> input type. Setting the <code>singleAnswer</code> boolean flag will turn those into <code>radio</code> buttons, allowing the student to select only one option at a time.</p> <p>Note Changing this flag will alter the shape of the Response Structure, and potentially require changing the grading function type and settings.</p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#response-structure","title":"Response Structure","text":"<p>This is how the react component will structure the user's input to the Grading Gateway, when they press the check button. </p> <p>This structure is different depending on if the <code>singleAnswer</code> option was used:</p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#singleanswer-false-or-undefined","title":"<code>singleAnswer</code> == False (or undefined)","text":"<p>In this case, the user data is saved as an array with the same length as <code>options</code>, where each item is either a <code>1</code> or a <code>0</code> depending on if the corresponding option was selected.</p> <p>Example</p> <p>If for an instance where there are 4 options, and the first and third options were selected, the response field would be:</p> <pre><code>\"response\": [1, 0, 1, 0]\n</code></pre> <p>Example Screenshot: SingleAnswer = False  </p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#singleanswer-true","title":"<code>singleAnswer</code> == True","text":"<p>In this case, there is only one correct answer, and each option is displayed as a radio button. Therefore the response field contains only one integer, corresponding to the index of the selected option. </p> <p>Example</p> <p>If for an instance where there are 4 options, and the third option was selected, the response field would be:</p> <pre><code>\"response\": 2\n</code></pre> <p>Example Screenshot: SingleAnswer = True  </p>"},{"location":"teacher/reference/response_area_components/MultipleChoice/#example-student-response","title":"Example Student Response","text":"<p> This shows a response where <code>singleAnswer</code> was set to False, since each option is displayed as a <code>checkbox</code></p>"},{"location":"teacher/reference/response_area_components/Number/","title":"Number","text":"<p>Very similar to the Text response area, except the user response is parsed as a float.</p>"},{"location":"teacher/reference/response_area_components/Number/#evaluation-function-options","title":"Evaluation Function Options","text":""},{"location":"teacher/reference/response_area_components/Number/#issimilar","title":"<code>isSimilar</code>","text":"<p>Calculates the difference between the teacher answer (ans) and the student response (res); compares this to an allowable difference comprising an absolute tolerance (atol) and a relative tolerance (rtol). </p>"},{"location":"teacher/reference/response_area_components/Number/#isexactequal","title":"<code>isExactEqual</code>","text":"<p>A strict comparison in Python using '=='. This function is a basic utility but often not the function you really want to use because it is quite brittle.</p>"},{"location":"teacher/reference/response_area_components/Number/#setting-the-answer","title":"Setting The Answer","text":"<p>In the 'Response Area Answer' section, enter the required float into the input field. To test this, try typing correct and incorrect answers into the 'Response Area Preview' section.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Number/#component-parameters","title":"Component Parameters","text":""},{"location":"teacher/reference/response_area_components/Number/#post_response_text-optional","title":"<code>post_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Number/#pre_response_text-optional","title":"<code>pre_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Number/#grading_parameters-optional","title":"<code>grading_parameters</code> (optional)","text":"<ul> <li><code>atol</code>: Absolute tolerance parameter</li> <li><code>rtol</code>: Relative tolerance parameter</li> </ul> <p>Valid params include atol and rtol, which can be used in combination, or alone. As the comparison made is the following:</p> <p>is_correct = abs(res - ans) &lt;= (atol + rtol*abs(ans))</p>"},{"location":"teacher/reference/response_area_components/Number/#response-structure","title":"Response Structure","text":"<p>This is how the react component will structure the user's input to the Grading Gateway, when they press the check button. </p> <p>The response is simply sent as a float, parsed from the input field using the JavaScript <code>parseFloat</code> function.</p> <p>Example</p> <pre><code>\"response\": 15.8\n</code></pre>"},{"location":"teacher/reference/response_area_components/Number/#example-student-response","title":"Example Student Response","text":"<p>Correct response: </p> <p>Incorrect response: </p>"},{"location":"teacher/reference/response_area_components/NumericUnits/","title":"NumericUnits","text":"<p>Provides two input fields with <code>Number</code> and <code>Units</code> placeholder texts. This area will also display its associated grading function (as seen in the screenshot below). </p> <p>Note this area will display how the user's response was interpred using the <code>interp_string</code> field provided in the feedback object returned by that function (if it exists).</p>"},{"location":"teacher/reference/response_area_components/NumericUnits/#component-parameters","title":"Component Parameters","text":""},{"location":"teacher/reference/response_area_components/NumericUnits/#pre_response_text-optional","title":"<code>pre_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/NumericUnits/#response-structure","title":"Response Structure","text":"<p>This is how the react component will structure the user's input to the Grading Gateway, when they press the check button. </p> <p>In this case, the response is a single string which features the user's response to both fields separated by a space.</p> <p>Example</p> <pre><code>\"response\": \"150 g\"\n</code></pre>"},{"location":"teacher/reference/response_area_components/NumericUnits/#example-screenshot","title":"Example Screenshot","text":""},{"location":"teacher/reference/response_area_components/Table/","title":"Table","text":"<p>Table response area. Will populate the component with a grid of text input fields, in order to facilitate inputing elements of a table. The number of rows and columns can be specified, along with their corresponding names.</p>"},{"location":"teacher/reference/response_area_components/Table/#evaluation-function-options","title":"Evaluation Function Options","text":""},{"location":"teacher/reference/response_area_components/Table/#arrayequal","title":"ArrayEqual","text":"<p>Evaluation function checks if the supplied response and answer arrays are within the optionally supplied tolerances. This is based on the numpy.allclose function. Numpy is a dependancy for this function, but it means that arrays of any shape (regular) can be compared efficiently.</p>"},{"location":"teacher/reference/response_area_components/Table/#arraysymbolicequal","title":"ArraySymbolicEqual","text":"<p>Very similar to the SymbolicEqual grading function, but grading any list of expressions instead. This algorithm can take any level of nesting for \"response\" and \"answer\" fields, as grading is done recursively (as long as both shapes are identical). Symbolic grading is done using the SymPy library. See SymPy for further information.</p>"},{"location":"teacher/reference/response_area_components/Table/#component-parameters","title":"Component Parameters","text":""},{"location":"teacher/reference/response_area_components/Table/#rows","title":"<code>rows</code>","text":"<p>The number of rows required for the table can be entered into this input field, either through typing directly, or using thr up and down arrows located inside the box.</p>"},{"location":"teacher/reference/response_area_components/Table/#cols","title":"<code>cols</code>","text":"<p>The number of columns required for the table can be entered into this input field, either through typing directly, or using thr up and down arrows located inside the box.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Table/#post_response_text-optional","title":"<code>post_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Table/#pre_response_text-optional","title":"<code>pre_response_text</code> (optional)","text":"<p>Text block to be displayed to the left of the input field. Markdown and LaTeX are allowed following the usual syntax.</p>"},{"location":"teacher/reference/response_area_components/Table/#setting-the-answer","title":"Setting The Answer","text":"<p>Once the required number of rows and cols has been inputted, The names of each row and column should be changed depending on their corresponding variables. The value of each grid element can then be entered into individual input fields. </p> <p>If the row or column names are not changed, these will appear blank in the student response area.</p> <p></p>"},{"location":"teacher/reference/response_area_components/Table/#example-student-response","title":"Example Student Response","text":"<p>Correct response: </p> <p>Incorrect response: </p>"},{"location":"dev_eval_function_docs/compareBoolean/","title":"YourFunctionName","text":"<p>Edit on GitHub  View Code </p> <p>Brief description of what this evaluation function does, from the developer perspective</p>"},{"location":"dev_eval_function_docs/compareBoolean/#inputs","title":"Inputs","text":"<p>Specific input parameters which can be supplied when the <code>eval</code> command is supplied to this function.</p>"},{"location":"dev_eval_function_docs/compareBoolean/#outputs","title":"Outputs","text":"<p>Output schema/values for this function</p>"},{"location":"dev_eval_function_docs/compareBoolean/#examples","title":"Examples","text":"<p>List of example inputs and outputs for this function, each under a different sub-heading</p>"},{"location":"dev_eval_function_docs/compareBoolean/#simple-evaluation","title":"Simple Evaluation","text":"<pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre> <pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre>"},{"location":"user_eval_function_docs/compareBoolean/","title":"compareBoolean","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>EXPRESSION</code></li> <li><code>CODE</code></li> </ul> <p>This function uses SymPy to test two Boolean expressions for equivalence. Expressions are considered equal if they result in the same truth table.</p> <p>When answering questions on Booleans, it is easy for students to come up with equivalent expressions but in a different form (e.g.  if using a Karnaugh map versus by inspection). compareBoolean aims to alleviate some of the frustration that may arise by accepting any response that is equivalent to the correct answer.</p>"},{"location":"user_eval_function_docs/compareBoolean/#syntax","title":"Syntax","text":"<p>The current syntax expected by this function is based on the bitwise Boolean syntax used in C, Matlab and many other programming languages.</p> Operator Meaning LaTeX <code>A | B</code> <code>A OR B</code> \\(A + B\\) <code>A &amp; B</code> <code>A AND B</code> \\(A \\cdot B\\) <code>A ^ B</code> <code>A XOR B</code> \\(A \\oplus B\\) <code>~A</code> <code>NOT A</code> \\(\\overline{A}\\) <p>The order of precedence is as follows:</p> <ol> <li>NOT</li> <li>AND</li> <li>OR/XOR</li> </ol> <p>Brackets can be used to group terms and specify the order of evaluation. For example, <code>A &amp; B | C &amp; D</code> is interpreted as <code>(A &amp; B) | (C &amp; D)</code>.</p>"},{"location":"user_eval_function_docs/compareBoolean/#examples","title":"Examples","text":"<p>The function can understand a wide variety of complex boolean expressions. Here are some examples to illustrate its capabilities. Each pair of expressions is equivalent, and would be marked as \"correct\" by compareBoolean.</p> Response Answer Comments <code>x &amp; y</code> <code>y &amp; x</code> A trivial example, but probably the most common way student responses will differ from the answer <code>(x &amp; ~y) | (y &amp; ~z)</code> <code>x ^ y</code> Both expressions are equivalent to a logical exclusive or. <code>~(~x &amp; ~y)</code> <code>x | y</code> In this example de Morgan's laws have been used to find an equivalent representation of the OR operator."},{"location":"user_eval_function_docs/compareBoolean/#inputs","title":"Inputs","text":""},{"location":"user_eval_function_docs/compareBoolean/#optional-parameters","title":"Optional parameters","text":"<p>There are two optional parameters that can be set: <code>enforce_expression_equality</code> and <code>disallowed</code>.</p>"},{"location":"user_eval_function_docs/compareBoolean/#enforce_expression_equality","title":"<code>enforce_expression_equality</code>","text":"<p>If this Boolean parameter is true, the response and the answer must be strictly equal, i.e in the same form.</p>"},{"location":"user_eval_function_docs/compareBoolean/#disallowed","title":"<code>disallowed</code>","text":"<p>This parameter is a list of strings (<code>\"and\"</code>, <code>\"or\"</code>, <code>\"not\"</code> or <code>\"xor\"</code>). If one of these strings is present in the list, that operation will be disallowed. For example, responding <code>A | B</code> to an answer of <code>~(~A &amp; ~ B)</code> would normally be considered correct, but if a  <code>\"disallowed\": [\"or\"]</code> parameter were added, it would be considered incorrect. This could be useful for questions on De Morgan's laws, such as  expressing a function using only NAND gates.</p>"},{"location":"user_eval_function_docs/compareBoolean/#examples-from-integration-tests","title":"Examples from Integration Tests","text":""},{"location":"user_eval_function_docs/compareBoolean/#trivial-comparisons","title":"Trivial comparisons","text":"<p>The response and answer are exactly the same, so the response should be considered correct.</p> Response Answer Correct? <code>A &amp; B</code> <code>A &amp; B</code> \u2713 <p>Multi-character variable names are also supported</p> Response Answer Correct? <code>A &amp; Test</code> <code>A &amp; Test</code> \u2713"},{"location":"user_eval_function_docs/compareBoolean/#trivial-comparisons-but-not-identical","title":"Trivial comparisons, but not identical","text":"<p>Variables can appear in any order.</p> Response Answer Correct? <code>B &amp; A</code> <code>A &amp; B</code> \u2713 <p>The wrong operator is used, so this is incorrect as the two expressions have different truth tables.</p> Response Answer Correct? <code>A | B</code> <code>A &amp; B</code> \u2717"},{"location":"user_eval_function_docs/compareBoolean/#more-complex-comparisons","title":"More complex comparisons","text":"<p>XOR can be implemented using NAND or NOR</p> <p>Using NAND:</p> Response Answer Correct? <code>~(~(A &amp; ~(A &amp; B)) &amp; ~(B &amp; ~(A &amp; B)))</code> <code>A ^ B</code> \u2713 <p>Using NOR:</p> Response Answer Correct? <code>~(~(~A | ~B) | ~(A | B))</code> <code>A ^ B</code> \u2713 <p>A few examples using de Morgan's laws:</p> Response Answer Correct? <code>~(~A &amp; ~(B &amp; C))</code> <code>A | (B &amp; C)</code> \u2713 <code>A | ~(~B | ~C)</code> <code>A | (B &amp; C)</code> \u2713"},{"location":"dev_eval_function_docs/arrayEqual/","title":"ArrayEqual","text":"<p>Edit on GitHub  View Code </p> <p>Evaluation function checks if the supplied response and answer arrays are within the optionally supplied tolerances. This is based on the numpy.allclose function. Numpy is a dependancy for this function, but it means that arrays of any shape (regular) can be compared efficiently.</p>"},{"location":"dev_eval_function_docs/arrayEqual/#inputs","title":"Inputs","text":"<p>Valid params include <code>atol</code> and <code>rtol</code>, which can be used in combination, or alone. (just like the <code>IsSimilar</code> grading function)</p> <pre><code>{\n  \"response\": \"&lt;array&gt;\",\n  \"answer\": \"&lt;array&gt;\",\n  \"params\": {\n    \"atol\": \"&lt;number&gt;\",\n    \"rtol\": \"&lt;number&gt;\"\n  }\n}\n</code></pre> <p>Note: <code>response</code> and <code>answer</code> arrays are parsed using <code>np.array(dtype=np.float32)</code>, any errors this causes are returned and the comparison fails.</p>"},{"location":"dev_eval_function_docs/arrayEqual/#atol","title":"<code>atol</code>","text":"<p>Absolute tolerance parameter</p>"},{"location":"dev_eval_function_docs/arrayEqual/#rtol","title":"<code>rtol</code>","text":"<p>Relative tolerance parameter</p>"},{"location":"dev_eval_function_docs/arrayEqual/#outputs","title":"Outputs","text":""},{"location":"dev_eval_function_docs/arrayEqual/#examples","title":"Examples","text":""},{"location":"user_eval_function_docs/arrayEqual/","title":"ArrayEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>MATRIX</code></li> <li><code>TABLE</code></li> <li><code>MULTIPLE_CHOICE</code></li> </ul> <p>This function is used to compare two number arrays/vectors/matrices, provided absolute and/or relative tolerance parameters <code>rtol</code> and <code>atol</code>. This is carried out using the numpy.allclose function.</p>"},{"location":"user_eval_function_docs/arrayEqual/#optional-parameters","title":"Optional parameters","text":"<p>There is one optional parameter: <code>feedback_for_incorrect_response</code>.</p>"},{"location":"user_eval_function_docs/arrayEqual/#feedback_for_incorrect_response","title":"<code>feedback_for_incorrect_response</code>","text":"<p>All feedback for all incorrect responses will be replaced with the string that this parameter is set to.</p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/","title":"WolframAlphaEqual","text":"<p>Edit on GitHub  View Code </p> <p>This simple evaluation function uses the WolframAlpha API to compare two strings. It performs two requests in parallel:</p> <ol> <li>One to check how the user's <code>response</code> is interpreted by WolframAlpha</li> <li>One to compare the <code>response</code> to the <code>answer</code>, by submitting the following input to the api: <code>res == ans</code></li> </ol> <p>NOTE: To work, this grading script requires a valid WolframAlpha AppID! This should be stored in the <code>WOLFRAM_APPID</code> env variable.</p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#inputs","title":"Inputs","text":"<p>This function doesn't need any parameters, simply two response and answer fields <pre><code>{\n  \"response\": \"&lt;string&gt;\",\n  \"answer\": \"&lt;string&gt;\"\n}\n</code></pre></p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#outputs","title":"Outputs","text":"<pre><code>{\n  \"is_correct\": \"&lt;bool or null&gt;\",\n  \"interp_string\": \"&lt;string&gt;\",\n  \"raw_comp\": \"&lt;dict&gt;\",\n  \"raw_interp\": \"&lt;dict&gt;\"\n}\n</code></pre>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#is_correct","title":"<code>is_correct</code>","text":"<p>Extracted from the second WolframAlpha call. More specifically, the <code>\"id\": \"Result\"</code> pod's first <code>subpod.plaintext</code> value.</p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#interp_string","title":"<code>interp_string</code>","text":"<p>Human friendly string which indicates how WolframAlpha interpreted the user response. Extracted from the first WolframAlpha call. Corresponds also to the value of <code>plaintext</code> from the first <code>subpod</code> in the <code>\"id\" : \"Input\"</code> pod.</p> <p>For example, if the user entered <code>10 kg</code>, this might look like <code>10 kg (kilograms)</code></p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#raw_comp","title":"<code>raw_comp</code>","text":"<p>For debugging, passes the raw json result obtained from the second WolframAlpha call (comparison).</p>"},{"location":"dev_eval_function_docs/wolframAlphaEqual/#raw_interp","title":"<code>raw_interp</code>","text":"<p>For debugging, passes the raw json result obtained from the first WolframAlpha call (interpretation).</p> <p>Will also return <code>error</code> detailing any issues that were encountered along the way</p>"},{"location":"user_eval_function_docs/wolframAlphaEqual/","title":"WolframAlphaEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>NUMERIC_UNITS</code></li> </ul> <p>This function uses the WolframAlpha engine to compare a student's response to the correct answer. Its power can be leveraged to realise physical-units-aware evaluation, symbolic expression comparison and much more. No validation is carried out on function inputs, values are simply sent to the API in the form <code>response == answer</code>. So for example if the student provided <code>10 kilograms</code>, and the answer was defined as <code>0.01 tonnes</code>, then <code>10 kilograms == 0.01 tonnes</code> is sent to the WolframAlpha API.</p>"},{"location":"dev_eval_function_docs/arraySymbolicEqual/","title":"ArraySymbolicEqual","text":"<p>Edit on GitHub  View Code </p> <p>This evaluation function can take any level of nesting for \"response\" and \"answer\" fields, as comparison is done recursively (as long as both shapes are identical). Symbolic grading is done using the SymbolicEqual function, called using the experimental EvaluationFunctionClient from the evaluation-function-utils library.</p>"},{"location":"dev_eval_function_docs/arraySymbolicEqual/#inputs","title":"Inputs","text":"<p>This compares cells using the <code>symbolicEqual</code> function. Please consult that function's documentation for details on it's allowable parameters, as the ones provided to this function are fed through as they are.</p> <pre><code>{\n  \"response\": \"&lt;array (of arrays) of strings&gt;\",\n  \"answer\": \"&lt;array (of arrays) of strings&gt;\",\n  \"params\": {\n            \"Any params accepted by symbolicEqual\"\n    }\n}\n</code></pre> <p>Note: <code>response</code> and <code>answer</code> arrays should ultimately have string elements, even though they can have any level of nesting.</p>"},{"location":"dev_eval_function_docs/arraySymbolicEqual/#outputs","title":"Outputs","text":"<p>Outputs to the <code>grade</code> command look like the following:</p> <pre><code>{\n  \"command\": \"eval\",\n  \"result\": {\n    \"is_correct\": \"&lt;bool&gt;\",\n    \"detailed_feedback\": [\n      {\n        \"is_correct\": \"&lt;bool&gt;\",\n        \"level\": \"&lt;sympy correctness level&gt;\"\n      },\n      {\n        \"...\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Note: The <code>detailed_feedback</code> result field is of the same shape as the answer, giving specific information for the correctness of each cell in the evaluated array</p>"},{"location":"dev_eval_function_docs/arraySymbolicEqual/#examples","title":"Examples","text":""},{"location":"dev_eval_function_docs/arraySymbolicEqual/#simple-arrays","title":"Simple Arrays","text":"<p>Correct behaviour Input <pre><code>{\n  \"response\": [\"a\", \"b + c\"],\n  \"answer\": [\"a\", \"c + b\"]\n}\n</code></pre></p> <p>Output <pre><code>{\n    \"command\": \"eval\",\n    \"result\": {\n        \"is_correct\": true,\n        \"detailed_feedback\": [\n            {\n                \"is_correct\": true,\n                \"level\": \"1\"\n            },\n            {\n                \"is_correct\": true,\n                \"level\": \"1\"\n            }\n        ]\n    }\n}\n</code></pre></p> <p>Incorrect behaviour Input <pre><code>{\n  \"response\": [\"a\", \"b + 2*c\"],\n  \"answer\": [\"a\", \"c + b\"]\n}\n</code></pre></p> <p>Output <pre><code>{\n    \"command\": \"eval\",\n    \"result\": {\n        \"is_correct\": false,\n        \"detailed_feedback\": [\n            {\n                \"is_correct\": true,\n                \"level\": \"1\"\n            },\n            {\n                \"is_correct\": false\n            }\n        ]\n    }\n}\n</code></pre></p>"},{"location":"user_eval_function_docs/arraySymbolicEqual/","title":"ArraySymbolicEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>MATRIX</code></li> <li><code>NUMBER</code></li> <li><code>TABLE</code></li> </ul> <p>This function compares two symbolic expression arrays, with any level of nesting (2D, 3D, irregular shape, ...). Each cell is compared using the <code>SymbolicEqual</code> evaluation function.</p>"},{"location":"user_eval_function_docs/arraySymbolicEqual/#inputs","title":"Inputs","text":"<p>This function support all input parameters that <code>SymbolicEqual</code> uses.</p>"},{"location":"dev_eval_function_docs/isExactEqual/","title":"IsExactEqual","text":"<p>Edit on GitHub  View Code </p> <p>Could be qualified as the simplest form of evaluation function, testing exact equality. This function will use the default python <code>==</code> test to compare answer and responses. It doesn't infer any types - meaning it requires a <code>params.type</code> to be supplied.</p>"},{"location":"dev_eval_function_docs/isExactEqual/#inputs","title":"Inputs","text":"<p>This function requires a parameter to function properly: <pre><code>{ \n  \"params\": {\n    \"type\": \"&lt;string&gt;\" (any of [\"int\", \"float\", \"str\", \"dict\"])\n  }\n  \"response\": &lt;&gt;,\n  \"answer\": &lt;&gt;\n}\n</code></pre></p>"},{"location":"dev_eval_function_docs/isExactEqual/#outputs","title":"Outputs","text":"<p>Outputs to the <code>grade</code> command will feature:</p> <pre><code>{\n  \"command\": \"eval\",\n  \"result\": {\n    \"is_correct\": \"&lt;bool&gt;\"\n  }\n}\n</code></pre>"},{"location":"dev_eval_function_docs/isExactEqual/#examples","title":"Examples","text":""},{"location":"dev_eval_function_docs/isExactEqual/#simple-string-comparison","title":"Simple String Comparison","text":"<pre><code>{\n  \"answer\": \"hydrophobic\",\n  \"response\" \"hydrophobic\",\n  \"params\": {\n    \"type\": \"str\"\n  }\n}\n</code></pre> <pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre>"},{"location":"user_eval_function_docs/isExactEqual/","title":"IsExactEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>NUMBER</code></li> <li><code>BOOLEAN</code></li> <li><code>TEXT</code></li> </ul> <p>Use this function to check the exact equality between the student response and answer. This function requires a 'type' parameter which specifies how each of the two inputs should be cast before direct comparison in python.</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/","title":"ShortTextAnswer","text":"<p>Edit on GitHub  View Code </p> <p>This function evaluates the similarity value between two short texts, as well as identifying certain key strings in a student's answer.</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#inputs","title":"Inputs","text":"<p><code>keystrings</code> - Optional parameter. Represents a list of keystring objects which the function will search for in the answer.</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#keystring-object","title":"<code>keystring</code> object","text":"<p>The <code>keystring</code> object contains several fields which affect how it will be interpreted:</p> <ul> <li><code>string</code> - Required. The actual keystring being searched for.</li> <li><code>exact_match</code> - Optional. A boolean value indicating whether to search for the exact string or for a semantically similar one. Defaults to <code>false</code></li> <li><code>should_contain</code> - Optional. A boolean value indicating whether it is expected for the keystring to be found in the answer or not. Defaults to <code>true</code>. Setting this flag to false indicates that a correct response will not contain the specified keystring.</li> <li><code>custom_feedback</code> - Optional. A feedback string to be returned if the <code>string</code> was not found (or if it was, in case <code>should_contain</code> was set to <code>false</code>). Defaults to <code>None</code>, in which case a generic response will be generated containing the string searched for.</li> </ul>"},{"location":"dev_eval_function_docs/shortTextAnswer/#outputs","title":"Outputs","text":"<p>The function will return an object with 3 fields of interest. the <code>is_correct</code> and <code>feedback</code> fields are required by LambdaFeedback to present feedback to the user. The <code>result</code> field is only used for development. <pre><code>{\n    \"is_correct\": \"&lt;bool&gt;\",\n    \"result\": {\n        \"response\": \"&lt;string&gt;\",\n        \"processing_time\": \"&lt;double&gt;\",\n    },\n    \"feedback\": \"string\"\n}\n</code></pre></p> <ul> <li><code>response</code> - The student answer. USed for debugging purposes.</li> <li><code>processing_time</code> - The time it took for the function to evaluate</li> </ul> <p>If the function identified a problematic keystring, the result object will have an additional field: * <code>keystring-scores</code> - list(string, double). List of the provided keystrings and their best similarity scores that were found in the answer.</p> <p>Otherwise, it will have the additional fields: * <code>method</code> - string. Either \"w2v\" or \"BOW vector similarity\". * <code>similarity_value</code> - double. The similarity value between the response and the answer.</p> <p>If the method is w2v, it means the two texts were found to be similar. Otherwise, a BOW vector similarity check is performed in order to identify the most likely word that caused the texts to be found dissimilar.</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#initial-setup","title":"Initial SetUp","text":"<p>Follow Docker Image instructions and run  <code>docker build -t &lt;image_name&gt; .</code> in app/</p> <p>Otherwise if setup locally: 1. create a venv 2. in the venv <code>pip install -r app/requirements.txt</code> 3. if errors encountered with nltk packages, follow <code>testing_nltk.py</code> instructions</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#examples","title":"Examples","text":"<p>List of example inputs and outputs for this function, each under a different sub-heading</p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#example-simple-input-no-keystring","title":"Example simple input, no keystring","text":"<p>Input <pre><code>{\n    \"response\": \"Density, velocity, viscosity, length\",\n    \"answer\": \"Density, speed, Viscosity, Length\",\n}\n</code></pre></p> <p>Output <pre><code>{\n    'is_correct': True, \n    'result': {\n        'response': 'Density, speed, Viscosity, Length',\n        'processing_time': 0.022912219000000178, \n        'method': 'w2v', \n        'similarity_value': 0.9326027035713196}, \n    'feedback': 'Confidence: 0.933%'\n}\n</code></pre></p>"},{"location":"dev_eval_function_docs/shortTextAnswer/#example-keystring-input","title":"Example keystring input","text":"<p>Input <pre><code>{\n    \"response\": \"Molecules are made out of atoms\",\n    \"answer\": \"Many atoms form a molecule\",\n    'keystrings': [\n        {'string': 'molecule'}, \n        {'string': 'proton', 'exact_match': True}\n    ]\n}\n</code></pre></p> <p>Output <pre><code>{\n    'is_correct': False, \n    'result': {\n        'response': 'Molecules are made out of atoms', \n        'processing_time': 0.30640586500000033, \n        'keystring-scores': [\n            ('molecule', 0.990715997949492), \n            ('proton', 0.9186190596675989) # Searched for with exact match, therefore not a match.\n        ]\n    }, \n    'feedback': \"Cannot determine if the answer is correct. Please provide more information about 'proton'\"}\n</code></pre></p>"},{"location":"user_eval_function_docs/shortTextAnswer/","title":"ShortTextAnswer","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> </ul> <p>This function evaluates the similarity value between two short texts, as well as identifying certain key strings in a student's answer.</p>"},{"location":"user_eval_function_docs/shortTextAnswer/#inputs","title":"Inputs","text":"<p><code>keystrings</code> - Optional parameter. Represents a list of keystring objects which the function will search for in the answer.</p>"},{"location":"user_eval_function_docs/shortTextAnswer/#keystring-object","title":"<code>keystring</code> object","text":"<p>The <code>keystring</code> object contains several fields which affect how it will be interpreted:</p> <ul> <li><code>string</code> - Required. The actual keystring being searched for.</li> <li><code>exact_match</code> - Optional. A boolean value indicating whether to search for the exact string or for a semantically similar one. Defaults to <code>false</code></li> <li><code>should_contain</code> - Optional. A boolean value indicating whether it is expected for the keystring to be found in the answer or not. Defaults to <code>true</code>. Setting this flag to false indicates that a correct response will not contain the specified keystring.</li> <li><code>custom_feedback</code> - Optional. A feedback string to be returned if the <code>string</code> was not found (or if it was, in case <code>should_contain</code> was set to <code>false</code>). Defaults to <code>None</code>, in which case a generic response will be generated containing the string searched for.</li> </ul>"},{"location":"user_eval_function_docs/shortTextAnswer/#outputs","title":"Outputs","text":"<p>The function will return an object with 3 fields of interest. the <code>is_correct</code> and <code>feedback</code> fields are required by LambdaFeedback to present feedback to the user. The <code>result</code> field is only used for development. <pre><code>{\n    \"is_correct\": \"&lt;bool&gt;\",\n    \"result\": {\n        \"response\": \"&lt;string&gt;\",\n        \"processing_time\": \"&lt;double&gt;\",\n    },\n    \"feedback\": \"string\"\n}\n</code></pre></p> <ul> <li><code>response</code> - The student answer. USed for debugging purposes.</li> <li><code>processing_time</code> - The time it took for the function to evaluate</li> </ul> <p>If the function identified a problematic keystring, the result object will have an additional field: * <code>keystring-scores</code> - list(string, double). List of the provided keystrings and their best similarity scores that were found in the answer.</p> <p>Otherwise, it will have the additional fields: * <code>method</code> - string. Either \"w2v\" or \"BOW vector similarity\". * <code>similarity_value</code> - double. The similarity value between the response and the answer.</p> <p>If the method is w2v, it means the two texts were found to be similar. Otherwise, a BOW vector similarity check is performed in order to identify the most likely word that caused the texts to be found dissimilar.</p>"},{"location":"user_eval_function_docs/shortTextAnswer/#examples","title":"Examples","text":"<p>List of example inputs and outputs for this function, each under a different sub-heading</p>"},{"location":"user_eval_function_docs/shortTextAnswer/#example-simple-input-no-keystring","title":"Example simple input, no keystring","text":"<p>Input <pre><code>{\n    \"response\": \"Density, velocity, viscosity, length\",\n    \"answer\": \"Density, speed, Viscosity, Length\",\n}\n</code></pre></p> <p>Output <pre><code>{\n    'is_correct': True, \n    'result': {\n        'response': 'Density, speed, Viscosity, Length',\n        'processing_time': 0.022912219000000178, \n        'method': 'w2v', \n        'similarity_value': 0.9326027035713196}, \n    'feedback': 'Confidence: 0.933%'\n}\n</code></pre></p>"},{"location":"user_eval_function_docs/shortTextAnswer/#example-keystring-input","title":"Example keystring input","text":"<p>Input <pre><code>{\n    \"response\": \"Molecules are made out of atoms\",\n    \"answer\": \"Many atoms form a molecule\",\n    'keystrings': [\n        {'string': 'molecule'}, \n        {'string': 'proton', 'exact_match': True}\n    ]\n}\n</code></pre></p> <p>Output <pre><code>{\n    'is_correct': False, \n    'result': {\n        'response': 'Molecules are made out of atoms', \n        'processing_time': 0.30640586500000033, \n        'keystring-scores': [\n            ('molecule', 0.990715997949492), \n            ('proton', 0.9186190596675989) # Searched for with exact match, therefore not a match.\n        ]\n    }, \n    'feedback': \"Cannot determine if the answer is correct. Please provide more information about 'proton'\"}\n</code></pre></p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/","title":"ComparePhysicalQuantities","text":"<p>Edit on GitHub  View Code </p> <p>Evaluation function which proveds some basic some dimensional analysis functionality.</p> <ul> <li>DEPRECATED Comparing physical quantities RECOMMENDED ALTERNATIVE: CompareExpressions with the <code>physical_quantity</code> parameter set to <code>true</code></li> <li>Substitutions of symbols before comparison of expressions is done</li> <li>Checking if a comma separated list of expressions can be interpreted as a set groups that satisfies the Buckingham Pi theorem</li> </ul> <p>Note: When the <code>quantities</code> grading parameter is set, this function cannot handle short form symbols for units. Thus when defining quantities all units must be given with full names in lower-case letters. For example <code>Nm/s</code> or <code>Newton*metre/SECOND</code> will not be handled correctly, but <code>newton*metre/second</code> will.</p> <p>Note: Prefixes have lower precedence than exponentiation, e.g. <code>10*cm**2</code> will be interpreted as \\(10 \\cdot 10^{-2} \\mathrm{metre}^2\\) rather than \\(10 (10^(-2)\\mathrm{metre})^2\\).</p> <p>Note: This function allows omitting <code>*</code> and using <code>^</code> instead of <code>**</code> if the grading parameter <code>strict_syntax</code> is set to false. In this case it is also recommended to list any multicharacter symbols (that are not part of the default list of SI units) expected to appear in the response as input symbols.</p> <p>Note: Only the short forms listed in the tables below are accepted. Not all units that are supported have short forms (since this leads to ambiguities).</p> <p>Note: When using the short forms the following convention is assumed: - Long form names takes precedence over sequences of short forms, e.g.  e.g. <code>mN</code> will be interpreted as <code>milli newton</code>, <code>Nm</code> as <code>newton metre</code>, <code>mmN</code> as <code>milli metre newton</code>, <code>mNm</code> as <code>milli newton metre</code> and <code>Nmm</code> as <code>newton milli metre</code>. - Short form symbols of prefixes will take precedence over short form symbols of units from the left, e.g. - If there is a short form symbol for a prefix that collides with the short form for a unit (i.e. <code>m</code>) then it is assumed the that unit will always be placed to the right of another unit in compound units, e.g. <code>mN</code> will be interpreted as <code>milli newton</code>, <code>Nm</code> as <code>newton metre</code>, <code>mmN</code> as <code>milli metre newton</code>, <code>mNm</code> as <code>milli newton metre</code> and <code>Nmm</code> as <code>newton milli metre</code>. - Longer short form symbols take precedence over shorter short forms, e.g. <code>sr</code> will be interpreted as <code>steradian</code> instead of <code>second radian</code>.</p> <p>Note: setting <code>elementary_functions</code> to true will disable using short forms symbols for units.</p> <p>Note: When running the unit test some tests are expected to take much longer than the other. These tests can be skipped by adding <code>skip_resource_intensive_tests</code> as a command line argument to improve iteration times.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#changing-default-feedback-messages","title":"Changing default feedback messages","text":"<p>The feedback messages can be set on a per-task basis (see description of the <code>custom_feedback</code> input parameter).</p> <p>The default feedback messages are defined in <code>feedback_responses_list</code> defined near the top of <code>evaulation.py</code>, which contains a list of dictionaries of feedback responses that are used througout the code. All feedback messages visible to learners are defined in these dictionaries. The entries in the dictionaries are either be string of functions that return strings.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#inputs","title":"Inputs","text":"<p>All input parameters need to be supplied via the Grading parameters panel.</p> <p>There are seven optional parameters that can be set: <code>elementary_functions</code>, <code>substitutions</code>, <code>quantities</code>, <code>strict_syntax</code>, <code>rtol</code>, <code>atol</code> and <code>comparison</code>.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#custom_feedback","title":"<code>custom_feedback</code>","text":"<p>Custom feedback can be set on a per-task basis. Note: Custom feedback only supports fixed strings, this means that for some situations the custom feedback cannot be as detailed as the default feedback.</p> <p>The parameter must be set as a dictionary with keys from the feedback tags listed below. The value for each key can be any string.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#feedback-tags-for-all-comparisons","title":"Feedback tags for all comparisons","text":"<ul> <li><code>PARSE_ERROR_WARNING</code> Response cannot be parsed as an expression or physical quantity.</li> <li><code>PER_FOR_DIVISION</code> Warns about risk of ambiguity when using <code>per</code> instead <code>/</code> for division.</li> <li><code>STRICT_SYNTAX_EXPONENTIATION</code> Warns that <code>^</code> cannot be used for exponentiation when <code>strict_syntax</code> is set to <code>true</code>.</li> <li><code>QUANTITIES_NOT_WRITTEN_CORRECTLY</code> Text in error message that appears if list of quantities could not be parsed.</li> <li><code>SUBSTITUTIONS_NOT_WRITTEN_CORRECTLY</code> Text in error message that appears if list of substitutions could not be parsed.</li> </ul>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#feedback-tags-for-buckinghampi-comparison","title":"Feedback tags for <code>buckinghamPi</code> comparison","text":"<ul> <li><code>VALID_CANDIDATE_SET</code> Message that is displayed when a response is found to be a valid set of groups. Note: setting this will not affect the Correct/Incorrect message, it will only add further text.</li> <li><code>NOT_DIMENSIONLESS</code> Message displayed when at least one groups is not dimensionless.</li> <li><code>MORE_GROUPS_THAN_REFERENCE_SET</code> Message displayed when the response contains more groups than necessary.</li> <li><code>CANDIDATE_GROUPS_NOT_INDEPENDENT</code> Message displayed when the groups in the response are not independent.</li> <li><code>TOO_FEW_INDEPENDENT_GROUPS</code> Message displayed when the response contains fewer groups than necessary.</li> <li><code>UNKNOWN_SYMBOL</code> Message displayed when the response contains some undefined symbol.</li> <li><code>SUM_WITH_INDEPENDENT_TERMS</code>  Message displayed when the response has too few groups but one (or more) of the groups is a sum with independent terms.</li> </ul>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#elementary_functions","title":"<code>elementary_functions</code>","text":"<p>When using implicit multiplication function names with mulitple characters are sometimes split and not interpreted properly. Setting <code>elementary_functions</code> to true will reserve the function names listed below and prevent them from being split. If a name is said to have one or more alternatives this means that it will accept the alternative names but the reserved name is what will be shown in the preview.</p> <p><code>sin</code>, <code>sinc</code>, <code>csc</code> (alternative <code>cosec</code>), <code>cos</code>, <code>sec</code>, <code>tan</code>, <code>cot</code> (alternative <code>cotan</code>), <code>asin</code> (alternative <code>arcsin</code>), <code>acsc</code> (alternatives <code>arccsc</code>, <code>arccosec</code>), <code>acos</code> (alternative <code>arccos</code>), <code>asec</code> (alternative <code>arcsec</code>), <code>atan</code> (alternative <code>arctan</code>), <code>acot</code> (alternatives <code>arccot</code>, <code>arccotan</code>), <code>atan2</code> (alternative <code>arctan2</code>), <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>csch</code> (alternative <code>cosech</code>), <code>sech</code>, <code>asinh</code> (alternative <code>arcsinh</code>), <code>acosh</code> (alternative <code>arccosh</code>), <code>atanh</code> (alternative <code>arctanh</code>), <code>acsch</code> (alternatives <code>arccsch</code>, <code>arcosech</code>), <code>asech</code> (alternative <code>arcsech</code>), <code>exp</code> (alternative <code>Exp</code>), <code>E</code> (equivalent to <code>exp(1)</code>, alternative <code>e</code>), <code>log</code>, <code>sqrt</code>, <code>sign</code>, <code>Abs</code> (alternative <code>abs</code>), <code>Max</code> (alternative <code>max</code>), <code>Min</code> (alternative <code>min</code>), <code>arg</code>, <code>ceiling</code> (alternative <code>ceil</code>), <code>floor</code></p> <p>Note: setting <code>elementary_functions</code> to true will disable using short forms symbols for units.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#substitutions","title":"<code>substitutions</code>","text":"<p>String that lists all substitutions that should be done to the answer and response inputs before processing.</p> <p>Each substitution should be written in the form <code>('original string','substitution string')</code> and all pairs concatenated into a single string. Substitutions can be grouped by adding <code>|</code> between two substitutions. Then all substitutions before <code>|</code> will be performed before the substitutions after <code>|</code>.</p> <p>The input can contain an arbitrary number of substitutions and <code>|</code> symbols.</p> <p>Note that using substitutions will replace all default definitions of quantities and dimensions.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#quantities","title":"<code>quantities</code>","text":"<p>String that lists all quantities that can be used in the answer and response.</p> <p>Each quantity should be written in the form <code>('quantity name','(units)')</code> and all pairs concatenated into a single string. See tables below for available default units.</p> <p>Whenever units are used they must be written exactly as in the left columns of the tables given below (no short forms or single-character symbols) and units must be multiplied (or divided) by each other, as well as any accompanying quantities.</p> <p>NOTE: Using units and predefined quantities at the same time in an answer or response can cause problems (especially if quantities are denoted using single characters). Ideally it should be clear that either predefined quantities, or units should only be used from the question.</p> <p>If the <code>comparison</code> parameter is set to <code>dimensions</code>, it is not necessary to give exact units for each quantity, but the dimensions must be given instead. See tables below for available default dimensions.</p> <p>If the <code>comparison</code> parameter is set to <code>buckinghamPi</code>, then <code>quantities</code> should be set in a different way. See the detailed description of <code>buckinghamPi</code> further down.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#table-base-si-units","title":"Table: Base SI units","text":"<p>SI base units taken from Table 1 of https://physics.nist.gov/cuu/Units/units.html</p> <p>Note that gram is used as a base unit instead of kilogram.</p> SI base unit Symbol Dimension name metre m length gram g mass second s time ampere A electriccurrent kelvin k temperature mole mol amountofsubstance candela cd luminousintensity"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#table-si-prefixes","title":"Table: SI prefixes","text":"<p>SI base units taken from Table 5 of https://physics.nist.gov/cuu/Units/prefixes.html</p> SI Prefix Symbol Factor SI Prefix Symbol Factor yotta Y \\(10^{24}\\) deci d \\(10^{-1}\\) zetta Z \\(10^{21}\\) centi c \\(10^{-2}\\) exa' E \\(10^{18}\\) milli m \\(10^{-3}\\) peta P \\(10^{15}\\) micro mu \\(10^{-6}\\) tera T \\(10^{12}\\) nano n \\(10^{-9}\\) giga G \\(10^{9}\\) pico p \\(10^{-12}\\) mega M \\(10^{6}\\) femto f \\(10^{-15}\\) kilo k \\(10^{3}\\) atto a \\(10^{-18}\\) hecto h \\(10^{2}\\) zepto z \\(10^{-21}\\) deka da \\(10^{1}\\) yocto y \\(10^{-24}\\)"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#table-derived-si-units","title":"Table: Derived SI units","text":"<p>Derived SI units taken from Table 3 of https://physics.nist.gov/cuu/Units/units.html</p> <p>Note that degrees Celsius is omitted.</p> <p>Note that the function treats radians and steradians as dimensionless values.</p> Unit name Symbol Expressed in base SI units radian r 1 steradian sr 1 hertz Hz \\(\\mathrm{second}^{-1}\\) newton N \\(\\mathrm{metre}~\\mathrm{kilogram}~\\mathrm{second}^{-2}\\) pascal Pa \\(\\mathrm{metre}^{-1}~\\mathrm{kilogram}~\\mathrm{second}^{-2}\\) joule J \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}\\) watt W \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-3}\\) coulomb C \\(\\mathrm{second~ampere}\\) volt V \\(\\mathrm{metre}^2~\\mathrm{kilogram second}^{-3}~\\mathrm{ampere}^{-1}\\) farad F \\(\\mathrm{metre}^{-2}~\\mathrm{kilogram}^{-1}~\\mathrm{second}^4~\\mathrm{ampere}^2\\) ohm O \\(\\mathrm{metre}^2~\\mathrm{kilogram second}^{-3}~\\mathrm{ampere}^{-2}\\) siemens S \\(\\mathrm{metre}^{-2}~\\mathrm{kilogram}^{-1}~\\mathrm{second}^3~\\mathrm{ampere}^2\\) weber Wb \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}~\\mathrm{ampere}^{-1}\\) tesla T \\(\\mathrm{kilogram~second}^{-2} \\mathrm{ampere}^{-1}\\) henry H \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}~\\mathrm{ampere}^{-2}\\) lumen lm \\(\\mathrm{candela}\\) lux lx \\(\\mathrm{metre}^{-2}~\\mathrm{candela}\\) becquerel Bq \\(\\mathrm{second}^{-1}\\) gray Gy \\(\\mathrm{metre}^2~\\mathrm{second}^{-2}\\) sievert Sv \\(\\mathrm{metre}^2~\\mathrm{second}^{-2}\\) katal kat \\(\\mathrm{mole~second}^{-1}\\)"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#table-common-non-si-units","title":"Table: Common non-SI units","text":"<p>Commonly used non-SI units taken from Table 6 and 7 of https://physics.nist.gov/cuu/Units/outside.html</p> <p>Note that the function treats angles, neper and bel as dimensionless values.</p> <p>Note that only the first table in this section has short form symbols defined, the second table does not.</p> Unit name Symbol Expressed in SI units minute min \\(60~\\mathrm{second}\\) hour h \\(3600~\\mathrm{second}\\) degree deg \\(\\frac{\\pi}{180}\\) liter l \\(10^{-3}~\\mathrm{metre}^3\\) metric_ton t \\(10^3~\\mathrm{kilogram}\\) neper Np \\(1\\) bel B \\(\\frac{1}{2}~\\ln(10)\\) electronvolt eV \\(1.60218 \\cdot 10^{-19}~\\mathrm{joule}\\) atomic_mass_unit u \\(1.66054 \\cdot 10^{-27}~\\mathrm{kilogram}\\) angstrom \u00e5 \\(10^{-10}~\\mathrm{metre}\\) Unit name Expressed in SI units day \\(86400~\\mathrm{second}\\) angleminute \\(\\frac{\\pi}{10800}\\) anglesecond \\(\\frac{\\pi}{648000}\\) astronomicalunit \\(149597870700~\\mathrm{metre}\\) nauticalmile \\(1852~\\mathrm{metre}\\) knot \\(\\frac{1852}{3600}~\\mathrm{metre~second}^{-1}\\) are \\(10^2~\\mathrm{metre}^2\\) hectare \\(10^4~\\mathrm{metre}^2\\) bar \\(10^5~\\mathrm{pascal}\\) barn \\(10^{-28}~\\mathrm{metre}\\) curie $3.7 \\cdot 10^{10}~\\mathrm{becquerel} roentgen \\(2.58 \\cdot 10^{-4}~\\mathrm{kelvin~(kilogram)}^{-1}\\) rad \\(10^{-2}~\\mathrm{gray}\\) rem \\(10^{-2}~\\mathrm{sievert}\\)"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#table-imperial-units","title":"Table: Imperial units","text":"<p>Commonly imperial units taken from https://en.wikipedia.org/wiki/Imperial_units</p> Unit name Symbol Expressed in SI units inch in \\(0.0254~\\mathrm{metre}\\) foot ft \\(0.3048~\\mathrm{metre}\\) yard yd \\(0.9144~\\mathrm{metre}\\) mile mi \\(1609.344~\\mathrm{metre}\\) fluid ounce fl oz \\(28.4130625~\\mathrm{millilitre}\\) gill gi \\(142.0653125~\\mathrm{millilitre}\\) pint pt \\(568.26125~\\mathrm{millilitre}\\) quart qt \\(1.1365225~\\mathrm{litre}\\) gallon gal \\(4546.09~\\mathrm{litre}\\) ounce oz \\(28.349523125~\\mathrm{gram}\\) pound lb \\(0.45359237~\\mathrm{kilogram}\\) stone st \\(6.35029318~\\mathrm{kilogram}\\)"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#strict_syntax","title":"<code>strict_syntax</code>","text":"<p>If <code>strict_syntax</code> is set to true then the answer and response must have <code>*</code> or <code>/</code> between each part of the expressions and exponentiation must be done using <code>**</code>, e.g. <code>10*kilo*metre/second**2</code> is accepted but <code>10 kilometre/second^2</code> is not.</p> <p>If <code>strict_syntax</code> is set to false, then <code>*</code> can be omitted and <code>^</code> used instead of <code>**</code>. In this case it is also recommended to list any multicharacter symbols (that are not part of the default list of SI units) expected to appear in the response as input symbols.</p> <p>By default <code>strict_syntax</code> is set to true.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#rtol","title":"<code>rtol</code>","text":"<p>Maximum relative error allowed when comparing expressions.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#atol","title":"<code>atol</code>","text":"<p>Maximum absolute error allowed when comparing expressions.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#comparison","title":"<code>comparison</code>","text":"<p>Parameter that determines what kind of comparison is done. There are four possible options:</p> <ul> <li><code>expression</code> Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is sufficienty close (as specified by the <code>atol</code> and <code>rtol</code> parameters).</li> <li><code>expressionExact</code> Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is identical to as high precision as possible.</li> <li><code>dimensions</code> Checks that the answer and response have the same dimensions, does not compare the values of the physical quantities.</li> <li><code>buckinghamPi</code> Checks that the set of quantities in the response matches the set of quantities in the sense given by the Buckingham Pi theorem.</li> </ul> <p>For more details on each options see the description below and the corresponding examples.</p> <p>If <code>comparison</code> is not specified it defaults to <code>expression</code>.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#expression","title":"<code>expression</code>","text":"<p>Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is sufficienty close.</p> <p>How big the difference is between the value of the answer and the value of the response is decided by the <code>rtol</code> and <code>atol</code> parameters. If neither <code>atol</code> nor <code>rtol</code> is specified the function will allow a relative error of \\(10^{-12}\\). If <code>atol</code> is specified its value will be interpreted as the maximum allowed absolute error. If <code>rtol</code> is specified its value will be interpreted as the maximum allowed relative error. If both <code>atol</code> and <code>rtol</code> the function will check both the absolute and relative error.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#expressionexact","title":"<code>expressionExact</code>","text":"<p>Converts the expression to base SI units and checks that the answer and response are identical to the highest precision possible (note that some unit conversions are not exact and that using decimal numbers in the answer or response limits this to floating point precision).</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#dimensions","title":"<code>dimensions</code>","text":"<p>Checks that the answer and response have the same dimensions, but does not compare the values of the physical quantities.</p> <p>With this option the quantities (specified by the <code>quantities</code> parameter) can be given either dimension only, or units.</p>"},{"location":"dev_eval_function_docs/comparePhysicalQuantities/#buckinghampi","title":"<code>buckinghamPi</code>","text":"<p>Checks that the set of quantities in the response matches the set of quantities in the sense given by the Buckingham Pi theorem.</p> <p>There are three different ways of supplying this function with the necessary information. - In the answer, provide an example set of groups as a comma seprated list. When used this way the function assumes that the given list is correct and contains at least the minimum number of groups. - In the <code>quantities</code> parameter, supply a list of what the dimensions for each quantity is and set answer to <code>-</code>. The function will then compute a list of sufficiently many independen dimensionless quantities and compare to the response. - In the <code>quantities</code> parameter, supply a list of what the dimensions for each quantity is and in the answer, supply a list of groups as in the first option. The function will then check that the supplied answer is dimensionless and has a sufficient number of independent groups before comparing it to the response.</p> <p>Note that in lists of groups the items should ideally be written on the form \\(q_1^{c_1} \\cdot q_2^{c_2} \\cdots q_n^{c_n}\\) where \\(q_1, q_2 \\ldots q_n\\) are quantities and \\(c_1, c_2 \\ldots c_n\\) are integers, but the function can also handle item that are sums with terms written on the form \\(a \\cdot q_1^{c_1} \\cdot q_2^{c_2} \\cdots q_n^{c_n}\\) where \\(q_1, q_2 \\ldots q_n\\) are quantities, \\(c_1, c_2 \\ldots c_n\\) rational numbers and \\(a\\) a constant. If the total number of groups is less than required the set of groups is considered invalid, even if there is a sufficient number of terms with independent power products in the response.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/","title":"ComparePhysicalQuantities","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>EXPRESSION</code></li> <li><code>NUMERIC_UNITS</code></li> </ul> <p>Evaluation function which proveds some basic some dimensional analysis functionality.</p> <ul> <li>DEPRECATED Comparing physical quantities RECOMMENDED ALTERNATIVE: CompareExpressions with the <code>physical_quantity</code> parameter set to <code>true</code></li> <li>Substitutions of symbols before comparison of expressions is done</li> <li>Checking if a comma separated list of expressions can be interpreted as a set groups that satisfies the Buckingham Pi theorem</li> </ul> <p>Note: When the <code>quantities</code> grading parameter is set, this function cannot handle short form symbols for units. Thus when defining quantities all units must be given with full names in lower-case letters. For example <code>Nm/s</code> or <code>Newton*metre/SECOND</code> will not be handled correctly, but <code>newton*metre/second</code> will.</p> <p>Note: Prefixes have lower precedence than exponentiation, e.g. <code>10*cm**2</code> will be interpreted as \\(10 \\cdot 10^{-2}~\\mathrm{metre}^2\\) rather than \\(10 \\cdot (10^{-2}~\\mathrm{metre})^2\\).</p> <p>Note: This function allows omitting <code>*</code> and using <code>^</code> instead of <code>**</code> if the grading parameter <code>strict_syntax</code> is set to false. In this case it is also recommended to list any multicharacter symbols (that are not part of the default list of SI units) expected to appear in the response as input symbols.</p> <p>Note: Only the short forms listed in the tables below are accepted. Not all units that are supported have short forms (since this leads to ambiguities).</p> <p>Note: When using the short forms the following convention is assumed: - Long form names takes precedence over sequences of short forms, e.g.  e.g. <code>mN</code> will be interpreted as <code>milli newton</code>, <code>Nm</code> as <code>newton metre</code>, <code>mmN</code> as <code>milli metre newton</code>, <code>mNm</code> as <code>milli newton metre</code> and <code>Nmm</code> as <code>newton milli metre</code>. - Short form symbols of prefixes will take precedence over short form symbols of units from the left, e.g. <code>mug</code> will be interpreted as <code>micro*gram</code> instead <code>metre*astronomicalunit*gram</code>. - If there is a short form symbol for a prefix that collides with the short form for a unit (i.e. <code>m</code>) then it is assumed the that unit will always be placed to the right of another unit in compound units, e.g. <code>mN</code> will be interpreted as <code>milli newton</code>, <code>Nm</code> as <code>newton metre</code>, <code>mmN</code> as <code>milli metre newton</code>, <code>mNm</code> as <code>milli newton metre</code> and <code>Nmm</code> as <code>newton milli metre</code>. - Longer short form symbols take precedence over shorter short forms, e.g. <code>sr</code> will be interpreted as <code>steradian</code> instead of <code>second radian</code>.</p> <p>Note: setting <code>elementary_functions</code> to true will disable using short forms symbols for units.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#inputs","title":"Inputs","text":"<p>All input parameters need to be supplied via the Grading parameters panel.</p> <p>There are seven optional parameters that can be set: <code>elementary_functions</code>, <code>substitutions</code>, <code>quantities</code>, <code>strict_syntax</code>, <code>rtol</code>, <code>atol</code> and <code>comparison</code>.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#custom_feedback","title":"<code>custom_feedback</code>","text":"<p>Custom feedback can be set on a per-task basis. Note: Custom feedback only supports fixed strings, this means that for some situations the custom feedback cannot be as detailed as the default feedback.</p> <p>The parameter must be set as a dictionary with keys from the feedback tags listed below. The value for each key can be any string.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#feedback-tags-for-all-comparisons","title":"Feedback tags for all comparisons","text":"<ul> <li><code>PARSE_ERROR_WARNING</code> Response cannot be parsed as an expression or physical quantity.</li> <li><code>PER_FOR_DIVISION</code> Warns about risk of ambiguity when using <code>per</code> instead <code>/</code> for division.</li> <li><code>STRICT_SYNTAX_EXPONENTIATION</code> Warns that <code>^</code> cannot be used for exponentiation when <code>strict_syntax</code> is set to <code>true</code>.</li> <li><code>QUANTITIES_NOT_WRITTEN_CORRECTLY</code> Text in error message that appears if list of quantities could not be parsed.</li> <li><code>SUBSTITUTIONS_NOT_WRITTEN_CORRECTLY</code> Text in error message that appears if list of substitutions could not be parsed.</li> </ul>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#feedback-tags-for-buckinghampi-comparison","title":"Feedback tags for <code>buckinghamPi</code> comparison","text":"<ul> <li><code>VALID_CANDIDATE_SET</code> Message that is displayed when a response is found to be a valid set of groups. Note: setting this will not affect the Correct/Incorrect message, it will only add further text.</li> <li><code>NOT_DIMENSIONLESS</code> Message displayed when at least one groups is not dimensionless.</li> <li><code>MORE_GROUPS_THAN_REFERENCE_SET</code> Message displayed when the response contains more groups than necessary.</li> <li><code>CANDIDATE_GROUPS_NOT_INDEPENDENT</code> Message displayed when the groups in the response are not independent.</li> <li><code>TOO_FEW_INDEPENDENT_GROUPS</code> Message displayed when the response contains fewer groups than necessary.</li> <li><code>UNKNOWN_SYMBOL</code> Message displayed when the response contains some undefined symbol.</li> <li><code>SUM_WITH_INDEPENDENT_TERMS</code>  Message displayed when the response has too few groups but one (or more) of the groups is a sum with independent terms.</li> </ul>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#elementary_functions","title":"<code>elementary_functions</code>","text":"<p>When using implicit multiplication function names with mulitple characters are sometimes split and not interpreted properly. Setting <code>elementary_functions</code> to true will reserve the function names listed below and prevent them from being split. If a name is said to have one or more alternatives this means that it will accept the alternative names but the reserved name is what will be shown in the preview.</p> <p><code>sin</code>, <code>sinc</code>, <code>csc</code> (alternative <code>cosec</code>), <code>cos</code>, <code>sec</code>, <code>tan</code>, <code>cot</code> (alternative <code>cotan</code>), <code>asin</code> (alternative <code>arcsin</code>), <code>acsc</code> (alternatives <code>arccsc</code>, <code>arccosec</code>), <code>acos</code> (alternative <code>arccos</code>), <code>asec</code> (alternative <code>arcsec</code>), <code>atan</code> (alternative <code>arctan</code>), <code>acot</code> (alternatives <code>arccot</code>, <code>arccotan</code>), <code>atan2</code> (alternative <code>arctan2</code>), <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>csch</code> (alternative <code>cosech</code>), <code>sech</code>, <code>asinh</code> (alternative <code>arcsinh</code>), <code>acosh</code> (alternative <code>arccosh</code>), <code>atanh</code> (alternative <code>arctanh</code>), <code>acsch</code> (alternatives <code>arccsch</code>, <code>arcosech</code>), <code>asech</code> (alternative <code>arcsech</code>), <code>exp</code> (alternative <code>Exp</code>), <code>E</code> (equivalent to <code>exp(1)</code>, alternative <code>e</code>), <code>log</code>, <code>sqrt</code>, <code>sign</code>, <code>Abs</code> (alternative <code>abs</code>), <code>Max</code> (alternative <code>max</code>), <code>Min</code> (alternative <code>min</code>), <code>arg</code>, <code>ceiling</code> (alternative <code>ceil</code>), <code>floor</code></p> <p>Note: setting <code>elementary_functions</code> to true will disable using short forms symbols for units.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#substitutions","title":"<code>substitutions</code>","text":"<p>String that lists all substitutions that should be done to the answer and response inputs before processing.</p> <p>Each substitution should be written in the form <code>('original string','substitution string')</code> and all pairs concatenated into a single string. Substitutions can be grouped by adding <code>|</code> between two substitutions. Then all substitutions before <code>|</code> will be performed before the substitutions after <code>|</code>.</p> <p>The input can contain an arbitrary number of substitutions and <code>|</code> symbols.</p> <p>Note that using substitutions will replace all default definitions of quantities and dimensions.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#quantities","title":"<code>quantities</code>","text":"<p>String that lists all quantities that can be used in the answer and response.</p> <p>Each quantity should be written in the form <code>('quantity name','(units)')</code> and all pairs concatenated into a single string. See tables below for available default units.</p> <p>Whenever units are used they must be written exactly as in the left columns of the tables given below (no short forms or single-character symbols) and units must be multiplied (or divided) by each other, as well as any accompanying quantities.</p> <p>NOTE: Using units and predefined quantities at the same time in an answer or response can cause problems (especially if quantities are denoted using single characters). Ideally it should be clear that either predefined quantities, or units should only be used from the question.</p> <p>If the <code>comparison</code> parameter is set to <code>dimensions</code>, it is not necessary to give exact units for each quantity, but the dimensions must be given instead. See tables below for available default dimensions.</p> <p>If the <code>comparison</code> parameter is set to <code>buckinghamPi</code>, then <code>quantities</code> should be set in a different way. See the detailed description of <code>buckinghamPi</code> further down.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#table-base-si-units","title":"Table: Base SI units","text":"<p>SI base units taken from Table 1 of https://physics.nist.gov/cuu/Units/units.html</p> <p>Note that gram is used as a base unit instead of kilogram.</p> SI base unit Symbol Dimension name metre m length gram g mass second s time ampere A electriccurrent kelvin k temperature mole mol amountofsubstance candela cd luminousintensity"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#table-si-prefixes","title":"Table: SI prefixes","text":"<p>SI base units taken from Table 5 of https://physics.nist.gov/cuu/Units/prefixes.html</p> SI Prefix Symbol Factor SI Prefix Symbol Factor yotta Y \\(10^{24}\\) deci d \\(10^{-1}\\) zetta Z \\(10^{21}\\) centi c \\(10^{-2}\\) exa' E \\(10^{18}\\) milli m \\(10^{-3}\\) peta P \\(10^{15}\\) micro mu \\(10^{-6}\\) tera T \\(10^{12}\\) nano n \\(10^{-9}\\) giga G \\(10^{9}\\) pico p \\(10^{-12}\\) mega M \\(10^{6}\\) femto f \\(10^{-15}\\) kilo k \\(10^{3}\\) atto a \\(10^{-18}\\) hecto h \\(10^{2}\\) zepto z \\(10^{-21}\\) deka da \\(10^{1}\\) yocto y \\(10^{-24}\\)"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#table-derived-si-units","title":"Table: Derived SI units","text":"<p>Derived SI units taken from Table 3 of https://physics.nist.gov/cuu/Units/units.html</p> <p>Note that degrees Celsius is omitted.</p> <p>Note that the function treats radians and steradians as dimensionless values.</p> Unit name Symbol Expressed in base SI units radian r 1 steradian sr 1 hertz Hz \\(\\mathrm{second}^{-1}\\) newton N \\(\\mathrm{metre}~\\mathrm{kilogram}~\\mathrm{second}^{-2}\\) pascal Pa \\(\\mathrm{metre}^{-1}~\\mathrm{kilogram}~\\mathrm{second}^{-2}\\) joule J \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}\\) watt W \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-3}\\) coulomb C \\(\\mathrm{second~ampere}\\) volt V \\(\\mathrm{metre}^2~\\mathrm{kilogram second}^{-3}~\\mathrm{ampere}^{-1}\\) farad F \\(\\mathrm{metre}^{-2}~\\mathrm{kilogram}^{-1}~\\mathrm{second}^4~\\mathrm{ampere}^2\\) ohm O \\(\\mathrm{metre}^2~\\mathrm{kilogram second}^{-3}~\\mathrm{ampere}^{-2}\\) siemens S \\(\\mathrm{metre}^{-2}~\\mathrm{kilogram}^{-1}~\\mathrm{second}^3~\\mathrm{ampere}^2\\) weber Wb \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}~\\mathrm{ampere}^{-1}\\) tesla T \\(\\mathrm{kilogram~second}^{-2} \\mathrm{ampere}^{-1}\\) henry H \\(\\mathrm{metre}^2~\\mathrm{kilogram~second}^{-2}~\\mathrm{ampere}^{-2}\\) lumen lm \\(\\mathrm{candela}\\) lux lx \\(\\mathrm{metre}^{-2}~\\mathrm{candela}\\) becquerel Bq \\(\\mathrm{second}^{-1}\\) gray Gy \\(\\mathrm{metre}^2~\\mathrm{second}^{-2}\\) sievert Sv \\(\\mathrm{metre}^2~\\mathrm{second}^{-2}\\) katal kat \\(\\mathrm{mole~second}^{-1}\\)"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#table-common-non-si-units","title":"Table: Common non-SI units","text":"<p>Commonly used non-SI units taken from Table 6 and 7 of https://physics.nist.gov/cuu/Units/outside.html</p> <p>Note that the function treats angles, neper and bel as dimensionless values.</p> <p>Note that only the first table in this section has short form symbols defined, the second table does not.</p> Unit name Symbol Expressed in SI units minute min \\(60~\\mathrm{second}\\) hour h \\(3600~\\mathrm{second}\\) degree deg \\(\\frac{\\pi}{180}\\) liter l \\(10^{-3}~\\mathrm{metre}^3\\) metric_ton t \\(10^3~\\mathrm{kilogram}\\) neper Np \\(1\\) bel B \\(\\frac{1}{2}~\\ln(10)\\) electronvolt eV \\(1.60218 \\cdot 10^{-19}~\\mathrm{joule}\\) atomic_mass_unit u \\(1.66054 \\cdot 10^{-27}~\\mathrm{kilogram}\\) angstrom \u00e5 \\(10^{-10}~\\mathrm{metre}\\) Unit name Expressed in SI units day \\(86400~\\mathrm{second}\\) angleminute \\(\\frac{\\pi}{10800}\\) anglesecond \\(\\frac{\\pi}{648000}\\) astronomicalunit \\(149597870700~\\mathrm{metre}\\) nauticalmile \\(1852~\\mathrm{metre}\\) knot \\(\\frac{1852}{3600}~\\mathrm{metre~second}^{-1}\\) are \\(10^2~\\mathrm{metre}^2\\) hectare \\(10^4~\\mathrm{metre}^2\\) bar \\(10^5~\\mathrm{pascal}\\) barn \\(10^{-28}~\\mathrm{metre}\\) curie $3.7 \\cdot 10^{10}~\\mathrm{becquerel} roentgen \\(2.58 \\cdot 10^{-4}~\\mathrm{kelvin~(kilogram)}^{-1}\\) rad \\(10^{-2}~\\mathrm{gray}\\) rem \\(10^{-2}~\\mathrm{sievert}\\)"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#table-imperial-units","title":"Table: Imperial units","text":"<p>Commonly imperial units taken from https://en.wikipedia.org/wiki/Imperial_units</p> Unit name Symbol Expressed in SI units inch in \\(0.0254~\\mathrm{metre}\\) foot ft \\(0.3048~\\mathrm{metre}\\) yard yd \\(0.9144~\\mathrm{metre}\\) mile mi \\(1609.344~\\mathrm{metre}\\) fluid ounce fl oz \\(28.4130625~\\mathrm{millilitre}\\) gill gi \\(142.0653125~\\mathrm{millilitre}\\) pint pt \\(568.26125~\\mathrm{millilitre}\\) quart qt \\(1.1365225~\\mathrm{litre}\\) gallon gal \\(4546.09~\\mathrm{litre}\\) ounce oz \\(28.349523125~\\mathrm{gram}\\) pound lb \\(0.45359237~\\mathrm{kilogram}\\) stone st \\(6.35029318~\\mathrm{kilogram}\\)"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#strict_syntax","title":"<code>strict_syntax</code>","text":"<p>If <code>strict_syntax</code> is set to true then the answer and response must have <code>*</code> or <code>/</code> between each part of the expressions and exponentiation must be done using <code>**</code>, e.g. <code>10*kilo*metre/second**2</code> is accepted but <code>10 kilometre/second^2</code> is not.</p> <p>If <code>strict_syntax</code> is set to false, then <code>*</code> can be omitted and <code>^</code> used instead of <code>**</code>. In this case it is also recommended to list any multicharacter symbols (that are not part of the default list of SI units) expected to appear in the response as input symbols.</p> <p>By default <code>strict_syntax</code> is set to true.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#rtol","title":"<code>rtol</code>","text":"<p>Maximum relative error allowed when comparing expressions.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#atol","title":"<code>atol</code>","text":"<p>Maximum absolute error allowed when comparing expressions.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#comparison","title":"<code>comparison</code>","text":"<p>Parameter that determines what kind of comparison is done. There are four possible options:</p> <ul> <li><code>expression</code> Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is sufficienty close (as specified by the <code>atol</code> and <code>rtol</code> parameters).</li> <li><code>expressionExact</code> Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is identical to as high precision as possible.</li> <li><code>dimensions</code> Checks that the answer and response have the same dimensions, does not compare the values of the physical quantities.</li> <li><code>buckinghamPi</code> Checks that the set of quantities in the response matches the set of quantities in the sense given by the Buckingham Pi theorem.</li> </ul> <p>For more details on each options see the description below and the corresponding examples.</p> <p>If <code>comparison</code> is not specified it defaults to <code>expression</code>.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#expression","title":"<code>expression</code>","text":"<p>Converts the expression to base SI units and checks that the units are the same and that the value of the answer and response is sufficienty close.</p> <p>How big the difference is between the value of the answer and the value of the response is decided by the <code>rtol</code> and <code>atol</code> parameters. If neither <code>atol</code> nor <code>rtol</code> is specified the function will allow a relative error of \\(10^{-12}\\). If <code>atol</code> is specified its value will be interpreted as the maximum allowed absolute error. If <code>rtol</code> is specified its value will be interpreted as the maximum allowed relative error. If both <code>atol</code> and <code>rtol</code> the function will check both the absolute and relative error.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#expressionexact","title":"<code>expressionExact</code>","text":"<p>Converts the expression to base SI units and checks that the answer and response are identical to the highest precision possible (note that some unit conversions are not exact and that using decimal numbers in the answer or response limits this to floating point precision).</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#dimensions","title":"<code>dimensions</code>","text":"<p>Checks that the answer and response have the same dimensions, but does not compare the values of the physical quantities.</p> <p>With this option the quantities (specified by the <code>quantities</code> parameter) can be given either dimension only, or units.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#buckinghampi","title":"<code>buckinghamPi</code>","text":"<p>Checks that the set of quantities in the response matches the set of quantities in the sense given by the Buckingham Pi theorem.</p> <p>There are three different ways of supplying this function with the necessary information. - In the answer, provide an example set of groups as a comma seprated list. When used this way the function assumes that the given list is correct and contains at least the minimum number of groups. - In the <code>quantities</code> parameter, supply a list of what the dimensions for each quantity is and set answer to <code>-</code>. The function will then compute a list of sufficiently many independen dimensionless quantities and compare to the response. - In the <code>quantities</code> parameter, supply a list of what the dimensions for each quantity is and in the answer, supply a list of groups as in the first option. The function will then check that the supplied answer is dimensionless and has a sufficient number of independent groups before comparing it to the response.</p> <p>Note that in lists of groups the items should ideally be written on the form \\(q_1^{c_1} \\cdot q_2^{c_2} \\cdots q_n^{c_n}\\) where \\(q_1, q_2 \\ldots q_n\\) are quantities and \\(c_1, c_2 \\ldots c_n\\) are integers, but the function can also handle item that are sums with terms written on the form \\(a \\cdot q_1^{c_1} \\cdot q_2^{c_2} \\cdots q_n^{c_n}\\) where \\(q_1, q_2 \\ldots q_n\\) are quantities, \\(c_1, c_2 \\ldots c_n\\) rational numbers and \\(a\\) a constant. If the total number of groups is less than required the set of groups is considered invalid, even if there is a sufficient number of terms with independent power products in the response.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#examples","title":"Examples","text":"<p>Implemented versions of these examples can be found in the module 'Examples: Evaluation Functions'.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#1-checking-the-dimensions-of-an-expression-or-physical-quantity","title":"1 Checking the dimensions of an expression or physical quantity","text":"<p>DEPRECATED</p> <p>RECOMMENDED ALTERNATIVE: CompareExpressions with the <code>physical_quantity</code> parameter set to <code>true</code></p> <p>This example will check if the response has dimensions \\(\\frac{\\mathrm{length}^2}{\\mathrm{time}^2}\\).</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#a","title":"a)","text":"<p>To check an expression there needs to be some predefined quantities that can be used in the expression. Since only dimensions will be checked units are not necessary (but could be used as well).</p> <p>Here a response area with input type <code>TEXT</code> and two grading parameters, <code>quantities</code> and <code>comparison</code>, will be used.</p> <p><code>quantities</code> is defined as follows: <pre><code>('d','(length)') ('t','(time)') ('v','(length/time)')\n</code></pre></p> <p><code>comparison</code> is set to <code>dimensions</code>.</p> <p>The answer is set two some expression with the right dimensions, e.g. <code>v**2</code>.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax <code>v**2</code> <code>v^2</code> <code>5*v**2</code> <code>5v^2</code> <code>(d/t)**2+v**2</code> <code>(d/t)^2+v^2</code> <code>d**2/t**2</code> <code>d^2/t^2</code> <code>d**2*t**(-2)</code> <code>d^2 t^(-2)</code> <code>d/t*v</code> <code>vd/t</code>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#b","title":"b)","text":"<p>Checking the dimensions of a quantity directly, i.e. the dimensions of an expression of the form <code>number*units</code>, no predefined quantities are necessary.</p> <p>Here a response area with input type <code>TEXT</code> and one grading parameter,<code>comparison</code>, will be used.</p> <p><code>comparison</code> is set to <code>dimensions</code>.</p> <p>The answer is set two some expression with the right dimensions, e.g. <code>length**2/time**2</code>.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since only default SI units are expected in the answer we do not need to set any input symbols.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax Using symbols <code>metre**2/second**2</code> <code>metre^2/second^2</code> <code>m^2/s^2</code> <code>(centi*metre)**2/hour**2</code> <code>(centimetre)^2/h^2</code> <code>(cm)^2/h^2</code> <code>246*ohm/(kilo*gram)*coulomb**2/second</code> <code>246 ohm/(kilogram) coulomb^2/second</code> <code>246 O/(kg) c^2/s</code>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#2-checking-the-value-of-an-expression-or-a-physical-quantity","title":"2 Checking the value of an expression or a physical quantity","text":"<p>DEPRECATED</p> <p>RECOMMENDED ALTERNATIVE: CompareExpressions with the <code>physical_quantity</code> parameter set to <code>true</code></p> <p>This examples checks if your expression is equal to \\(2~\\frac{\\mathrm{kilometre}}{\\mathrm{hour}}\\).</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#a_1","title":"a)","text":"<p>Here an expression with predefined quantities is checked as exactly as possible. This is done with a TEXT response area with the following parameters: <code>quantities</code> is set to: <pre><code>('d','(length)') ('t','(time)') ('v','(length/time)')\n</code></pre> Note that short form symbols cannot be used when defining quantities.</p> <p><code>comparison</code> is set to <code>expressionExact</code>.</p> <p>The response area answer is set to <code>2*v</code> but there are many other expressions that would work just as well. Note that we cannot write <code>2*kilo*metre/second</code> as response or answer since the predefined quantity <code>t</code> will substitute the <code>t</code> in <code>metre</code> which results in unparseable input.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since only default SI units and single character symbols are expected in the answer we will not set the grading parameter <code>symbols</code>.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax <code>2*v</code> <code>2v</code> <code>2000/3600*d/t</code> <code>2000/3600 d/t</code> <code>1/1.8*d/t</code> <code>d/(1.8t)</code> <code>v+1/3.6*d/t</code> <code>v+d/(3.6t)</code>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#b_1","title":"b)","text":"<p>Checking if a quantity is equal to \\(2~\\frac{kilometre}{hour}\\) with a fixed absolute tolerance of \\(0.05 \\frac{metre}{second}\\) can be done with a TEXT response area with <code>atol</code> set to <code>0.05</code> and the answer set to <code>2*kilo*metre/hour</code>.</p> <p>Note: <code>atol</code> is always assumed to be given in the base SI units version of the expression. This is likely to change in future versions of the function.</p> <p>The <code>comparison</code> parameter could also be set to <code>expression</code> but since this is the default it is not necessary.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since only default SI units are expected in the answer no input symbols are necessary.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax Using symbols <code>0.556*metre/second</code> <code>0.556 metre/second</code> <code>0.556 m/s</code> <code>0.560*metre/second</code> <code>0.560 metre/second</code> <code>0.560 m/s</code> <code>0.6*metre/second</code> <code>0.6 metre/second</code> <code>0.6 m/s</code> <code>2*kilo*metre/hour</code> <code>2 kilometre/hour</code> <code>2 km/h</code> <code>1.9*kilo*metre/hour</code> <code>1.9 kilometre/hour</code> <code>1.9 km/h</code> <code>2.1*kilo*metre/hour</code> <code>2.1 kilometre/hour</code> <code>2.1 km/h</code> <p>In the example given in the example problem set, the following responses are tested and evaluated as incorrect:</p> Strict syntax Relaxed syntax Using symbols <code>0.61*metre/second</code> <code>0.61 metre/second</code> <code>0.61 m/s</code> <code>2.2*kilo*metre/hour</code> <code>2.2 kilometre/hour</code> <code>2.2 km/h</code>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#c","title":"c)","text":"<p>Checking if a quantity is equal to \\(2~\\frac{kilometre}{hour}\\) with a fixed relative tolerance of \\(0.05\\) can be done with a TEXT response area with <code>rtol</code> set to <code>0.05</code> and the answer set to <code>2*kilo*metre/hour</code>.</p> <p>The <code>comparison</code> parameter could also be set to <code>expression</code> but since this is the default it is not necessary.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax Using symbols <code>0.533*metre/second</code> <code>0.533 metre/second</code> <code>0.533 m/s</code> <code>2.08*kilo*metre/hour</code> <code>2.08 kilometre/hour</code> <code>2.08 km/h</code> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since only default SI units are expected it is not necessary to set any input symbols.</p> <p>In the example given in the example problem set, the following responses are tested and evaluated as incorrect:</p> Strict syntax Relaxed syntax Using symbols <code>0.522*metre/second</code> <code>0.522 metre/second</code> <code>0.522 m/s</code> <code>2.11*kilo*metre/hour</code> <code>2.11 kilometre/hour</code> <code>2.11 km/h</code>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#3-checking-if-a-set-of-quantities-match-the-buckingham-pi-theorem","title":"3 Checking if a set of quantities match the Buckingham pi theorem","text":""},{"location":"user_eval_function_docs/comparePhysicalQuantities/#a_2","title":"a)","text":"<p>In this example the task is: Given \\(U\\), \\(L\\) and \\(\\nu\\), suggest a dimensionless group.</p> <p>For this problem we do not need to predefine any quantities and give exact dimensions. The algorithm assumes that all symbols in the answer (that are not numbers or predefined constants such as \\(\\pi\\)) are quantities and that there are no other quantities that should appear in the answer.</p> <p>Note: This means that the algorithm does not in any way check that the stated answer is dimensionless, ensuring that that is left to the problem author.</p> <p>For this example a TEXT response area is used with <code>comparison</code> set to <code>buckinghamPi</code> and answer set to <code>['U*L/nu']</code>. It is not necessary to use this specific answer, any example of a correct dimensionless group should work.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since <code>nu</code> is a multicharacter symbol it needs to be added as an input symbol.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#b_2","title":"b)","text":"<p>In this example the task is: Given \\(U\\), \\(L\\), \\(\\nu\\) and \\(f\\), determine the necessary number of dimensionless groups and give one example of possible expressions for them.</p> <p>This task is similar to example a) with two significant differences. First, adding \\(f\\) means that there are now two groups required, and second the problem will constructed by defining the quantities and let the function compute the rest on its own instead of supplying a reference example.</p> <p>For this example a TEXT response area is used with <code>comparison</code> set to <code>buckinghamPi</code>, <code>quantities</code> set to <code>('U','(length/time)') ('L','(length)') ('nu','(length**2/time)') ('f','(1/time)')</code> and <code>answer</code> set to <code>-</code>.</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since <code>nu</code> is a multicharacter symbol it needs to be added as an input symbol.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#c_1","title":"c)","text":"<p>In this example the task is: Suppose we are studying water waves that move under the influence of gravity. We suppose that the variables of interest are the acceleration in free fall \\(g\\), the velocity of the wave \\(v\\), the height of the wave \\(h\\) and the wave length \\(\\ell\\). We also suppose that they are related by a dimensionally consistent equation \\(f(g,v,h,l) = 0\\). Determine the minimum number of dimensionless \\(\\pi\\)-variables needed to describe this problem according to the Buckingham pi-theorem and give one example of possible expressions for the dimensionless quantities.</p> <p>For this problem two dimensionless groups are needed, see the worked solution for a terse solution that gives the general form of the dimensionless quantities.</p> <p>For this example a TEXT response area is used with <code>comparison</code> set to <code>buckinghamPi</code> and then give a list of correct group expressions formatted as the code for a python list. For this example the answer <code>['g**(-2)*v**4*h*l**3', 'g**(-2)*v**4*h**2*l**4']</code> was used (this corresponds to \\(p_1 = 1\\), \\(p_2 = 2\\), \\(q_1 = 3\\), \\(q_2 = 4\\) in the worked solution). The feedback was costumized by setting the <code>custom_feedback</code> parameter too: <code>\"custom_feedback\": { \"VALID_CANDIDATE_SET\": \"Your list of power products satisfies the Buckingham Pi theorem.\", \"NOT_DIMENSIONLESS\": \"At least one power product is not dimensionless.\", \"MORE_GROUPS_THAN_REFERENCE_SET\": \"Response has more power products than necessary.\", \"CANDIDATE_GROUPS_NOT_INDEPENDENT\": \"Power products in response are not independent.\", \"TOO_FEW_INDEPENDENT_GROUPS\": \"Candidate set contains too few independent groups.\", \"UNKNOWN_SYMBOL\": \"One of the prower products contains an unkown symbol.\", \"SUM_WITH_INDEPENDENT_TERMS\": \"The candidate set contains an expression which contains more independent terms that there are groups in total. The candidate set should ideally only contain expressions written as power products.\" }</code></p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. To remove this requirement the grading parameter <code>strict_syntax</code> is set to false. Since <code>nu</code> is a multicharacter symbol it needs to be added as an input symbol.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#4-defining-costum-sets-of-units","title":"4 Defining costum sets of units","text":"<p>In this problem it is demonstrated how to use <code>substitutions</code> to define costum units.</p>"},{"location":"user_eval_function_docs/comparePhysicalQuantities/#a_3","title":"a)","text":"<p>In this problem currencies will be us as units, and thus the quantities will no longer be physical.</p> <p>Here the <code>substitutions</code> parameter will be set so that the evaluation function can be used to compare. Note that using <code>substitutions</code> this way means that the default SI units can no longer be used.</p> <p>The following exchange rates (from Bank of England 1 August 2022) will be used:</p> Currency Exchange rate \\(1\\) EUR \\(1.1957\\) GBP \\(1\\) USD \\(1.2283\\) GBP \\(1\\) CNY \\(8.3104\\) GBP \\(1\\) INR \\(96.943\\) GBP <p>To compare prices written in different currencies a reference currency needs to be chosen. In this case GBP will be used. To substitute other currencies for their corresponding value in GBP the following grading parameter can be used: <pre><code>\"substitutions\":\"('EUR','(1/1.1957)*GBP') ('USD','(1/1.2283)*GBP') ('CNY','(1/8.3104)*GBP') ('INR','(1/96.9430)*GBP')\"\n</code></pre> Since these conversion are not exact and for practical purposes prices are often not gives with more than two decimals of precision we also want to set the absolute tolerance, <code>atol</code>, to \\(0.05\\).</p> <p>With default settings it is required to put <code>*</code> (or <code>/</code>) between each part of the response and answer. By setting the grading parameter <code>strict_syntax</code> to false the <code>*</code> can be omitted and <code>^</code> can be used instead of <code>**</code>. To ensure that this works correctly it is necessary to list the multicharacter symbols that are expected to appear in the answer and response as input symbols. For this example this means setting <code>EUR</code>, <code>USD</code>, <code>CNY</code> and <code>INR</code> as codes for inut symbols.</p> <p>In the example given in the example problem set, the answer set to <code>10*GBP</code> and the following responses are tested and evaluated as correct:</p> Strict syntax Relaxed syntax <code>11.96*EUR</code> <code>11.96 EUR</code> <code>12.28*USD</code> <code>12.28 USD</code> <code>83.10*CNY</code> <code>83.10 CNY</code> <code>969.43*INR</code> <code>969.43 INR</code>"},{"location":"dev_eval_function_docs/latexEqual/","title":"LatexEqual","text":"<p>Edit on GitHub  View Code </p> <p>This is an experimental evaluation function for comparing two latex strings. For evaluation, it actually calls the <code>symbolicEqual</code> function using the experimental EvaluationFunctionClient.</p>"},{"location":"dev_eval_function_docs/latexEqual/#inputs","title":"Inputs","text":"<p>This function doesn't have any parameters, both <code>response</code> and <code>answer</code> should be valid LaTeX strings. If you wish, you can pass parameters that are relayed to the <code>symbolicEqual</code> function (refer to it's documentation for more information about those).</p>"},{"location":"dev_eval_function_docs/latexEqual/#outputs","title":"Outputs","text":"<pre><code>{\n  \"is_correct\": \"&lt;bool&gt;\"\n}\n</code></pre>"},{"location":"user_eval_function_docs/latexEqual/","title":"LatexEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is not configured for any Response Area components</p> <p>Use this function to check if a given latex string response is mathematically equivalent to the answer. This is done by converting the latex inputs into mathematical expressions, which are then compared using the symbolicEqual function.</p>"},{"location":"dev_eval_function_docs/isSimilar/","title":"IsSimilar","text":"<p>Edit on GitHub  View Code </p> <p>This simple evaluation function checks if the supplied response is within a tolerance range defined in <code>params</code>. Works exactly like the numpy.isclose function.</p> <p>Valid params include <code>atol</code> and <code>rtol</code>, which can be used in combination, or alone. As the comparison made is the following:</p> <pre><code>is_correct = abs(res - ans) &lt;= (atol + rtol*abs(ans))\n</code></pre>"},{"location":"dev_eval_function_docs/isSimilar/#inputs","title":"Inputs","text":"<pre><code>{\n  \"response\": \"&lt;number&gt;\",\n  \"answer\": \"&lt;number&gt;\",\n  \"params\": {\n    \"atol\": \"&lt;number&gt;\",\n    \"rtol\": \"&lt;number&gt;\"\n  }\n}\n</code></pre>"},{"location":"dev_eval_function_docs/isSimilar/#atol","title":"<code>atol</code>","text":"<p>Absolute tolerance parameter</p>"},{"location":"dev_eval_function_docs/isSimilar/#rtol","title":"<code>rtol</code>","text":"<p>Relative tolerance parameter</p>"},{"location":"dev_eval_function_docs/isSimilar/#outputs","title":"Outputs","text":"<pre><code>{\n  \"is_correct\": \"&lt;bool&gt;\",\n  \"real_diff\": \"&lt;number&gt;\",\n  \"allowed_diff\": \"&lt;number&gt;\",\n}\n</code></pre>"},{"location":"dev_eval_function_docs/isSimilar/#real_diff","title":"<code>real_diff</code>","text":"<p>Real difference between the given answer and response</p>"},{"location":"dev_eval_function_docs/isSimilar/#allowed_diff","title":"<code>allowed_diff</code>","text":"<p>Allowed difference between answer and response, calculated using the supplied <code>atol</code> and <code>rtol</code> parameters</p>"},{"location":"dev_eval_function_docs/isSimilar/#examples","title":"Examples","text":""},{"location":"user_eval_function_docs/isSimilar/","title":"IsSimilar","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>NUMBER</code></li> <li><code>TEXT</code></li> </ul> <p>Use this evaluation function to check if the student's reponse is within a tolerance range defined in <code>params</code>. Works exactly like the numpy.isclose function. Valid params include <code>atol</code> and <code>rtol</code> (absolute and relative tolerances) which can be used in combination, or alone.</p>"},{"location":"dev_eval_function_docs/compareSets/","title":"YourFunctionName","text":"<p>Edit on GitHub  View Code </p> <p>Brief description of what this evaluation function does, from the developer perspective</p>"},{"location":"dev_eval_function_docs/compareSets/#inputs","title":"Inputs","text":"<p>Specific input parameters which can be supplied when the <code>eval</code> command is supplied to this function.</p>"},{"location":"dev_eval_function_docs/compareSets/#outputs","title":"Outputs","text":"<p>Output schema/values for this function</p>"},{"location":"dev_eval_function_docs/compareSets/#examples","title":"Examples","text":"<p>List of example inputs and outputs for this function, each under a different sub-heading</p>"},{"location":"dev_eval_function_docs/compareSets/#simple-evaluation","title":"Simple Evaluation","text":"<pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre> <pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre>"},{"location":"user_eval_function_docs/compareSets/","title":"YourFunctionName","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>EXPRESSION</code></li> </ul> <p>Teacher-facing documentation for this function.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/","title":"SymbolicEqual","text":"<p>Edit on GitHub  View Code </p> <p>Evaluates the equality between two symbolic expressions using the python <code>SymPy</code> package.</p> <p>Note that <code>pi</code> is a reserved constant and cannot be used as a symbol name.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#inputs","title":"Inputs","text":""},{"location":"dev_eval_function_docs/symbolicEqual/#optional-grading-parameters","title":"Optional grading parameters","text":"<p>There are eight optional parameters that can be set: <code>complexNumbers</code>, <code>elementary_functions</code>, <code>specialFunctions</code>, <code>strict_syntax</code>,  <code>symbol_assumptions</code>, <code>multiple_answers_criteria</code>, <code>plus_minus</code> and <code>minus_plus</code>.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#complexnumbers","title":"<code>complexNumbers</code>","text":"<p>If you want to use <code>I</code> for the imaginary constant, set the grading parameter <code>complexNumbers</code> to True.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#elementary_functions","title":"<code>elementary_functions</code>","text":"<p>When using implicit multiplication function names with mulitple characters are sometimes split and not interpreted properly. Setting <code>elementary_functions</code> to true will reserve the function names listed below and prevent them from being split. If a name is said to have one or more alternatives this means that it will accept the alternative names but the reserved name is what will be shown in the preview.</p> <p><code>sin</code>, <code>sinc</code>, <code>csc</code> (alternative <code>cosec</code>), <code>cos</code>, <code>sec</code>, <code>tan</code>, <code>cot</code> (alternative <code>cotan</code>), <code>asin</code> (alternative <code>arcsin</code>), <code>acsc</code> (alternatives <code>arccsc</code>, <code>arccosec</code>), <code>acos</code> (alternative <code>arccos</code>), <code>asec</code> (alternative <code>arcsec</code>), <code>atan</code> (alternative <code>arctan</code>), <code>acot</code> (alternatives <code>arccot</code>, <code>arccotan</code>), <code>atan2</code> (alternative <code>arctan2</code>), <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>csch</code> (alternative <code>cosech</code>), <code>sech</code>, <code>asinh</code> (alternative <code>arcsinh</code>), <code>acosh</code> (alternative <code>arccosh</code>), <code>atanh</code> (alternative <code>arctanh</code>), <code>acsch</code> (alternatives <code>arccsch</code>, <code>arcosech</code>), <code>asech</code> (alternative <code>arcsech</code>), <code>exp</code> (alternative <code>Exp</code>), <code>E</code> (equivalent to <code>exp(1)</code>, alternative <code>e</code>), <code>log</code>, <code>sqrt</code>, <code>sign</code>, <code>Abs</code> (alternative <code>abs</code>), <code>Max</code> (alternative <code>max</code>), <code>Min</code> (alternative <code>min</code>), <code>arg</code>, <code>ceiling</code> (alternative <code>ceil</code>), <code>floor</code></p>"},{"location":"dev_eval_function_docs/symbolicEqual/#specialfunctions","title":"<code>specialFunctions</code>","text":"<p>If you want to use the special functions <code>beta</code> (Euler Beta function), <code>gamma</code> (Gamma function) and <code>zeta</code> (Riemann Zeta function), set the grading parameter <code>specialFunctions</code> to True.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#strict_syntax","title":"<code>strict_syntax</code>","text":"<p>If <code>strict_syntax</code> is set to true then the answer and response must have <code>*</code> or <code>/</code> between each part of the expressions and exponentiation must be done using <code>**</code>, e.g. <code>10*x*y/z**2</code> is accepted but <code>10xy/z^2</code> is not.</p> <p>If <code>strict_syntax</code> is set to false, then <code>*</code> can be omitted and <code>^</code> used instead of <code>**</code>. In this case it is also recommended to list any multicharacter symbols expected to appear in the response as input symbols.</p> <p>By default <code>strict_syntax</code> is set to true.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#symbol_assumptions","title":"<code>symbol_assumptions</code>","text":"<p>This input parameter allows the author to set an extra assumption each symbol. Each assumption should be written on the form <code>('symbol','assumption name')</code> and all pairs concatenated into a single string.</p> <p>The possible assumption names can be found in this list:  <code>SymPy Assumption Predicates</code></p>"},{"location":"dev_eval_function_docs/symbolicEqual/#multiple_answers_criteria","title":"<code>multiple_answers_criteria</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>Answers or responses that contain \\(\\pm\\) or \\(\\mp\\) has two possible interpretations which requires further criteria for equality. The grading parameter <code>multiple_answers_criteria</code> controls this. The default setting, <code>all</code>, is that each answer must have a corresponding answer and vice versa. The setting <code>all_responses</code> check that all responses are valid answers and the setting <code>all_answers</code> checks that all answers are found among the responses.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#plus_minus-and-minus_plus","title":"<code>plus_minus</code> and <code>minus_plus</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>To use other symbols for \\(\\pm\\) and \\(\\mp\\) set the grading parameters <code>plus_minus</code> and <code>minus_plus</code> to the desired symbol. Remark: symbol replacement is brittle and can have unintended consequences.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#outputs","title":"Outputs","text":"<p>Outputs to the <code>eval</code> command will feature:</p> <pre><code>{\n  \"command\": \"eval\",\n  \"result\": {\n    \"is_correct\": \"&lt;bool&gt;\",\n    \"response_latex\": \"&lt;str&gt;\",\n    \"response_simplified\": \"&lt;str&gt;\",\n    \"level\": \"&lt;int&gt;\"\n  }\n}\n</code></pre>"},{"location":"dev_eval_function_docs/symbolicEqual/#response_latex","title":"<code>response_latex</code>","text":"<p>This is a latex string, indicating how the user's <code>response</code> was understood by SymPy. It can be used to provide feedback in the front-end.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#level","title":"<code>level</code>","text":"<p>The function tests equality using three levels, of increasing complexity. This parameter indicates the level at which equality was found. It is not present if the result is incorrect.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#response_simplified","title":"<code>response_simplified</code>","text":"<p>This is a math-simplified string of the given response. All mathematically-equivalent expressions will yield identical strings under this field. This can be used by teacher dashboards when aggregating common student errors.</p>"},{"location":"dev_eval_function_docs/symbolicEqual/#examples","title":"Examples","text":""},{"location":"user_eval_function_docs/symbolicEqual/","title":"SymbolicEqual","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>EXPRESSION</code></li> </ul> <p>This function utilises the <code>SymPy</code> to provide a maths-aware comparsion of a student's response to the correct answer. This means that mathematically equivalent inputs will be marked as correct. Note that <code>pi</code> is a reserved constant and cannot be used as a symbol name.</p> <p>Note that this function is designed to handle comparisons of mathematical expressions but has some limited ability to handle comparison of equations as well. More precisely, if the answer is of the form \\(f(x_1,\\ldots,x_n) = g(x_1,\\ldots,x_n)\\) and the response is of the form \\(\\tilde{f}(x_1,\\ldots,x_n) = \\tilde{g}(x_1,\\ldots,x_n)\\) then the function checks if \\(f(x_1,\\ldots,x_n) - g(x_1,\\ldots,x_n)\\) is a multiple of \\(\\tilde{f}(x_1,\\ldots,x_n) / \\tilde{g}(x_1,\\ldots,x_n)\\).</p>"},{"location":"user_eval_function_docs/symbolicEqual/#inputs","title":"Inputs","text":""},{"location":"user_eval_function_docs/symbolicEqual/#optional-grading-parameters","title":"Optional grading parameters","text":"<p>There are eight optional parameters that can be set: <code>complexNumbers</code>, <code>elementary_functions</code>, <code>specialFunctions</code>, <code>strict_syntax</code>,  <code>symbol_assumptions</code>, <code>multiple_answers_criteria</code>, <code>plus_minus</code> and <code>minus_plus</code>.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#complexnumbers","title":"<code>complexNumbers</code>","text":"<p>If you want to use <code>I</code> for the imaginary constant, set the grading parameter <code>complexNumbers</code> to True.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#elementary_functions","title":"<code>elementary_functions</code>","text":"<p>When using implicit multiplication function names with mulitple characters are sometimes split and not interpreted properly. Setting <code>elementary_functions</code> to true will reserve the function names listed below and prevent them from being split. If a name is said to have one or more alternatives this means that it will accept the alternative names but the reserved name is what will be shown in the preview.</p> <p><code>sin</code>, <code>sinc</code>, <code>csc</code> (alternative <code>cosec</code>), <code>cos</code>, <code>sec</code>, <code>tan</code>, <code>cot</code> (alternative <code>cotan</code>), <code>asin</code> (alternative <code>arcsin</code>), <code>acsc</code> (alternatives <code>arccsc</code>, <code>arccosec</code>), <code>acos</code> (alternative <code>arccos</code>), <code>asec</code> (alternative <code>arcsec</code>), <code>atan</code> (alternative <code>arctan</code>), <code>acot</code> (alternatives <code>arccot</code>, <code>arccotan</code>), <code>atan2</code> (alternative <code>arctan2</code>), <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>csch</code> (alternative <code>cosech</code>), <code>sech</code>, <code>asinh</code> (alternative <code>arcsinh</code>), <code>acosh</code> (alternative <code>arccosh</code>), <code>atanh</code> (alternative <code>arctanh</code>), <code>acsch</code> (alternatives <code>arccsch</code>, <code>arcosech</code>), <code>asech</code> (alternative <code>arcsech</code>), <code>exp</code> (alternative <code>Exp</code>), <code>E</code> (equivalent to <code>exp(1)</code>, alternative <code>e</code>), <code>log</code>, <code>sqrt</code>, <code>sign</code>, <code>Abs</code> (alternative <code>abs</code>), <code>Max</code> (alternative <code>max</code>), <code>Min</code> (alternative <code>min</code>), <code>arg</code>, <code>ceiling</code> (alternative <code>ceil</code>), <code>floor</code></p>"},{"location":"user_eval_function_docs/symbolicEqual/#specialfunctions","title":"<code>specialFunctions</code>","text":"<p>If you want to use the special functions <code>beta</code> (Euler Beta function), <code>gamma</code> (Gamma function) and <code>zeta</code> (Riemann Zeta function), set the grading parameter <code>specialFunctions</code> to True.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#strict_syntax","title":"<code>strict_syntax</code>","text":"<p>If <code>strict_syntax</code> is set to true then the answer and response must have <code>*</code> or <code>/</code> between each part of the expressions and exponentiation must be done using <code>**</code>, e.g. <code>10*x*y/z**2</code> is accepted but <code>10xy/z^2</code> is not.</p> <p>If <code>strict_syntax</code> is set to false, then <code>*</code> can be omitted and <code>^</code> used instead of <code>**</code>. In this case it is also recommended to list any multicharacter symbols expected to appear in the response as input symbols.</p> <p>By default <code>strict_syntax</code> is set to true.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#symbol_assumptions","title":"<code>symbol_assumptions</code>","text":"<p>This input parameter allows the author to set an extra assumption each symbol. Each assumption should be written on the form <code>('symbol','assumption name')</code> and all pairs concatenated into a single string.</p> <p>The possible assumption names can be found in this list:  <code>SymPy Assumption Predicates</code></p>"},{"location":"user_eval_function_docs/symbolicEqual/#multiple_answers_criteria","title":"<code>multiple_answers_criteria</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>Answers or responses that contain \\(\\pm\\) or \\(\\mp\\) has two possible interpretations which requires further criteria for equality. The grading parameter <code>multiple_answers_criteria</code> controls this. The default setting, <code>all</code>, is that each answer must have a corresponding answer and vice versa. The setting <code>all_responses</code> check that all responses are valid answers and the setting <code>all_answers</code> checks that all answers are found among the responses.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#plus_minus-and-minus_plus","title":"<code>plus_minus</code> and <code>minus_plus</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>To use other symbols for \\(\\pm\\) and \\(\\mp\\) set the grading parameters <code>plus_minus</code> and <code>minus_plus</code> to the desired symbol. Remark: symbol replacement is brittle and can have unintended consequences.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#examples","title":"Examples","text":"<p>Implemented versions of these examples can be found in the module 'Examples: Evaluation Functions'.</p>"},{"location":"user_eval_function_docs/symbolicEqual/#1-setting-input-symbols-to-be-assumed-positive-to-avoid-issues-with-fractional-powers","title":"1 Setting input symbols to be assumed positive to avoid issues with fractional powers","text":"<p>In general \\(\\frac{\\sqrt{a}}{\\sqrt{b}} \\neq \\sqrt{\\frac{a}{b}}\\) but if \\(a &gt; 0\\) and \\(b &gt; 0\\) then \\(\\frac{\\sqrt{a}}{\\sqrt{b}} = \\sqrt{\\frac{a}{b}}\\). The same is true for other fractional powers.</p> <p>So if expression like these are expected in the answer and/or response then it is a good idea to use the <code>symbol_assumptions</code> parameter to note that \\(a &gt; 0\\) and \\(b &gt; 0\\). This can be done by setting <code>symbol_assumptions</code> to <code>('a','positive') ('b','positive')</code>.</p> <p>The example given in the example problem set uses an EXPRESSION response area that uses <code>SymbolicEqual</code> with answer <code>sqrt(a/b)</code>, <code>strict_syntax</code> set to false and <code>symbol_assumptions</code> set as above. Some examples of expressions that are accepted as correct: <code>sqrt(a)/sqrt(b)</code>, <code>(a/b)**(1/2)</code>, <code>a**(1/2)/b**(1/2)</code>, <code>(a/b)^(0.5)</code>, <code>a^(0.5)/b^(0.5)</code></p>"},{"location":"dev_eval_function_docs/compareExpressions/","title":"YourFunctionName","text":"<p>Edit on GitHub  View Code </p> <p>Brief description of what this evaluation function does, from the developer perspective</p>"},{"location":"dev_eval_function_docs/compareExpressions/#inputs","title":"Inputs","text":"<p>Specific input parameters which can be supplied when the <code>eval</code> command is supplied to this function.</p>"},{"location":"dev_eval_function_docs/compareExpressions/#outputs","title":"Outputs","text":"<p>Output schema/values for this function</p>"},{"location":"dev_eval_function_docs/compareExpressions/#examples","title":"Examples","text":"<p>List of example inputs and outputs for this function, each under a different sub-heading</p>"},{"location":"dev_eval_function_docs/compareExpressions/#simple-evaluation","title":"Simple Evaluation","text":"<pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre> <pre><code>{\n  \"example\": {\n    \"Something\": \"something\"\n  }\n}\n</code></pre>"},{"location":"user_eval_function_docs/compareExpressions/","title":"CompareExpressions","text":"<p>Edit on GitHub  View Code </p> <p>Supported Response Area Types</p> <p>This evaluation function is supported by the following Response Area components:</p> <ul> <li><code>TEXT</code></li> <li><code>EXPRESSION</code></li> <li><code>NUMERIC_UNITS</code></li> <li><code>CODE</code></li> <li><code>ESSAY</code></li> </ul> <p>This function utilises the <code>SymPy</code> to provide a maths-aware comparsion of a student's response to the correct answer. This means that mathematically equivalent inputs will be marked as correct. Note that <code>pi</code> is a reserved constant and cannot be used as a symbol name.</p> <p>Note that this function is designed to handle comparisons of mathematical expressions but has some limited ability to handle comparison of equalities as well. More precisely, if the answer is of the form \\(f(x_1,\\ldots,x_n) = g(x_1,\\ldots,x_n)\\) and the response is of the form \\(\\tilde{f}(x_1,\\ldots,x_n) = \\tilde{g}(x_1,\\ldots,x_n)\\) then the function checks if \\(f(x_1,\\ldots,x_n) - g(x_1,\\ldots,x_n)\\) is a multiple of \\(\\tilde{f}(x_1,\\ldots,x_n) / \\tilde{g}(x_1,\\ldots,x_n)\\).</p>"},{"location":"user_eval_function_docs/compareExpressions/#inputs","title":"Inputs","text":""},{"location":"user_eval_function_docs/compareExpressions/#optional-parameters","title":"Optional parameters","text":"<p>There are nine optional parameters that can be set: <code>complexNumbers</code>, <code>convention</code>, <code>criteria</code>, <code>multiple_answers_criteria</code>, <code>elementary_functions</code>, <code>feedback_for_incorrect_response</code>, <code>physical_quantity</code>, <code>plus_minus</code>/<code>minus_plus</code> <code>specialFunctions</code>, <code>strict_syntax</code>, <code>symbol_assumptions</code>.</p>"},{"location":"user_eval_function_docs/compareExpressions/#complexnumbers","title":"<code>complexNumbers</code>","text":"<p>If you want to use <code>I</code> for the imaginary constant, set the grading parameter <code>complexNumbers</code> to True.</p>"},{"location":"user_eval_function_docs/compareExpressions/#convention","title":"<code>convention</code>","text":"<p>Changes the implicit multiplication convention. If unset it will default to <code>equal_precedence</code>.</p> <p>If set to <code>implicit_higher_precedence</code> then implicit multiplication will have higher precedence than explicit multiplication, i.e. <code>1/ab</code> will be equal to <code>1/(ab)</code> and <code>1/a*b</code> will be equal to <code>(1/a)*b</code>.</p> <p>If set to <code>equal_precedence</code> then implicit multiplication will have the same precedence than explicit multiplication, i.e. both <code>1/ab</code> and <code>1/a*b</code> will be equal to <code>(1/a)*b</code>.</p>"},{"location":"user_eval_function_docs/compareExpressions/#criteria","title":"<code>criteria</code>","text":"<p>The <code>criteria</code> parameter can be used to customize the comparison performed by the evaluation function. If unset the evaluation function will will default to checking if the answer and response are symbolically equal.</p> <p>The <code>criteria</code> parameter takes a string that defines a set of (comma separated) mathematical statements. If all statements in the list are true the response is considered correct.</p> <p>The <code>criteria</code> parameter reserves <code>response</code> and <code>answer</code> as keywords that will be replaced y the response and answer respectively when the criteria is checked. Setting <code>criteria</code> to <code>answer=response</code> is gives the same behaviour as leaving <code>criteria</code> unset.</p> <p>Note: Currently the <code>criteria</code> parameter is ignored if <code>physical_quantity</code> is set to true.</p> <p>Note: The <code>criteria</code> parameters functionality is currently under development and will rarely produce appropriate feedback and can be quite difficult to debug.</p>"},{"location":"user_eval_function_docs/compareExpressions/#elementary_functions","title":"<code>elementary_functions</code>","text":"<p>When using implicit multiplication function names with multiple characters are sometimes split and not interpreted properly. Setting <code>elementary_functions</code> to true will reserve the function names listed below and prevent them from being split. If a name is said to have one or more alternatives this means that it will accept the alternative names but the reserved name is what will be shown in the preview.</p> <p><code>sin</code>, <code>sinc</code>, <code>csc</code> (alternative <code>cosec</code>), <code>cos</code>, <code>sec</code>, <code>tan</code>, <code>cot</code> (alternative <code>cotan</code>), <code>asin</code> (alternative <code>arcsin</code>), <code>acsc</code> (alternatives <code>arccsc</code>, <code>arccosec</code>), <code>acos</code> (alternative <code>arccos</code>), <code>asec</code> (alternative <code>arcsec</code>), <code>atan</code> (alternative <code>arctan</code>), <code>acot</code> (alternatives <code>arccot</code>, <code>arccotan</code>), <code>atan2</code> (alternative <code>arctan2</code>), <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>csch</code> (alternative <code>cosech</code>), <code>sech</code>, <code>asinh</code> (alternative <code>arcsinh</code>), <code>acosh</code> (alternative <code>arccosh</code>), <code>atanh</code> (alternative <code>arctanh</code>), <code>acsch</code> (alternatives <code>arccsch</code>, <code>arcosech</code>), <code>asech</code> (alternative <code>arcsech</code>), <code>exp</code> (alternative <code>Exp</code>), <code>E</code> (equivalent to <code>exp(1)</code>, alternative <code>e</code>), <code>log</code>, <code>sqrt</code>, <code>sign</code>, <code>Abs</code> (alternative <code>abs</code>), <code>Max</code> (alternative <code>max</code>), <code>Min</code> (alternative <code>min</code>), <code>arg</code>, <code>ceiling</code> (alternative <code>ceil</code>), <code>floor</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#feedback_for_incorrect_response","title":"<code>feedback_for_incorrect_response</code>","text":"<p>All feedback for all incorrect responses will be replaced with the string that this parameter is set to.</p>"},{"location":"user_eval_function_docs/compareExpressions/#multiple_answers_criteria","title":"<code>multiple_answers_criteria</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>Answers or responses that contain \\(\\pm\\) or \\(\\mp\\) has two possible interpretations which requires further criteria for equality. The grading parameter <code>multiple_answers_criteria</code> controls this. The default setting, <code>all</code>, is that each answer must have a corresponding answer and vice versa. The setting <code>all_responses</code> check that all responses are valid answers and the setting <code>all_answers</code> checks that all answers are found among the responses.</p>"},{"location":"user_eval_function_docs/compareExpressions/#physical_quantity","title":"<code>physical_quantity</code>","text":"<p>If unset, <code>physical_quantity</code> will default to <code>false</code>.</p> <p>If <code>physical_quantity</code> is set to <code>true</code> the answer and response will interpreted as a physical quantity using units and conventions decided by the <code>strictness</code> and <code>units_string</code> parameters.</p> <p>Remark: Setting <code>physical_quantity</code> to <code>true</code> will also mean that comparisons will be done numerically. If neither the <code>atol</code> nor <code>rtol</code> parameters are set, the evaluation function will choose a relative error based on the number of sigificant digits given in the answer.</p> <p>When <code>physical_quantity</code> the evaluation function will generate feedback based on the flowchart below. Hovering over a criterion node will show a short natural language description of the criterion. Hovering over a result node will show the feedback produced so far.</p> <p>Remark: In some browser it is necessary to right-click and open the image in a separate tab in order for the tooltips to show up on hover.</p> <p></p>"},{"location":"user_eval_function_docs/compareExpressions/#plus_minus-and-minus_plus","title":"<code>plus_minus</code> and <code>minus_plus</code>","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively.</p> <p>To use other symbols for \\(\\pm\\) and \\(\\mp\\) set the grading parameters <code>plus_minus</code> and <code>minus_plus</code> to the desired symbol. Remark: symbol replacement is brittle and can have unintended consequences.</p>"},{"location":"user_eval_function_docs/compareExpressions/#specialfunctions","title":"<code>specialFunctions</code>","text":"<p>If you want to use the special functions <code>beta</code> (Euler Beta function), <code>gamma</code> (Gamma function) and <code>zeta</code> (Riemann Zeta function), set the grading parameter <code>specialFunctions</code> to True.</p>"},{"location":"user_eval_function_docs/compareExpressions/#strict_syntax","title":"<code>strict_syntax</code>","text":"<p>If <code>strict_syntax</code> is set to true then the answer and response must have <code>*</code> or <code>/</code> between each part of the expressions and exponentiation must be done using <code>**</code>, e.g. <code>10*x*y/z**2</code> is accepted but <code>10xy/z^2</code> is not.</p> <p>If <code>strict_syntax</code> is set to false, then <code>*</code> can be omitted and <code>^</code> used instead of <code>**</code>. In this case it is also recommended to list any multicharacter symbols expected to appear in the response as input symbols.</p> <p>By default <code>strict_syntax</code> is set to true.</p>"},{"location":"user_eval_function_docs/compareExpressions/#symbol_assumptions","title":"<code>symbol_assumptions</code>","text":"<p>This input parameter allows the author to set an extra assumption each symbol. Each assumption should be written on the form <code>('symbol','assumption name')</code> and all pairs concatenated into a single string.</p> <p>The possible assumption names can be found in this list:  <code>SymPy Assumption Predicates</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#examples","title":"Examples","text":"<p>Implemented versions of these examples can be found in the module 'Examples: Evaluation Functions'.</p>"},{"location":"user_eval_function_docs/compareExpressions/#1-setting-input-symbols-to-be-assumed-positive-to-avoid-issues-with-fractional-powers","title":"1 Setting input symbols to be assumed positive to avoid issues with fractional powers","text":"<p>In general \\(\\frac{\\sqrt{a}}{\\sqrt{b}} \\neq \\sqrt{\\frac{a}{b}}\\) but if \\(a &gt; 0\\) and \\(b &gt; 0\\) then \\(\\frac{\\sqrt{a}}{\\sqrt{b}} = \\sqrt{\\frac{a}{b}}\\). The same is true for other fractional powers.</p> <p>So if expressions like these are expected in the answer and/or response then it is a good idea to use the <code>symbol_assumptions</code> parameter to note that \\(a &gt; 0\\) and \\(b &gt; 0\\). This can be done by setting <code>symbol_assumptions</code> to <code>('a','positive') ('b','positive')</code>.</p> <p>The example given in the example problem set uses two EXPRESSION response areas. Both response areas uses <code>compareExpression</code> with answer <code>sqrt(a/b)</code>, <code>strict_syntax</code> set to false, <code>elementary_functions</code> set to true. One response area leaves <code>symbol_assumptions</code> unset and the other sets the parameter as described in the previous paragraph. Some examples of expressions that are accepted as correct when positivity is assumed: <code>sqrt(a)/sqrt(b)</code>, <code>(a/b)**(1/2)</code>, <code>a**(1/2)/b**(1/2)</code>, <code>(a/b)^(0.5)</code>, <code>a^(0.5)/b^(0.5)</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#2-using-plusminus-symbols","title":"2 Using plus/minus symbols","text":"<p>The \\(\\pm\\) and \\(\\mp\\) symbols can be represented in  the answer or response by <code>plus_minus</code> and <code>minus_plus</code> respectively. To use other symbols for \\(\\pm\\) and \\(\\mp\\) set the grading parameters <code>plus_minus</code> and <code>minus_plus</code> to the desired symbol. Remark: symbol replacement is brittle and can have unintended consequences.</p> <p>It is considered good practice to make sure that the appropriate notation for \\(\\pm\\) and \\(\\mp\\) are added and displayed as input symbols in order to minimize confusion.</p> <p>The example given in the example problem set uses an EXPRESSION response area that uses <code>compareExpression</code> with answer <code>plus_minus x**2 + minus_plus y**2</code>, <code>strict_syntax</code> set to false and <code>elementary_function</code> set to true. Some examples of expressions that are accepted as correct: <code>plus_minus x**2 + minus_plus y**2</code>, <code>- minus_plus x**2 + minus_plus y**2</code>, <code>- minus_plus x^2 minus_plus y^2</code>, <code>- minus_plus x^2 - plus_minus y^2</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#3-equalities-in-the-answer-and-response","title":"3 Equalities in the answer and response","text":"<p>There is (limited) support for using equalities in the response and answer.</p> <p>The example given in the example problem set uses an EXPRESSION response area that uses <code>compareExpression</code> with answer <code>x**2-5*y**2-7=0</code>. Some examples of expressions that are accepted as correct: <code>x**2-5*y**2-7=0</code>, <code>x^2 = 5y^2+7</code>, <code>2x^2 = 10y^2+14</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#4-checking-the-value-of-an-expression-or-a-physical-quantity","title":"4 Checking the value of an expression or a physical quantity","text":"<p>If the parameter <code>physical_quantity</code> is set to true, the evaluation function can handle expressions that describe physical quantities. Which units are permitted and how they should be written depends on the <code>units_string</code> and <code>strictness</code> parameters respectively.</p> <p>There are three examples in the example problem set. Each examples uses an EXPRESSION response area that uses <code>compareExpression</code> with answer <code>strict_syntax</code> set to false and <code>physical_quantity</code> set to true.</p>"},{"location":"user_eval_function_docs/compareExpressions/#example-a","title":"Example (a)","text":"<p>Here the answer is <code>2.00 km/h</code>. The parameters <code>strictness</code> and <code>units_string</code> are left unset which is equivalent to setting <code>strictness</code> to <code>natural</code>, and <code>units_string</code> to <code>SI common imperial</code>. Thus this response area accepts a wide range of responses, e.g. <code>2.00 kilometre/hour</code>, <code>2 km/h</code>, <code>2000 meter/hour</code>, <code>2 metre/millihour</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#example-b","title":"Example (b)","text":"<p>Here the answer is <code>2.00 km/h</code>. To restrict the answers to SI units <code>strictness</code> is set to <code>strict</code> and <code>units_string</code> is set to <code>SI</code>. Some examples of accepted responses are: <code>0.556 metre/second</code>, <code>5.56 dm/s</code>, <code>55.6 centimetre second^(-1)</code></p>"},{"location":"user_eval_function_docs/compareExpressions/#example-c","title":"Example (c)","text":"<p>Here the answer is <code>2.00 km/h</code>. To restrict the answers to imperial units <code>strictness</code> is set to <code>strict</code> and <code>units_string</code> is set to <code>imperial common</code>. Accepted response: <code>1.24 mile/hour</code></p>"}]}